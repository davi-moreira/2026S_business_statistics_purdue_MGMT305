[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MGMT 30500: Business Statistics",
    "section": "",
    "text": "IMPORTANT\nThis document does not replace the official information in the course brightspace page\n\n\n\nCourse Description and Objectives\nThis course is designed to introduce students to basic data analysis techniques. Coverage includes the application of probability distributions (normal, \\(t\\), binomial), sampling distributions, basic statistical inference methods, analysis of variance, applied linear regression techniques, logistic regression, time series analysis, statistical quality control, and decision analysis.\nOur main goal is to instill the basic quantitative and data analysis skills needed by managers in modern business, where Business Analytics and Data Science have become essential. These skills will aid in data-driven decision-making, risk assessments, and policy formulation, and will enable managers to collaborate effectively with data analysis teams to enhance business performance.\nSince modern data analysis is primarily performed using computers and various sophisticated software, this course will also emphasize software applications (such as Minitab, R, or Python). However, Microsoft Excel is the primary software tool demonstrated in this course.\nCourse Website: https://davi-moreira.github.io/2026S_business_statistics_purdue_MGMT305/\n\n\nInstructor: Professor Davi Moreira\n\nEmail: dmoreira@purdue.edu\nVirtual Office hours: Zoom link in your Course Brightspace Page\nIndividual Appointments: Book time with me through the link in the course syllabus on your Course Brightspace Page or by appointment.\n\n\n\nLearning Outcomes\nBy the end of this course, students will be able to:\n\nUnderstand the basic statistical principles and their applications in the area of management and business.\n\nUnderstand fundamental issues in business and management.\n\nDescribe and use the commonly used statistical techniques for analyzing business data.\n\nBe proficient in using Excel to carry out statistical and analytics methods covered in the course.\n\n\n\nPrerequisite\n\nSTAT 30301: Probability and Statistics for Business.\n\n\n\nCourse Materials\n\nTextbook:\nAnderson, Sweeney, Williams, Camn, Cochran, Fry, and Ohlmann.\nModern Business Statistics with Microsoft Excel, 7th Edition, 2020, Cengage Learning, Inc.\n(Required; also used in STAT 30301)\nHandouts:\nLecture Slides and Supplementary Materials (available on Brightspace).\nThe E-Book and handouts are located in Brightspace → Content → Table of Contents → …\nComputing:\nQuizzes will be administered in-person, and you will need to work on practice exercises in class. You should have access to a PC, Mac, or tablet.\nSoftware:\nMicrosoft Excel is used for in-class demonstrations. Ensure the “Data Analysis” ToolPak is enabled:\n\nFile -&gt; Options -&gt; Add-ins\n\nSelect Analysis ToolPak and Analysis ToolPak-VBA → Go\n\nData → Data Analysis (for Excel-based analyses)\n\n\n\n\nCourse Infra-structure\nBrightspace: The Course Brightspace Page https://purdue.brightspace.com/ should be checked on a regular basis for announcements and course material.\nSoftware: Microsoft Excel will be used for in-class demonstrations and instruction. The main tool is Data Analysis under Tools. If you don’t see this tool, follow the following steps to add in:\n\nFile -&gt; Options -&gt; Add-ins -&gt; Select Analysis ToolPak and Analysis ToolPak-VBA (also select StatTools 7.5, if available) -&gt; Go -&gt; Data -&gt; Data Analysis (to conduct analyses)\n\nCourse Website: This class website will be used throughout the course, but it does not replace the Course Brightspace Page.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule and Material",
    "section": "",
    "text": "Week\nDay\nDate\nTopic\nBook Sections*\nSlides***\nData\nSupplementary Materials\n\n\n\n\n1\nM\nJan 12\nIntro. & Basic Stat. & Prob. Review 01\nSyl., 1.2, 1.4, 1.5\nslidespodcast**video**\ndata\n- Video: The NBA Data Scientist- Video: Hans Rosling’s 200 Countries, 200 Years- IMS: Introduction to data\n\n\n1\nW\nJan 14\nBasic Stat. & Prob. Review 02\n1.8, 3.3 (omit Chebyshev), 3.4, 3.5\nslidespodcast**video**\ndata\n- Video: Data Basics- Video: Summarizing and Graphing Numerical Data- Video: Exploring Categorical Data- IMS: Exploratory data analysis\n\n\n1\nF\nJan 16\nBasic Stat. & Prob. Review 03\n6.2, t Dist. Supplement\nslidespodcast**video**\n.\n- Video: Normal Distribution\n\n\n2\nS\nJan 18\nHomework 01 Due date\nBasic Stat. & Prob. Review\n.\n.\n.\n\n\n2\nM\nJan 19\nMARTIN LUTHER KING JR. DAY\n—\n.\n.\n.\n\n\n2\nW\nJan 21\nInt. Est. Review\n8.1, 8.2, 8.3, 8.4\nslidespodcast**video**\n.\n- Video: Point Estimates- Video: Confidence Intervals- Video: t-distribution\n\n\n2\nF\nJan 23\nHyp. Testing Review 01\n9.1, 9.2, 9.4, 9.5\nslidespodcast**video**\n.\n- Video: Hypothesis Testing Fundamentals\n\n\n2\nS\nJan 25\nHomework 02 Due date\nBasic Stat. & Prob. Review\n.\n.\n.\n\n\n3\nM\nJan 26\nHyp. Testing Review 02\n11.1, 11.2\nslidespodcast**video**\ndata\n- Nature: Statisticians issue warning over misuse of P-values\n\n\n3\nW\nJan 28\nQuiz 1\nReview Material\n.\n.\n.\n\n\n3\nF\nJan 30\nAnalysis of Variance\n13.1, 13.2\nslidespodcast**video**\ndata\n- Video: ANOVA Introduction- Video: Conditions for ANOVA- Video: Multiple comparisons\n\n\n3\nS\nFeb 1\nHomework 02 Due date\nInt. Est. & Hyp. Testing Review\n.\n.\n.\n\n\n4\nM\nFeb 2\nSimple Regression\n14.1\nslidespodcast**video**\ndata\n- Video: Line Fitting & Correlation\n\n\n4\nW\nFeb 4\nSimple Regression\n14.2, 14.3\nslidespodcast**video**\n.\n.\n\n\n4\nF\nFeb 6\nSimple Regression\n14.4, 14.5\nslidespodcast**video**\n.\n.\n\n\n5\nM\nFeb 9\nSimple Regression\n14.6, 14.7\nslidespodcast**video**\n.\n.\n\n\n5\nW\nFeb 11\nSimple Regression\n14.8\nslidespodcast**video**\n.\n.\n\n\n5\nF\nFeb 13\nSimple Regression\n14.9\nslidespodcast**video**\n.\n.\n\n\n5\nS\nFeb 15\nHomework 03 Due date\nSimple Regression\n.\n.\n.\n\n\n6\nM\nFeb 16\nMidterm 1 Review\nAnalysis of Variance & Simple Regression\n.\n.\n.\n\n\n6\nW\nFeb 18\nMidterm 1 Review\nAnalysis of Variance & Simple Regression\n.\n.\n.\n\n\n6\nW\nFeb 19\nMidterm 1 (TBD pm–TBD pm, TBD)\nAnalysis of Variance & Simple Regression\n.\n.\n.\n\n\n6\nW\nFeb 20\nNo Class\n.\n.\n.\n.\n\n\n7\nF\nFeb 23\nMultiple Regression\n15.1, 15.2, 15.3\nslidespodcast**video**\ndata\n- Video: Introduction to Multiple Regression\n\n\n7\nW\nFeb 25\nMultiple Regression\n15.4\nslidespodcast**video**\n.\n.\n\n\n7\nF\nFeb 27\nMultiple Regression\n15.5\nslidespodcast**video**\n.\n.\n\n\n8\nM\nMar 2\nMultiple Regression\n15.6\nslidespodcast**video**\n.\n.\n\n\n8\nW\nMar 4\nMultiple Regression\n15.7\nslidespodcast**video**\n.\n.\n\n\n8\nS\nMar 8\nHomework 04 Due date\nMultiple Regression, Pt. 1\n.\n.\n.\n\n\n9\nM\nMar 9\nModel Building\n16.1, 16.2\nslidespodcast**video**\ndata\n- Video: Model Selection in Multiple Regression\n\n\n9\nW\nMar 11\nQuiz 2\nMultiple Regression\n.\n.\n.\n\n\n9\nF\nMar 13\nModel Building\n16.3, 16.4\nslidespodcast**video**\n.\n.\n\n\n10\nM\nMar 16\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nW\nMar 18\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nF\nMar 20\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nS\nMar 22\nHomework 05 Due date\nMultiple Regression, Pt. 2\n.\n.\n.\n\n\n11\nM\nMar 23\nLogistic Regression\nSupplement in Brightspace & Slides\nslidespodcast**video**\n.\n- Video: Basic Ideas of Logistic Regression\n\n\n11\nW\nMar 25\nLogistic Regression\nSupplement in Brightspace & Slides\nslidespodcast**video**\n.\n.\n\n\n11\nF\nMar 27\nLogistic Regression\nSupplement in Brightspace & Slides\nslidespodcast**video**\n.\n.\n\n\n11\nS\nMar 29\nHomework 06 Due date\nLogistic Regression\n.\n.\n.\n\n\n12\nM\nMar 30\nMidterm 2 Review\nMult. Regr., Model Bldg., Log. Regr.\n.\n.\n.\n\n\n12\nM\nApr 1\nMidterm 2 Review\nMult. Regr., Model Bldg., Log. Regr.\n.\n.\n.\n\n\n12\nW\nApr 1\nMidterm 2 (TBD pm–TBD pm, TBD)\nMult. Regr., Model Bldg., Log. Regr.\n.\n.\n.\n\n\n12\nF\nApr 3\nNo Class\n.\n.\n.\n.\n\n\n13\nF\nApr 6\nTime Series\n17.1, 17.2, 17.3\nslidespodcast**video**\ndata\nVideo: Time Series Forecast Using Forecast Sheet in Excel\n\n\n13\nW\nApr 8\nTime Series\n17.4\nslidespodcast**video**\n.\n.\n\n\n13\nF\nApr 10\nTime Series\n17.5, 17.6\nslidespodcast**video**\n.\n.\n\n\n13\nS\nApr 12\nHomework 07 Due date\nTime Series\n.\n.\n.\n\n\n14\nM\nApr 13\nQuality Control\n19.1\nslidespodcast**video**\n.\n.\n\n\n14\nW\nApr 15\nQuiz 3\nTime Series\n.\n.\n.\n\n\n14\nF\nApr 17\nQuality Control\n19.2, 19.3\nslidespodcast**video**\n.\n.\n\n\n15\nM\nApr 20\nDecision Analysis\n20.1\nslidespodcast**video**\n.\n- Video: Bayes theorem\n\n\n15\nW\nApr 22\nDecision Analysis\n20.2\nslidespodcast**video**\n.\n.\n\n\n15\nF\nApr 24\nDecision Analysis\n20.3, 20.4\nslidespodcast**video**\n.\n.\n\n\n15\nS\nApr 26\nHomework 08 Due date\nQuality Control & Decision Analysis\n.\n.\n.\n\n\n16\nM\nApr 27\nFinal Exam Review\nCumulative\n.\n.\n.\n\n\n16\nW\nApr 29\nFinal Exam Review\nCumulative\n.\n.\n.\n\n\n16\nF\nMay 1\nFinal Exam Preparation\nNo class\n.\n.\n.\n\n\n17\n—\nTBD\nFinal Exam (TBD pm–TBD pm, TBD)\nCumulative\n.\n.\n.\n\n\n\n\n\n*Section Numbers refer to sections in the course textbook.\n** This material was generated with Google NotebookLM based on the slides prepared for the course.\n*** Course material adapted from the textbook and previous course editions to better fit our curriculum. Thanks to Professor Jen Tang for guidance and for generously sharing the materials.",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "syllabus.html#course-description-and-objectives",
    "href": "syllabus.html#course-description-and-objectives",
    "title": "Syllabus",
    "section": "Course Description and Objectives",
    "text": "Course Description and Objectives\nThis course is designed to introduce students to basic data analysis techniques, including applications of probability distributions (normal, (t), binomial), sampling distributions, basic statistical inference methods, analysis of variance, applied linear regression techniques, logistic regression, time series analysis, statistical quality control, and decision analysis.\nOur primary goal is to instill in students the quantitative and data analysis skills essential in modern business, where Business Analytics and Data Science are increasingly important. These skills will empower managers to make data-based decisions, perform risk assessments, develop policies, and collaborate effectively with analytics teams to boost business performance.\nBecause modern data analysis relies heavily on computers and software, we will emphasize practical applications using Microsoft Excel (with exposure to Minitab, R, or Python when relevant).\nCourse Website: https://davi-moreira.github.io/2026S_business_statistics_purdue_MGMT305/",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "Instructor",
    "text": "Instructor\n\nInstructor: Professor Davi Moreira\n\nOffice: Young Hall 1019\nEmail: dmoreira@purdue.edu\nVirtual Office hours: Zoom link in your Course Brightspace Page\nIndividual Appointments: Book time with me through the link in the course syllabus on your Course Brightspace Page or by appointment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#learning-outcomes",
    "href": "syllabus.html#learning-outcomes",
    "title": "Syllabus",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, students will be able to:\n\nUnderstand the basic statistical principles and their applications in the area of management and business.\n\nUnderstand fundamental issues in business and management.\n\nDescribe and use the commonly used statistical techniques for analyzing business data.\n\nBe proficient in using Excel to carry out statistical and analytics methods covered in the course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-materials",
    "href": "syllabus.html#course-materials",
    "title": "Syllabus",
    "section": "Course Materials",
    "text": "Course Materials\n\nTextbook\n\nAnderson, Sweeney, Williams, Camn, Cochran, Fry, and Ohlmann (2020).\nModern Business Statistics with Microsoft Excel (7th edition). Cengage Learning, Inc.\n– Required textbook, also used in STAT 30301.\n\nHandouts\n\nPresentation slides and supplementary materials posted on Brightspace:\nBrightspace → Content → Table of Contents → …\n\nComputing Requirements\n\nYou must have access to a PC, Mac, or tablet equipped with a webcam to complete in-class quizzes and practice exercises.\n\nSoftware\n\nMicrosoft Excel will be used for in-class demonstrations.\n\nTo enable Excel’s “Data Analysis” ToolPak:\n\nFile → Options → Add-ins\n\nSelect Analysis ToolPak and Analysis ToolPak-VBA (also StatTools 7.5 if available) → Go\n\nReturn to Data tab → Data Analysis\n## Course Infrastructure\n\n\n\n\nBrightspace: The Course Brightspace Page (https://purdue.brightspace.com/) should be checked on a regular basis for announcements and course material.\nSoftware: Microsoft Excel will be used for in-class demonstrations and instruction. The main tool is Data Analysis under Tools. If you don’t see this tool, follow these steps to add it in:\n\nFile &gt; Options &gt; Add-ins &gt; Select Analysis ToolPak and Analysis ToolPak-VBA (also select StatTools 7.5, if available) &gt; Go &gt; Data &gt; Data Analysis (to conduct analyses)\n\nCourse Website: This class website will be used throughout the course, but it does not replace the Course Brightspace Page.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assessments-and-grading",
    "href": "syllabus.html#assessments-and-grading",
    "title": "Syllabus",
    "section": "Assessments and Grading",
    "text": "Assessments and Grading\nIn compliance with the Business School’s Official Grading Policy for MGMT 30500, the overall class GPA cannot exceed 3.0. Final letter grades will be based on a curved distribution of final course percentages. While Brightspace will display your final percentage performance, specific grade thresholds will not be released prior to official submission.\nBelow are the grading components and their respective weights:\n\n\n\nAssessment\nWeight\n\n\n\n\nAttendance\n1%\n\n\nParticipation\n4%\n\n\nHomework (8 total)\n24%\n\n\nQuizzes (3 total)\n21%\n\n\nMidterms (2 total)\n30%\n\n\nFinal (cumulative)\n20%\n\n\n\n\nAttendance\nAttendance is essential for success in this course. If you do not attend class regularly, you are unlikely to succeed. According to the University regulations, “Scheduled courses allow students to avoid conflicts and reflect the University’s expectation that students should be present for every meeting of a class/laboratory for which they are registered.” Attendance will be recorded using iClicker, and these records will be reflected in your gradebook at the end of the semester. A minimum attendance rate of 85% is required to meet the expectations of this course.\n\n\nParticipation\nDuring the semester you will be required to take participatory activities. Your participation grade will be based on this record.\n\n\nHomework\n\nEight homework assignments; none are dropped.\n\nHomework must be submitted on Brightspace by the deadline in a single PDF or Word file, with all relevant Excel (or other) outputs included and clearly referenced.\n\nSubmissions:\n\nYou have 2 attempts to upload your assignment; only the second is graded if you use both attempts.\n\nNo late homework or email submissions are accepted.\n\n\nYou may discuss homework with classmates, but copying or duplicate submissions are considered cheating.\n\n\n\nQuizzes\n\nThree quizzes, each worth 5%. Quizzes 2 and 3 are not cumulative.\n\nMake-up quizzes are only allowed under exceptional circumstances (e.g., verifiable medical emergencies, conflicting NCAA events).\n\n\n\nMidterms\n\nTwo in-person midterms exams, each worth 15%. Neither is cumulative.\n\nExams test technical calculation skills and conceptual understanding similar to homework problems.\n\nCalculators without internet or USB capabilities are allowed; phones/watches are not.\n\n\n\nFinal\n\nCumulative in-person exam.\n\nBring an approved calculator as described above.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grade-challenges",
    "href": "syllabus.html#grade-challenges",
    "title": "Syllabus",
    "section": "Grade Challenges",
    "text": "Grade Challenges\nGrades and solutions will be posted soon after each assignment deadline. Students have 7 calendar days from the grade posting to submit any challenge (3 days for the final two quizzes and homework assignments). Challenges must be based on legitimate discrepancies regarding data mining principles or grading accuracy.\n\nReview posted solutions thoroughly.\n\nIf you suspect an error, email Dr. Moreira with:\n\nCourse name, section, and lecture day/time\n\nYour name and Student ID\n\nAssignment/Exam Title or Number\n\nSpecific deduction questioned\n\nClear rationale referencing solutions or rubrics\n\n\n\nNo grades will be discussed in-class. Please use office hours for clarifications. After the 7-day (or 3-day) window, grades are final.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies-and-additional-details",
    "href": "syllabus.html#course-policies-and-additional-details",
    "title": "Syllabus",
    "section": "Course Policies and Additional Details",
    "text": "Course Policies and Additional Details\n\nExtra Credit Opportunities\n\nCheck the Course Syllabus document on Brightspace for details.\n\n\n\nKeys to Success\n\nConsistent Effort – Follow the course schedule regularly.\n\nPre-Class Preparation – Read the assigned materials and review homework exercises.\n\nClass Materials – Print or digitally access slides/readings for note-taking.\n\nEngage with Problems – Practice is crucial; problems may be more challenging than they appear in lecture.\n\nActive Learning – Do not rely solely on class presentations. Work through exercises and reinforce your understanding.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-policies-and-additional-details-1",
    "href": "syllabus.html#course-policies-and-additional-details-1",
    "title": "Syllabus",
    "section": "Course Policies and Additional Details",
    "text": "Course Policies and Additional Details\n\nExtra Credit Opportunities\n\nCheck the Course Syllabus document on Brightspace for details.\n\n\n\nAI Policy\n\nYou may use AI tools to support your learning (e.g., clarifying concepts, generating examples), but:\n\nDo not use AI for homework, quizzes, or exams.\n\nPractice refining prompts to get better AI outputs.\n\nVerify all AI-generated content for accuracy.\n\nCite any AI usage in your documents.\n\n\n\n\nAdditional Information\nRefer to Brightspace for deadlines, academic integrity policies, accommodations, CAPS information, and non-discrimination statements.\n\n\nSubject to Change Policy\nWhile we will endeavor to maintain the course schedule, the syllabus may be adjusted to accommodate the learning pace and needs of the class.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html",
    "title": " MGMT 30500: Business Statistics ",
    "section": "",
    "text": "Multiple Regression Model\nLeast Squares Method\nMultiple Coefficient of Determination\nModel Assumptions\nTesting for Significance: Overall and Individual\n\n\n\nMulticollinearity Issue\nResidual Analysis\nPrediction\nCategorical Independent Variables"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#overview",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nMultiple Regression Model\nLeast Squares Method\nMultiple Coefficient of Determination\nModel Assumptions\nTesting for Significance: Overall and Individual\n\n\n\nMulticollinearity Issue\nResidual Analysis\nPrediction\nCategorical Independent Variables"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Controlling for a Variable",
    "text": "Motivation: Controlling for a Variable\n\nPuzzle: What is the effect of education on income?\nY: Income\nX: Education\nObjective: X \\(\\rightarrow\\) Y\nChallenge: X \\(\\leftarrow\\) W \\(\\rightarrow\\) Y\nW: IQ (Intelligence)\nSolution: Control for W"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Controlling for a Variable",
    "text": "Motivation: Controlling for a Variable\n\n\n\n\nDAG\n\n\n\nSource: Causal Inference Animated Plots"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#motivation-controlling-for-a-variable-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Controlling for a Variable",
    "text": "Motivation: Controlling for a Variable\n\n\n\n\nRelationship between Y and X controlled for W\n\n\n\nSource: Causal Inference Animated Plots"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#omitted-variables-confounders",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#omitted-variables-confounders",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Omitted Variables (Confounders)",
    "text": "Omitted Variables (Confounders)\n\nOne of the most common errors in observational studies (besides selection bias and information bias — classification or measurement error);\nIt occurs when we suggest that the explanation for something is “confounded” with the effect of another variable;\nFor example, “the sun rose because the rooster crowed,” and not because of Earth’s rotation."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#how-to-address-omitted-variable-bias",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#how-to-address-omitted-variable-bias",
    "title": " MGMT 30500: Business Statistics ",
    "section": "How to Address Omitted Variable Bias?",
    "text": "How to Address Omitted Variable Bias?\n\nBe well-versed in the literature;\nSelect good control variables for your model;\nThat is, perform a multiple regression model."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression",
    "text": "Multiple Regression\n\nRegression analysis involving two or more independent variables (x’s).\nThis subject area, called multiple regression analysis, enables us to consider more independent variables (factors) and thus obtain better estimates of the relationship than are possible with simple linear regression."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\nThe equation that describes how the dependent variable \\(y\\) is related to the independent variables \\(x_1, x_2, \\ldots x_p\\) and an error term \\(\\epsilon\\) is:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\n\\]\nWhere:\n\n\\(\\beta_0, \\beta_1, \\beta_2, \\dots, \\beta_p\\) are the unknown parameters.\n\\(\\epsilon\\) is a random variable called the error term with the same assumptions as in simple regression (Normality, zero mean, constant variance, independence).\n\\(p\\) is the number of independent variables (dimension or complexity of the model)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-equation",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression Equation",
    "text": "Multiple Regression Equation\nThe equation that describes how the mean value of \\(y\\) is related to \\(x_1, x_2, \\ldots x_p\\) is:\n\\[\nE(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n\\]\n\\(\\beta_1, \\ldots, \\beta_p\\) measure the marginal effects of the respective independent variables.\n\nFor example, \\(\\beta_1\\) is the change in \\(E(y)\\) corresponding to a 1-unit increase in \\(x_1\\), when all other independent variables are held constant or when we control for all other independent variables."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimated-multiple-regression-equation",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimated-multiple-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimated Multiple Regression Equation",
    "text": "Estimated Multiple Regression Equation\n\n\\[\n\\hat{y} = b_0 + b_1 x_1 + b_2 x_2 + \\dots + b_p x_p\n\\]\nA simple random sample is used to compute sample slopes \\(b_0, b_1, b_2, \\dots, b_p\\) that are used as the point estimators of the population slopes \\(\\beta_0, \\beta_1, \\beta_2, \\dots, \\beta_p\\).\n\nHence, \\(\\hat{y}\\) estimates \\(E(Y)\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#least-squares-method-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#least-squares-method-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Least Squares Method",
    "text": "Least Squares Method\n\nLeast Squares Criterion: Minimize the Sum of Squared Errors (SSE):\n\\[\n\\min \\sum (y_i - \\hat{y_i})^2\n\\]\nWhere \\(y_i - \\hat{y_i}\\) is the \\(i\\)-th residual/error.\n\n\nThe formulas for the regression coefficients \\(b_0, b_1, b_2, \\dots, b_p\\) involve the use of matrix algebra. We will rely on computer software packages to perform the calculations.\nThe emphasis will be on how to interpret the computer output rather than on how to make the multiple regression computations."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimation-process",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimation-process",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimation Process",
    "text": "Estimation Process"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\nExample: Butler Trucking Company\nManagers at Butler Trucking Company want to develop better work schedules for their drivers. They believe that the total daily travel time would be closely related to the number of miles traveled in making the daily deliveries and also to the number of deliveries.\nA simple random sample of 10 driving assignments was taken."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\nExample: Butler Trucking Company - Butler.xlsx\n\n\n\n\n\n\n\n\n\nDriving Assignment\nMiles traveled \\(x_1\\)\nDeliveries \\(x_2\\)\n\\(y\\) = Travel Time (hours)\n\n\n\n\n1\n100\n4\n9.3\n\n\n2\n50\n3\n4.8\n\n\n3\n100\n4\n8.9\n\n\n4\n100\n2\n6.5\n\n\n5\n50\n2\n4.2\n\n\n6\n80\n2\n6.2\n\n\n7\n75\n3\n7.4\n\n\n8\n65\n4\n6.0\n\n\n9\n90\n3\n7.6\n\n\n10\n90\n2\n6.1"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-3",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-regression-model-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Regression Model",
    "text": "Multiple Regression Model\nExample: Butler Trucking Company\nSuppose we believe that total daily travel time (\\(y\\)) is related to the miles traveled (\\(x_1\\)) and the number of deliveries made (\\(x_2\\)) by the following multiple linear regression model:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n\\]\nWhere:\n\n\\(y\\) = Total travel time\n\\(x_1\\) = Miles traveled\n\\(x_2\\) = Deliveries made\n\\(n = 10, p = 2\\)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#summary-statistics",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#summary-statistics",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\n\n\n\n\nMiles (\\(x_1\\))\nDeliveries (\\(x_2\\))\nTime (\\(Y\\))\n\n\n\n\nMean\n80\n2.9\n6.7\n\n\nStandard Error\n6.191\n0.277\n0.515\n\n\nMedian\n85\n3\n6.35\n\n\nMode\n100\n2\n#N/A\n\n\nStandard Deviation\n19.579\n0.876\n1.630\n\n\nSample Variance\n383.333\n0.767\n2.656\n\n\nKurtosis\n-1.114\n-1.734\n-0.547\n\n\nSkewness\n-0.583\n0.223\n0.196\n\n\nRange\n50\n2\n5.1\n\n\nMinimum\n50\n2\n4.2\n\n\nMaximum\n100\n4\n9.3\n\n\nSum\n800\n29\n67\n\n\nCount\n10\n10\n10"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#correlations",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#correlations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlations",
    "text": "Correlations\n\n\n\n\n\n\n\n\n\n\nMiles (\\(x_1\\))\nDeliveries (\\(x_2\\))\nTime (\\(Y\\))\n\n\n\n\nMiles (\\(x_1\\))\n1\n\n\n\n\nDeliveries (\\(x_2\\))\n0.162\n1\n\n\n\nTime (\\(Y\\))\n0.815\n0.615\n1"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#regression-output",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#regression-output",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Regression Output",
    "text": "Regression Output\nExample: Butler Trucking Company"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimated-regression-equation",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimated-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimated Regression Equation",
    "text": "Estimated Regression Equation\nExample: Butler Trucking Company\nPrediction equation:\n\\[\n\\hat{y} = -0.8687 + 0.0611x_1 + 0.9234x_2\n\\]\n\n\nFor observation #1 where \\(x_1 = 100\\), \\(x_2 = 4\\), and \\(y = 9.3\\):\n\\[\n\\hat{y} = -0.8687 + 0.0611(100) + 0.9234(4) = 8.9385\n\\]\nUnexplained residual = \\(y - \\hat{y} = 9.3 - 8.9385 = 0.3615\\)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpreting-the-regression-coefficients",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpreting-the-regression-coefficients",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpreting the Regression Coefficients",
    "text": "Interpreting the Regression Coefficients\n\nEach \\(b_i\\) (for \\(x_i\\)) represents an estimate of the change in the expected \\(y\\) corresponding to a 1-unit increase in \\(x_i\\), when all other independent variables are held constant or when we control for all other independent variables."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpreting-the-regression-coefficients-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpreting-the-regression-coefficients-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpreting the Regression Coefficients",
    "text": "Interpreting the Regression Coefficients\nExample: Butler Trucking Company\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(b_1 = +0.0611\\) (for \\(x_1\\))\n\n+0.0611 is the estimated average change (increase) in the expected travel time corresponding to an increase of one mile in the distance traveled when the number of deliveries is held constant.\n\n\n\n\n\\(b_2 = +0.9234\\) (for \\(x_2\\))\n\n+0.9234 is the estimated average change (increase) in the expected travel time corresponding to an increase of one delivery when the number of miles traveled is held constant."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Coefficient of Determination",
    "text": "Multiple Coefficient of Determination\n\nRelationship Among SST, SSR, SSE\n\n\n\n\n\n\n\n\n\n\nSST\nSSR\nSSE\n\n\n\n\nFormula\n\\(\\sum (y_i - \\bar{y})^2\\)\n\\(\\sum (\\hat{y}_i - \\bar{y})^2\\)\n\\(\\sum (y_i - \\hat{y}_i)^2\\)\n\n\nDegrees of Freedom\n\\(n-1\\)\n\\(p\\)\n\\(n-p-1\\)\n\n\n\n\\[\n\\sum (y_i - \\bar{y})^2 = \\sum (\\hat{y_i} - \\bar{y})^2 + \\sum (y_i - \\hat{y_i})^2\n\\]\nWhere:\n\nSST = Total sum of squares (total variation of the response)\nSSR = Sum of squares due to regression (explained by all predictors)\nSSE = Sum of squares due to error (unexplained variation of residuals)\n\\(n\\) = sample size.\n\\(p\\) = number of predictors (independent variables).\nThe degrees of freedom for SSE reflect the number of observations left after accounting for the number of estimated parameters (\\(n - (p + \\text{one intercept})\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#partition-of-sst",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#partition-of-sst",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Partition of SST",
    "text": "Partition of SST\n\n\n\n\ndf: SST = 9, SSE = 7, SSR = 2"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Coefficient of Determination",
    "text": "Multiple Coefficient of Determination\nExample: Butler Trucking Company\nANOVA Table\n\n\n\nANOVA\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n\nRegression\n2\n21.6006\n10.8003\n32.8784\n0.0003\n\n\nResidual\n7\n2.2994\n0.3285\n\n\n\n\nTotal\n9\n23.9"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-3",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multiple-coefficient-of-determination-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Coefficient of Determination",
    "text": "Multiple Coefficient of Determination\nExample: Butler Trucking Company\n\\[\nR^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\n\\]\n\\[\nR^2 = \\frac{21.6006}{23.9} = 1 - \\frac{2.2994}{23.9} = 90.38\\%\n\\]\n\\[\nR^2 = 1 - \\frac{SSE / (n - 1)}{SST / (n - 1)} = 1 - \\frac{\\text{Residual variance}}{\\text{Response variance}}\n\\]"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#remarks-on-multiple-coefficient-of-determination",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#remarks-on-multiple-coefficient-of-determination",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Remarks on Multiple Coefficient of Determination",
    "text": "Remarks on Multiple Coefficient of Determination\n\nAdding independent variables, even ones that are not statistically significant, will reduce the prediction errors, thus the SSE will become smaller.\nBecause SST = SSR + SSE is fixed, SSR will become larger, SSE will become smaller, and hence, \\(R^2 = SSR/SST\\) will always increase.\nBut, adding independent variables, the model will become more complex (a larger \\(p\\))."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adjusted Multiple Coefficient of Determination",
    "text": "Adjusted Multiple Coefficient of Determination\n\nThe adjusted multiple coefficient of determination (\\(R^2_a\\)) takes into account the following factors:\n\nThe number of independent variables in the model (\\(p\\), dimension or complexity)\nThe \\(R^2\\) (Adequacy)\nThe sample size (\\(n\\), available information)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adjusted Multiple Coefficient of Determination",
    "text": "Adjusted Multiple Coefficient of Determination\nExample: Butler Trucking Company\n\\[\nR^2 = 1 - \\frac{SSE}{SST} = 90.38\\%\n\\]\n\\[\nR^2_a = 1 - \\frac{\\frac{SSE}{(n - p - 1)}}{\\frac{SST}{(n - 1)}} = 1 - (1 - R^2) \\cdot \\frac{n - 1}{n - p - 1}\n\\]\n\\[\nR^2_a = 1 - \\frac{2.2994 / (10 - 2 - 1)}{23.9 / (10 - 1)} = 1 - (1 - 0.9038) \\cdot \\frac{10 - 1}{10 - 2 - 1} = 87.63\\%\n\\]"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#adjusted-multiple-coefficient-of-determination-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adjusted Multiple Coefficient of Determination",
    "text": "Adjusted Multiple Coefficient of Determination\n\\[\nR^2_a = 1 - \\frac{\\frac{SSE}{(n - p - 1)}}{\\frac{SST}{(n - 1)}} = 1 - \\frac{MSE}{\\frac{SST}{(n - 1)}} = 1 - \\frac{S^2}{\\frac{SST}{(n - 1)}}\n\\]\n\nA smaller \\(S^2\\) gives a higher \\(R^2_a\\).\nBringing in a new independent variable will increase the \\(R^2_a\\) when and only when it can decrease the estimated error variance (\\(S^2\\) or MSE). Hence, \\(R^2_a\\) is a good criterion for model building or model selection.\n\n(Recall: MSE or \\(S^2\\) estimates the error variance \\(\\sigma^2\\).)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-significance-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-significance-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Significance",
    "text": "Testing for Significance\n\nIn simple linear regression, the F and \\(t\\) Tests provide the same conclusion:\n\nThey are equivalen\\(t\\) Tests: Squared t-value = F-value.\nThey have the same p-value.\n\nIn multiple regression, the F and \\(t\\) Tests have different purposes and are not equivalent."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\n\nThe \\(F\\) Test is used to determine whether a significant linear relationship exists between the dependent variable and the set of all the independent variables, by testing their population slopes (\\(\\beta_1, \\dots, \\beta_p\\)) together as a group.\nThe \\(F\\) Test is referred to as the test for overall significance."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\n\nHypotheses\n\\[\nH_0: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0 \\quad (\\text{No linear relationship})\n\\]\n\\[\nH_a: \\text{One or more of the slopes is not equal to zero}\n\\]\nTest Statistics\n\\[\nF = \\frac{MSR}{MSE}\n\\] where,\n\\[\nMSR = \\frac{SSR}{p} \\quad \\text{and} \\quad MSE = \\frac{SSE}{n-p-1}\n\\]\nRejection Rule\nReject \\(H_0\\) if \\(F \\geq F_\\alpha\\) or \\(p \\leq \\alpha\\).\nwhere \\(F_\\alpha\\) is based on an \\(F\\) distribution with \\(p\\) d.f. (numerator) and \\(n - p - 1\\) d.f. (denominator)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\nExample: Butler Trucking Company\nHypotheses:\n\\[\nH_0: \\beta_1 = \\beta_2 = 0\n\\]\n\\[\nH_a: \\text{One or both slopes are not equal to zero}\n\\]\nRejection Rule\nFor \\(\\alpha = 0.01\\) and degrees of freedom = 2 and 7, \\(F_{\\alpha} = 9.55\\).\nReject \\(H_0\\) if \\(F \\geq 9.55\\) or \\(p \\leq .01\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-3",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\nTest Statistics\n\\[\nF = \\frac{MSR}{MSE} = \\frac{10.8003}{0.3285} = 32.8784\n\\]\nConclusion:\nWe reject \\(H_0\\) because \\(F = 32.8784 &gt; 9.55\\).\nWe have significant statistical evidence to conclude that at least one of the independent variables is useful in explaining the variation in the total travel time, or for predicting the total travel time. The significance level is 1%."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-4",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\nANOVA Output\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n\nRegression\n\\(p\\)\nSSR\n\\(MSR=\\frac{SSR}{p}\\)\n\\(F=\\frac{MSR}{MSE}\\)\n\\(p-value\\)\n\n\nResidual\n\\(n-p-1\\)\nSSE\n\\(MSE=\\frac{SSE}{n-p-1}\\)\n\n\n\n\nTotal\n\\(n-1\\)\nSST"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-5",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-overall-significance-f-test-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\nANOVA Output\n\n\n\nSource\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n\nRegression\n2\n21.6006\n10.8003\n32.8784\n0.0003\n\n\nResidual\n7\n2.2994\n0.3285\n\n\n\n\nTotal\n9\n23.9\n\n\n\n\n\n\n\\[\np-value = 1 - F.DIST(32.8784, 2, 7, TRUE) \\approx 0.0003\n\\]"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\n\nIf the \\(F\\) test shows an overall significance, a separate \\(t\\) test is conducted for each of the independent variables in the model.\nThe \\(t\\) test is used to determine whether each of the individual independent variables is significant in the presence of all other independent variables in the model.\n\nIt tests the additional contribution in reducing the variation of the unexplained error (or in increasing the explained variation).\n\nWe refer to each of these \\(t\\) tests as a test for individual significance."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\nHypotheses\n\\[\nH_0: \\beta_i = 0 \\quad (x_i \\text{ is not significant in the presence of all other } x's)\n\\]\n\\[\nH_a: \\beta_i \\neq 0\n\\]\nTest Statistic\n\\[\nt = \\frac{b_i - 0}{s_{b_i}} \\quad (s_{b_i} \\text{ is the standard error of } b_i)\n\\]\nRejection Rule\nReject \\(H_0\\) if \\(t \\leq -t_{\\alpha / 2}\\) or \\(t \\geq t_{\\alpha / 2}\\) or if \\(p\\)-value \\(\\leq \\alpha\\).\nwhere \\(t_{\\alpha/2}\\) is based on a \\(t\\)-distribution with \\(n - p - 1\\) degrees of freedom."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\nExample: Butler Trucking Company\n\n\\(H_0: \\beta_i = 0\\)\n\\(H_a: \\beta_i \\neq 0 \\quad \\text{(Two-tailed)}\\)\n\n\nFor \\(\\alpha = 0.01\\) and \\(df = 7\\):\n\\[\nt_{0.005} = 3.499\n\\]\nReject \\(H_0\\) if \\(p\\)-value \\(\\leq .01\\), or if \\(t \\leq -3.499\\) or \\(t \\geq 3.499\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-3",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\nTest Statistics\n\\[\nt = \\frac{b_1 - 0}{s_{b_1}} = \\frac{0.0611 - 0}{0.0099} = 6.1717, \\quad \\text{for } x_1\n\\]\n\\[\nt = \\frac{b_2 - 0}{s_{b_2}} = \\frac{0.9234 - 0}{0.2211} = 4.1764, \\quad \\text{for } x_2\n\\]\nConclusion\nReject each of \\(H_0: \\beta_1 = 0\\) and \\(H_0: \\beta_2 = 0\\). Each independent variable is statistically significant in the presence of the other."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-4",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#testing-for-individual-significance-t-test-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\nExample: Butler Trucking Company\nRegression Table"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multicollinearity-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multicollinearity-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nThe term multicollinearity refers to the correlation among the independent variables.\nIt is important to compute pairwise correlations in a multiple regression analysis.\nRule of Thumb: When independent variables are highly correlated (e.g., \\(|r| &gt; 0.7\\)), it is difficult to determine the separate/marginal effect of each independent variable on the dependent variable.\nEvery attempt should be made to avoid including independent variables that are highly correlated.\nIf the estimated regression equation is to be used only for predictive purposes, multicollinearity is usually not a serious problem"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multicollinearity-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#multicollinearity-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multicollinearity",
    "text": "Multicollinearity\n\nThe coefficients do not measure marginal effects of the predictors (rather combined effects may be measured).\nCoefficient estimates (b’s) are unstable (having “inflated” standard errors — also see Variance Inflation Factor, VIF).\n\nNonsignificant test results for important predictor variables.\nEstimated regression coefficients with an algebraic sign that is the opposite of what is expected from theoretical considerations or prior experience.\nLarge changes in the estimated regression coefficients (slopes) when a predictor variable is added or deleted.\nWide confidence intervals for the regression coefficients representing important predictor variables."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimation-and-prediction-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#estimation-and-prediction-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimation and Prediction",
    "text": "Estimation and Prediction\n\nThe procedures for estimating the mean value of \\(y\\) and predicting an individual value of \\(y\\) in multiple regression are similar to those in simple regression.\nWe substitute the given values of \\(x_1, x_2, ..., x_p\\) into the estimated regression equation and use the corresponding value of \\(\\hat{y}\\) as the point estimate.\nThe interpretations of the Confidence Interval (CI) and Prediction Interval (PI) in multiple regression are similar to those in simple regression:\n\nThe Confidence Interval (CI) estimates the range within which the mean value of the dependent variable is expected to lie, given specific values of the independent variables.\nThe Prediction Interval (PI) estimates the range within which an individual observation of the dependent variable is expected to lie, given specific values of the independent variables.\n\n\n\n\nThe formulas required to develop interval estimates, CI and PI, are beyond the scope of the course and our textbook. Software packages for multiple regression will often provide these interval estimates."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\n\nIn many situations, we need to work with categorical independent variables such as gender (an independent variable with 2 categories: Male, Female), method of payment (an independent variable with 3 categories: Cash, Check, Credit card), etc.\nNeed to code categorical independent variables. For example, if \\(x_2\\) is a gender variable, let \\(x_2 = 1\\) for males and \\(x_2 = 0\\) for females.\nIn this case, \\(x_2\\) is called a dummy or indicator variable, and the category with a 0 (i.e., female) is called the reference category or level."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\n\nGender: F, M\nJob Type: Lawyer, Salesperson, Educator, Government (for salary)\nTool Type: A, B, C (for yields)\nRegion: NE, NW, SE, SW (for sales)\nSeason (for sales)\nTraining Method: Online, Hybrid, In-person (for learning outcome)\nPosition: Manager, AVP, Senior VP, Chair (for retirement age)\nAdvertising Media: Newspaper, Magazine, Spot TV (for sales)\nSmoker: Yes, No (for health risk)\nMethod of Payment: Cash, Check, Credit Card (for credit rating or loan approvals)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-3",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nExample: Johnson Filtration, Inc.\nManagers of Johnson Filtration, Inc. want to predict the repair time necessary for processing its maintenance requests. Repair time is believed to be related to two factors, the number of months since last service and the type of repair problem (mechanical or electrical). Data for a sample of 10 service calls are reported in the table (next slide)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-4",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nExample: Johnson Filtration, Inc\n\n\n\n\n\n\n\n\n\nService Call\nMonths since last service\nType of repair\nRepair time (hours)\n\n\n\n\n1\n2\nElectrical\n2.9\n\n\n2\n6\nMechanical\n3.0\n\n\n3\n8\nElectrical\n4.8\n\n\n4\n3\nMechanical\n1.8\n\n\n5\n2\nElectrical\n2.9\n\n\n6\n7\nElectrical\n4.9\n\n\n7\n9\nMechanical\n4.2\n\n\n8\n8\nMechanical\n4.8\n\n\n9\n4\nElectrical\n4.4\n\n\n10\n6\nElectrical\n4.5"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-5",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nExample: Johnson Filtration, Inc: Now with a dummy or indicator variable.\n\n\n\n\n\n\n\n\n\nService Call\nMonths since last service\nType of repair\nRepair time (hours)\n\n\n\n\n1\n2\n1\n2.9\n\n\n2\n6\n0\n3.0\n\n\n3\n8\n1\n4.8\n\n\n4\n3\n0\n1.8\n\n\n5\n2\n1\n2.9\n\n\n6\n7\n1\n4.9\n\n\n7\n9\n0\n4.2\n\n\n8\n8\n0\n4.8\n\n\n9\n4\n1\n4.4\n\n\n10\n6\n1\n4.5\n\n\n\n0 = Mechanical (reference)\n1 = Electrical"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-6",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nExample: Johnson Filtration, Inc.\nRegression model:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n\\]\nWhere:\n\\(y\\) = Repair time in hours\n\\(x_1\\) = Number of months since last maintenance service\n\\(x_2\\) = 0 if type of repair is mechanical, 1 if the type of repair is electrical ( \\(x_2\\) is a dummy variable)"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-7",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-7",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nExample: Johnson Filtration, Inc."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-8",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-8",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\nInterpretation of regression coefficient \\(\\beta_2\\) of dummy variable \\(x_2\\):\n\\[\nE(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\n\\]\nFor mechanical (reference):\n\\[\nE(y|mechanical) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\cdot 0 = \\beta_0 + \\beta_1 x_1\n\\]\nFor electrical:\n\\[\nE(y|electrical) = \\beta_0 + \\beta_1 x_1 + \\beta_2 \\cdot 1 = (\\beta_0 + \\beta_2) + \\beta_1 x_1\n\\]"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-9",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-9",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables\n\nThe mean repair time is a linear function of \\(x_1\\) for both mechanical and electrical repairs.\nThe slope of both equations is \\(\\beta_1\\), but the y-intercept differs:\n\nFor mechanical repairs: the y-intercept is \\(\\beta_0\\).\nFor electrical repairs: the y-intercept is \\(\\beta_0 + \\beta_2\\).\n\nThe coefficient \\(\\beta_2\\) indicates the difference between the mean repair time for electrical repairs and the mean repair time for mechanical repairs."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpretation-of-beta_2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#interpretation-of-beta_2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of \\(\\beta_2\\)",
    "text": "Interpretation of \\(\\beta_2\\)\n\nIf \\(\\beta_2\\) is positive: The mean repair time for an electrical repair is greater than for a mechanical repair.\nIf \\(\\beta_2\\) is negative: The mean repair time for an electrical repair is less than for a mechanical repair.\nIf \\(\\beta_2 = 0\\): There is no difference in the mean repair time between electrical and mechanical repairs, indicating that the type of repair is not related to repair time.\nIn effect, the use of the dummy variable for type of repair provides two estimated regression equations that can be used to predict the repair time."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-10",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#categorical-independent-variables-10",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Categorical Independent Variables",
    "text": "Categorical Independent Variables"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#more-complex-categorical-variables",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#more-complex-categorical-variables",
    "title": " MGMT 30500: Business Statistics ",
    "section": "More Complex Categorical Variables",
    "text": "More Complex Categorical Variables\n\nA categorical variable with \\(k\\) levels must be modeled using \\(k - 1\\) dummy variables. Care must be taken in defining and interpreting the dummy variables.\n\n\nIn the Johnson Filtration example, a categorical variable (mechanical and electrical) with two levels was represented by a single dummy variable.\nWhen a categorical variable has more than two levels, \\(k - 1\\) dummy variables are required, with each coded as 0 or 1."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-categorical-variable-with-three-levels",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-categorical-variable-with-three-levels",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Categorical Variable with Three Levels",
    "text": "Example: Categorical Variable with Three Levels\n\nSuppose a manufacturer organizes the sales territories into three regions: A, B, and C.\nThe number of copiers sold per week is the dependent variable.\nThe sales region is a categorical variable with three levels: A, B, and C.\n\n\nDummy Variables for Sales Region: We need \\(3 - 1 = 2\\) dummy variables.\n\\[\nx_1 =\n\\begin{cases}\n1 & \\text{if sales region B} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\\[\nx_2 =\n\\begin{cases}\n1 & \\text{if sales region C} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-dummy-variable-coding",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-dummy-variable-coding",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Dummy Variable Coding",
    "text": "Example: Dummy Variable Coding\n\nThe following table shows the coding for the dummy variables \\(x_1\\) and \\(x_2\\) for each sales region.\n\n\n\n\n\nRegion\n\\(x_1\\)\n\\(x_2\\)\n\n\n\n\nA\n0\n0\n\n\nB\n1\n0\n\n\nC\n0\n1\n\n\n\n\n\nObservations corresponding to region A are coded \\(x_1 = 0,  x_2 = 0\\).\nObservations corresponding to region B are coded \\(x_1 = 1,  x_2 = 0\\).\nObservations corresponding to region C are coded \\(x_1 = 0,  x_2 = 1\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-regression-equation-with-dummy-variables",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-regression-equation-with-dummy-variables",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Regression Equation with Dummy Variables",
    "text": "Example: Regression Equation with Dummy Variables\n\n\nThe regression equation for the expected number of units sold is:\n\n\n\\[\nE(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\n\\]\n\n\nTo interpret the parameters \\(\\beta_0,  \\beta_1,  \\beta_2\\), consider the three variations of the regression equation:\nRegion A: \\[\nE(y | \\text{region A}) = \\beta_0 + \\beta_1 (0) + \\beta_2 (0) = \\beta_0\n\\]\nRegion B: \\[\nE(y | \\text{region B}) = \\beta_0 + \\beta_1 (1) + \\beta_2 (0) = \\beta_0 + \\beta_1\n\\]\nRegion C: \\[\nE(y | \\text{region C}) = \\beta_0 + \\beta_1 (0) + \\beta_2 (1) = \\beta_0 + \\beta_2\n\\]\nInterpretation:\n\n\\(\\beta_0\\): Mean or expected value of sales for region A.\n\\(\\beta_1\\): Difference in mean sales between region B and region A.\n\\(\\beta_2\\): Difference in mean sales between region C and region A."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-important-points-on-dummy-variables",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#example-important-points-on-dummy-variables",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Important Points on Dummy Variables",
    "text": "Example: Important Points on Dummy Variables\n\nTwo dummy variables are used because the sales region has three levels.\nThe assignment of \\(x_1 = 0, x_2 = 0\\) for region A is arbitrary.\nAlternative coding choices are possible, which would change the interpretation of \\(\\beta_1\\) and \\(\\beta_2\\).\nKey Point: For a categorical variable with \\(k\\) levels, \\(k - 1\\) dummy variables are required.\n\nFor a fourth region \\(D\\), we would need three dummy variables."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#precision-and-accuracy",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#precision-and-accuracy",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Precision and Accuracy",
    "text": "Precision and Accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision: Refers to the consistency or reliability of the model’s predictions.\nAccuracy: Refers to how close the model’s predictions are to the true values.\n\n\nIn the context of regression:\n\nHigh Precision, Low Accuracy: Predictions are consistent but biased.\nHigh Precision, High Accuracy: Predictions are both consistent and valid.\nLow Precision, Low Accuracy: Predictions are neither consistent nor valid.\nLow Precision, High Accuracy: Predictions are valid on average but have high variability.\n\n\nTo achieve high precision and high accuracy, we need to meet the model assumptions."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model",
    "text": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model\n\nConsider the following two-independent-variable multiple regression equation:\n\\[\nE(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\n\\]\n\n\n\n\nThe graph of this equation is a plane in three-dimensional space. The value of \\(\\epsilon\\) shown is the difference between the actual \\(y\\) value and the expected value of \\(y\\), \\(E(y)\\), when \\(x_1 = x_1^*\\) and \\(x_2 = x_2^*\\)."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model",
    "text": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\cdots + \\beta_p x_p + \\epsilon\n\\]\n\nThe error term \\(\\epsilon\\) is a random variable with \\(E(\\epsilon) = 0\\).\n\n\nImplication: For given values of \\(x_1, x_2, \\ldots, x_p\\), the expected, or average, value of \\(y\\) is given by:\n\n\n\\[\nE(y) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p\n\\]\n\n\nValidation: Residuals vs. Predicted Values Plot or the Standardized Residuals vs. Predicted Values Plot\n\n\nThe variance of \\(\\epsilon\\) is denoted by \\(\\sigma^2\\) and is the same for all values of the independent variables \\(x_1, x_2, \\ldots, x_p\\).\n\n\nImplication: The variance of \\(y\\) about the regression line equals \\(\\sigma^2\\) and is the same for all values of \\(x_1, x_2, \\ldots, x_p\\).\nValidation: Residuals vs. Predicted Values Plot or the Standardized Residuals vs. Predicted Values Plot"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model-2",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#assumptions-about-the-error-term-epsilon-in-the-multiple-regression-model-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model",
    "text": "Assumptions about the Error Term \\(\\epsilon\\) in the Multiple Regression Model\n\nThe values of \\(\\epsilon\\) are independent.\n\nImplication: The value of \\(\\epsilon\\) for a particular set of values for the independent variables is not related to the value of \\(\\epsilon\\) for any other set of values.\nValidation: Standardized Residuals vs. Predicted Values Plot\n\nThe error term \\(\\epsilon\\) is a normally distributed random variable reflecting the deviation between the \\(y\\) value and the expected value of \\(y\\).\n\nImplication: Because \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) are constants for the given values of \\(x_1, x_2, \\ldots, x_p\\), the dependent variable \\(y\\) is also a normally distributed random variable.\nValidation: Normal Probability Plot or Q-Q Plot (Quantile-Quantile Plot) of Residuals."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#residual-analysis-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#residual-analysis-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Analysis",
    "text": "Residual Analysis\n\nFor simple linear regression, the residual plot against \\(\\hat{y}\\) and the residual plot against \\(x\\) provide the same information.\nIn multiple regression analysis, it is preferable to use the residual plot against \\(\\hat{y}\\) to determine if the model assumptions are satisfied."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residuals",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residuals",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\n\nStandardized residuals are frequently used in residual plots for purposes of:\n\nIdentifying outliers (typically, standardized residuals \\(&lt; -2\\) or \\(&gt; +2\\))\nProviding insight about the assumption that the error term \\(\\epsilon\\) has a normal distribution, using the Empirical Rule.\n\nThe computation of standardized residuals in multiple regression analysis is too complex to be done by hand.\n\nExcel’s Regression tool can be used.\n\nNormality of residuals can be checked by the normal probability plot."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residuals-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residuals-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nExample: Butler Trucking Company: Residual output"
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residual-plot-against-haty",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#standardized-residual-plot-against-haty",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residual Plot Against \\(\\hat{y}\\)",
    "text": "Standardized Residual Plot Against \\(\\hat{y}\\)\nExample: Butler Trucking Company\n\n\n\n\n\nThe standardized residual plot does not indicate any abnormalities, and no standard residual is less than -2 or greater than +2.\nNote: the pattern of the standardized residual plot against \\(\\hat{y}\\) is the same as the pattern of the residual plot against \\(\\hat{y}\\). But the standardized residual plot enables us to check for outliers and determine whether the assumption of normality for the regression model (Distribution of \\(y\\)) is reasonable."
  },
  {
    "objectID": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#summary-1",
    "href": "lecture_slides/15_chapter_multiple_regression/15_chapter_multiple_regression.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nMultiple regression analysis enables the inclusion of more independent variables, improving estimates over simple regression.\nThe multiple regression model describes how the dependent variable is related to multiple independent variables.\nLeast Squares Method is used to estimate the coefficients by minimizing the sum of squared errors.\nAdjusted \\(R^2\\) accounts for the number of predictors, making it a more reliable criterion for model selection.\nMulticollinearity can affect the stability of coefficient estimates and make it difficult to isolate the effects of individual predictors.\nDummy variables can be used to incorporate categorical variables in regression models.\nThe overall significance of the model is tested using the F-test, while individual predictors are tested using t-tests."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html",
    "title": " MGMT 30500: Business Statistics ",
    "section": "",
    "text": "Logistic Regression Model."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#overview",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\n\nLogistic Regression Model."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#motivation-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#motivation-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation",
    "text": "Motivation\n\nWhat is the probability of success of a candidate based on the data below?\n\n\n\n\n\n\nadmit\ngre\ngpa\nrank\n\n\n\n\n0\n380\n3.61\n3\n\n\n1\n660\n3.67\n3\n\n\n1\n800\n4.00\n1\n\n\n1\n640\n3.19\n4\n\n\n0\n520\n2.93\n4\n\n\n1\n760\n3.00\n2\n\n\n\n\n\n\ngre: Graduate Record Exam scores\ngpa: Grade Point Average\nrank: prestige of undergraduate institution\nadmit: admission to graduate school"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#review-of-linear-estimation",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#review-of-linear-estimation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Review of Linear Estimation",
    "text": "Review of Linear Estimation\n\n\n\\(Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}Z + \\epsilon\\)\n\n\n\nWe could transform or add variables to achieve model linearity:\n\nTaking logarithms of Y and/or X’s;\nAdding quadratic terms;\nAdding interactions.\n\n\n\n\nThen we run our estimation, check model quality, visualize results, etc."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#review-of-linear-estimation-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#review-of-linear-estimation-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Review of Linear Estimation",
    "text": "Review of Linear Estimation\n\n\n\\(Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}Z + \\epsilon\\)\n\n\nIn all linear models we have covered, the dependent variable (\\(Y\\)) was numerical/continuous.\n\n\nWhat do we do when it is not numerical/continuous?"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#general-linear-model-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#general-linear-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "General Linear Model",
    "text": "General Linear Model\n\nModels in which the parameters \\((\\beta_0, \\beta_1, \\ldots, \\beta_p)\\) all have exponents of one are called linear models.\nA general linear model involving \\(p\\) independent variables (\\(z_i\\)’s) is:\n\n\n\\[\ny = \\beta_0 + \\beta_1 z_1 + \\beta_2 z_2 + \\ldots + \\beta_p z_p + \\epsilon\n\\]\nwhere each independent variable \\(z_i\\) is a (linear or nonlinear) function of \\(x_1, x_2, \\ldots, x_k\\) (the variables for which data have been collected).\n\nHere, \\(y\\) can be a function of the original response variable as well."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#general-linear-model-2",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#general-linear-model-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "General Linear Model",
    "text": "General Linear Model\n\nThe General Linear Model can be used to relates the dependent variable \\(Y\\) to the systematic part of the model (linear predictors) through a link function.\n\nFrom:\n\n\n\\(Y = \\beta_{0} + \\beta_{1}X + \\beta_{2}Z + \\epsilon\\)\n\n\n\n\nTo:\n\n\n\\(P_{i} = P (Y = 1) = \\Lambda(\\beta_{0} + \\beta_{1}X_{1i} + \\beta_{2}Z_{2i} + \\epsilon) = \\Lambda(XB + \\epsilon)\\),\n\n\nwhere \\(\\Lambda\\) (lambda) represents the link function that strictly assumes values between 0 and 1.\n\n\nSource: Wikipedia - Generalized linear model."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#binary-dependent-variable",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#binary-dependent-variable",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Binary Dependent Variable",
    "text": "Binary Dependent Variable\n\nTherefore, the predicted probabilities of a binary dependent variable model can be given by:\n\n\n\\(\\hat{P}_{i} = \\hat{P} (Y = 1) = \\Lambda (\\hat{\\beta}_{0} + \\hat{\\beta}_{1}X_{1i} + \\hat{\\beta}_{2}Z_{2i}) = \\Lambda(\\hat{X}_{i}B)\\) ,\n\n\nwhere \\(\\Lambda(\\hat{X}_{i}B)\\) is the systematic (linear) component of the model."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Understanding the Link Function",
    "text": "Understanding the Link Function\n\n\nHow to solve this problem?"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-2",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Understanding the Link Function",
    "text": "Understanding the Link Function\n\n\nHow to solve this problem?\n\n\nWe need to transform \\(Y\\) (dichotomous) into a continuous variable \\(Y'\\) (\\(-\\infty\\), \\(\\infty\\));\nTo do this, we need a link function that performs this transformation."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#solution",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#solution",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Solution:",
    "text": "Solution:"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-3",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#understanding-the-link-function-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Understanding the Link Function",
    "text": "Understanding the Link Function\n\nLet’s remember the log-level model transformation:\n\n\\[\n\\log(\\hat{Y}_{i}) = \\beta_{0} + \\beta X\n\\]\n\n\n\nA variation of one unit in \\(X_i\\) implies a \\(\\beta\\%\\) variation in \\(Y_i\\);\nThe link function is: \\(F(Y) = \\log(Y)\\);"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-role-of-the-link-function",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-role-of-the-link-function",
    "title": " MGMT 30500: Business Statistics ",
    "section": "The Role of the Link Function",
    "text": "The Role of the Link Function\n\n\n\n\n\nThe logistic function transforms the linear prediction \\(\\beta_0 + \\beta X\\) into a probability that \\(Y = 1\\), denoted as \\(\\Pr(Y = 1|X)\\).\nThis function is sigmoidal (S-shaped), which is why the probability smoothly transitions between 0 and 1.\nThe line \\(E(y^*|X)\\) represents the expected value of the latent variable for a given value of \\(X\\).\n\n\n\n\n\n\\[\nY =\n  \\begin{cases}\n    1       & \\quad \\text{if } y^{*}_{i} &gt; 0 \\\\\n    0  & \\quad \\text{if } y^{*}_{i} \\leq 0\n  \\end{cases}\n\\]\n\n\\(y^{*}\\): is a latent (unobserved) variable, which represents an underlying continuous measure that influences the binary outcome. It drives the observed binary outcome \\(Y\\).\n\n\n\\[\ny^{*}_{i} = \\beta_{0} + \\beta X + \\epsilon\n\\]\n\nThe binary variable \\(Y\\) is determined by a threshold applied to the latent variable \\(y^{*}\\).\nThe plot illustrates the role of the logistic function in converting the continuous latent variable into probabilities that \\(Y = 1\\) or \\(Y = 0\\). As \\(X\\) increases past a certain threshold (denoted \\(\\tau = 0\\) on the graph), the probability that \\(Y = 1\\) rises above 0.5, indicating a higher likelihood of observing \\(Y = 1\\).\nIn summary: The logistic model maps a linear predictor (\\(\\beta_0 + \\beta X\\)) to a binary outcome, using the latent variable \\(y^*\\) to link the continuous world with the binary outcome via a threshold and the logistic function."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#logit-models",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#logit-models",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Logit Models",
    "text": "Logit Models\n\n\nLogistic distribution: In the Logit model, \\(\\epsilon\\) has a logistic distribution, \\(\\mu = 0\\) and variance given by: \\(\\sigma^2(u) = \\pi^2/3\\)\n\n\\[\n\\text{Pr}(y = 1|x) = \\frac{\\exp(\\beta_{0} + \\beta x)}{1 + \\exp(\\beta_{0} + \\beta x)} \\quad \\text{or} \\quad \\frac{e^{\\beta_0 + \\beta_1 x_i}}{1 + e^{\\beta_0 + \\beta_1 x_i}}\n\\]"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#logistic-function-vs-normal-distribution",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#logistic-function-vs-normal-distribution",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Logistic Function vs Normal Distribution",
    "text": "Logistic Function vs Normal Distribution"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-logit-link-function-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-logit-link-function-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "The Logit Link Function",
    "text": "The Logit Link Function"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-logit-link-function-2",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#the-logit-link-function-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "The Logit Link Function",
    "text": "The Logit Link Function\n\n\nThe probability of the event occurring is the cumulative density function of \\(\\epsilon\\) evaluated at values determined by the independent variables"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#estimating-the-event-probability",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#estimating-the-event-probability",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimating the Event Probability",
    "text": "Estimating the Event Probability\n\\[\nP(Y_i = 1) = \\frac{e^{\\beta_0 + \\beta_1 x_i}}{1 + e^{\\beta_0 + \\beta_1 x_i}}\n\\]\nLogit link function\n\\[\n\\hat{Y}_i = \\frac{e^{b_0 + b_1 x_i}}{1 + e^{b_0 + b_1 x_i}}\n\\]\nPrediction equation\nA common estimation method to obtain \\(b_0\\) and \\(b_1\\) is called the Maximum Likelihood Method. It finds the values of \\(\\beta_0\\) and \\(\\beta_1\\) that maximize the probability (or likelihood) of observing the data."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-beta_1-via-lnodds",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-beta_1-via-lnodds",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of \\(\\beta_1\\) via Ln(Odds)",
    "text": "Interpretation of \\(\\beta_1\\) via Ln(Odds)\nDefine the odds for the event:\n\\[\n\\text{Odds}(x) \\equiv \\frac{\\text{Event probability}}{\\text{Non-event probability}} = \\frac{P(Y = 1)}{1 - P(Y = 1)} = e^{\\beta_0 + \\beta_1 x}\n\\]\n\\[\n\\ln(\\text{Odds}(x)) = \\beta_0 + \\beta_1 x\n\\]\n\n\\(b_1\\) is the predicted change in the \\(\\ln(\\text{Odds}(x))\\) per-unit increase in \\(x\\).\n\\(b_1\\) is the predicted difference: \\[\n\\ln(\\text{Odds}(x+1)) - \\ln(\\text{Odds}(x)).\n\\]\nThis relationship is true for all \\(x\\)."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-ebeta_1-via-odds-ratio",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-ebeta_1-via-odds-ratio",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of \\(e^{\\beta_1}\\) via Odds Ratio",
    "text": "Interpretation of \\(e^{\\beta_1}\\) via Odds Ratio\nDefine the odds ratio:\n\\[\n\\text{Odds Ratio}(x) \\equiv \\frac{\\text{Odds}(x+1)}{\\text{Odds}(x)} = e^{\\beta_1}\n\\]\nBy increasing \\(x\\) by one unit, the odds of the event change by a factor of \\(e^{\\beta_1}\\)."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-ebeta_1-continuous-predictor-x",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-ebeta_1-continuous-predictor-x",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of \\(e^{\\beta_1}\\) (Continuous Predictor, \\(x\\))",
    "text": "Interpretation of \\(e^{\\beta_1}\\) (Continuous Predictor, \\(x\\))\n\\[\n\\frac{\\text{Odds}(x+1)}{\\text{Odds}(x)} = e^{\\beta_1}\n\\]\n\nThe odds for the event will change by a factor of \\(e^{\\beta_1}\\) per unit increase in \\(x\\), where \\(\\beta_1\\) is the population slope of \\(x\\).\nIf \\(\\beta_1 = 0\\) or \\(e^{\\beta_1} = 1\\), there is no change in odds.\nIf \\(\\beta_1 &gt; 0\\) or \\(e^{\\beta_1} &gt; 1\\), the odds increase.\nIf \\(\\beta_1 &lt; 0\\) or \\(e^{\\beta_1} &lt; 1\\), the odds decrease.\n\nIf \\(\\beta_1\\) is estimated by \\(b_1\\), then the odds for the event are predicted to change by a factor of \\(e^{b_1}\\) per unit increase in \\(x\\)."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#motivation-binomial-logit-model-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#motivation-binomial-logit-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Binomial Logit Model",
    "text": "Motivation: Binomial Logit Model\nA researcher is interested in how variables such as GRE (Graduate Record Exam scores), GPA (Grade Point Average), and the prestige of the undergraduate institution affect admission into graduate school. The response variable, admit/don’t admit, is binary. What is the probability of success of a candidate based on these data?\n\n\n\n\n\nadmit\ngre\ngpa\nrank\n\n\n\n\n0\n380\n3.61\n3\n\n\n1\n660\n3.67\n3\n\n\n1\n800\n4.00\n1\n\n\n1\n640\n3.19\n4\n\n\n0\n520\n2.93\n4\n\n\n1\n760\n3.00\n2\n\n\n\n\n\n Source: LOGIT REGRESSION - R DATA ANALYSIS EXAMPLES"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#estimating-the-model-r-output",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#estimating-the-model-r-output",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimating the Model: R Output",
    "text": "Estimating the Model: R Output\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-model-summary",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-model-summary",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Output: Model Summary",
    "text": "Output: Model Summary\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations: 400\n\nThe number of data points used in the model (400 observations).\n\nDependent Variable: admit\n\nThe binary outcome variable being predicted (in this case, admission to a school).\n\nType: Generalized linear model\n\nThe model used is a generalized linear model (GLM).\n\nFamily: binomial\n\nThe binomial family is appropriate for binary outcomes.\n\nLink: logit\n\nThe logit link function is used to model the log-odds of the probability of success."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-model-fit-statistics",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-model-fit-statistics",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Output: Model Fit Statistics",
    "text": "Output: Model Fit Statistics\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nχ²(5) = 41.46:\n\nThe chi-squared test statistic for the overall model fit.\n\np = 0.00:\n\nThe p-value for the model, indicating that the model is statistically significant (p &lt; 0.05).\n\nPseudo-R² (Cragg-Uhler) = 0.14:\n\nThe pseudo-R², similar to the R² in linear regression, but interpreted more loosely. Indicates that 14% of the variation in the outcome is explained by the model.\n\nPseudo-R² (McFadden) = 0.08:\n\nAnother form of pseudo-R², typically smaller than Cragg-Uhler’s.\n\nAIC = 470.52:\n\nThe Akaike Information Criterion, a measure of model fit that penalizes for complexity. Lower values indicate a better fit.\n\nBIC = 494.47:\n\nThe Bayesian Information Criterion, similar to AIC but with a stronger penalty for complexity."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-coefficients",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#output-coefficients",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Output: Coefficients",
    "text": "Output: Coefficients\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntercept (Est. = -3.99, p = 0.00):\n\nThe log-odds of being admitted when all predictors are zero. The negative value indicates a low baseline probability of admission.\n\nGRE (Est. = 0.00, p = 0.04):\n\nThe coefficient for GRE is positive and statistically significant (p &lt; 0.05), but the value is very close to zero. This means GRE has a very small positive effect on the log-odds of admission.\n\nGPA (Est. = 0.80, p = 0.02):\n\nA positive coefficient indicates that higher GPA increases the likelihood of admission. It is statistically significant (p &lt; 0.05).\n\nRank 2 (Est. = -0.68, p = 0.03):\n\nBeing in rank 2 (relative to rank 1) decreases the odds of admission. This is statistically significant.\n\nRank 3 (Est. = -1.34, p = 0.00):\n\nA strong negative effect on the log-odds of admission for rank 3. It is statistically significant.\n\nRank 4 (Est. = -1.55, p = 0.00):\n\nBeing in rank 4 strongly reduces the chances of admission, statistically significant with a very low p-value."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-odds-and-probabilities-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-odds-and-probabilities-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "From Log-Odds to Odds and Probabilities",
    "text": "From Log-Odds to Odds and Probabilities\n\nLog-Odds (Linear Equation)\n\nThe log-odds (logit) from a logistic regression model can be written as:\n\\[\n\\text{Log-Odds}(Y = 1) = \\beta_0 + \\beta_1 \\times X_1 + \\beta_2 \\times X_2 + \\dots + \\beta_k \\times X_k\n\\]\nWhere:\n\n\\(\\beta_0\\) is the intercept,\n\\(\\beta_1, \\beta_2, \\dots, \\beta_k\\) are the coefficients for predictors \\(X_1, X_2, \\dots, X_k\\)."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-odds",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-odds",
    "title": " MGMT 30500: Business Statistics ",
    "section": "From Log-Odds to Odds",
    "text": "From Log-Odds to Odds\n\nConverting Log-Odds to Odds\n\nTo convert the log-odds to odds, use the exponential function:\n\\[\n\\text{Odds} = e^{\\text{Log-Odds}} = e^{\\beta_0 + \\beta_1 X_1 + \\dots + \\beta_k X_k}\n\\]\nThe odds represent the ratio of the probability of the event happening to the probability of the event not happening."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-probabilities",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#from-log-odds-to-probabilities",
    "title": " MGMT 30500: Business Statistics ",
    "section": "From Log-Odds to Probabilities",
    "text": "From Log-Odds to Probabilities\n\nComputing the Probability\n\nTo compute the probability from the log-odds, use the logistic function:\n\\[\nP(Y = 1) = \\frac{1}{1 + e^{-\\text{Log-Odds}}}\n\\]\nOr equivalently:\n\\[\nP(Y = 1) = \\frac{e^{\\text{Log-Odds}}}{1 + e^{\\text{Log-Odds}}}\n\\]\nThis formula converts the log-odds into a probability value between 0 and 1."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-log-odds",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-log-odds",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Results: Log-Odds",
    "text": "Interpretation of Results: Log-Odds\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRE: For a one-unit increase in gre, the log-odds of the dependent variable (admit) increase by 0.002;\nGPA: For a one-unit increase in gpa, the log-odds of the DV increase by 0.804;\nRank: In the case of the variable rank, being a graduate of an institution with rank\\(=2\\) changes the log-odds by \\(-0.675\\) compared to an institution with rank\\(=1\\).\n\n\nSource: How do I interpret Odds Ratios in Logistic Regression?"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-odds",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-odds",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Results: Odds",
    "text": "Interpretation of Results: Odds\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRE: For a one-unit increase in GRE, the odds of being admitted increase by a factor of: \\[\ne^{0.002} \\approx 1.002\n\\] This means that for every additional point in GRE, the odds of admission increase by 0.2%.\nGPA: For a one-unit increase in GPA, the odds of being admitted increase by a factor of: \\[\ne^{0.804} \\approx 2.23\n\\] This means that for each additional GPA point, the odds of admission more than double (2.23 times higher).\nRank (Rank 2): For being in Rank 2 compared to Rank 1, the odds of admission decrease by a factor of: \\[\ne^{-0.675} \\approx 0.51\n\\] This means that students from Rank 2 institutions have approximately half the odds of being admitted compared to those from Rank 1 institutions."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-probability",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-probability",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Results: Probability",
    "text": "Interpretation of Results: Probability\n\n\n\n\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\nadmit\n\n\nType\nGeneralized linear model\n\n\nFamily\nbinomial\n\n\nLink\nlogit\n\n\n\n\n \n\n\n\n\n𝛘²(5)\n41.46\n\n\np\n0.00\n\n\nPseudo-R² (Cragg-Uhler)\n0.14\n\n\nPseudo-R² (McFadden)\n0.08\n\n\nAIC\n470.52\n\n\nBIC\n494.47\n\n\n\n\n \n\n\n\n\n\nEst.\nS.E.\nz val.\np\n\n\n\n\n(Intercept)\n-3.99\n1.14\n-3.50\n0.00\n\n\ngre\n0.00\n0.00\n2.07\n0.04\n\n\ngpa\n0.80\n0.33\n2.42\n0.02\n\n\nrank2\n-0.68\n0.32\n-2.13\n0.03\n\n\nrank3\n-1.34\n0.35\n-3.88\n0.00\n\n\nrank4\n-1.55\n0.42\n-3.71\n0.00\n\n\n\n Standard errors: MLE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo convert log-odds into probabilities:\n\\[\nP(Y = 1) = \\frac{1}{1 + e^{-(\\text{log-odds})}}\n\\]\n\nGRE: The change in probability for a one-unit increase in GRE is minimal, given the very small log-odds coefficient (0.002). The probability increases slightly for each GRE point.\nGPA: A one-unit increase in GPA substantially increases the probability of admission, as the log-odds increase by 0.804. This leads to a noticeable jump in the probability of being admitted.\nRank (Rank 2): Being in Rank 2 compared to Rank 1 decreases the probability of admission due to the reduction in log-odds by 0.675. This results in a lower probability of being admitted for Rank 2 graduates."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-predicted-probability",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#interpretation-of-results-predicted-probability",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Results: Predicted Probability",
    "text": "Interpretation of Results: Predicted Probability\n\\[\np = \\frac{\\exp(\\beta x)}{1 + \\exp(\\beta x)}\n\\]"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#example-output-conclusion",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#example-output-conclusion",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example Output: Conclusion",
    "text": "Example Output: Conclusion\n\nThis model indicates that GPA, GRE, and rank significantly influence the likelihood of admission, with lower ranks (higher numerical values) significantly decreasing the chances of admission."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#additional-material",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#additional-material",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Additional Material",
    "text": "Additional Material\n\nBinomial Logistic Regression.\nHow do I interpret Odds Ratios in Logistic Regression?.\nMultinomial Logistic Regression.\nTutorial: Leveraging Labelled Data in R.\nUCLA: Data Analysis Examples.\nIntroduction to Econometrics with R.\nBeyond Multiple Linear Regression: Applied Generalized Linear Models and Multilevel Models in R"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-1",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nWhen to Use Logistic Regression: Use logistic regression when the dependent variable is binary (e.g., success/failure).\nProbabilistic Interpretation: Models the probability of an event occurring based on predictor variables.\nInterpretation of Coefficients: Log-Odds:\n\\[\n\\ln\\left(\\frac{P(Y = 1)}{1 - P(Y = 1)}\\right) = \\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p\n\\]\n\nCoefficients represent the change in log-odds for a one-unit increase in the predictor.\n\nInterpretation of Coefficients: Odds Ratio:\n\\[\n\\text{Odds Ratio} = e^{\\beta_i}\n\\]\n\nAn odds ratio &gt; 1 indicates increased odds of the event occurring with a one-unit increase in \\(X_i\\).\nAn odds ratio &lt; 1 indicates decreased odds."
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-2",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nLog-Odds to Odds:\n\\[\n\\text{Odds} = e^{\\text{Log-Odds}}\n\\]\nOdds to Probability:\n\\[\nP(Y = 1) = \\frac{\\text{Odds}}{1 + \\text{Odds}}\n\\]\nDirect Conversion:\n\\[\nP(Y = 1) = \\frac{e^{\\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p}}{1 + e^{\\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_p X_p}}\n\\]"
  },
  {
    "objectID": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-3",
    "href": "lecture_slides/16_02_logistic_regression/16_02_logistic_regression.html#summary-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nMaximum Likelihood Estimation (MLE): Estimates the parameters that maximize the likelihood of observing the given data.\nModel Assessment: AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion): Lower values indicate a better balance between model fit and complexity.\nThe logistic function ensures predicted probabilities are between 0 and 1.\nCoefficients can be interpreted in terms of log-odds and odds ratios.\nModel fit and predictor significance can be evaluated using pseudo R-squared, AIC, BIC, and statistical tests.\nUnderstanding how to convert between log-odds, odds, and probabilities is crucial for interpretation."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html",
    "title": " MGMT 30500: Business Statistics ",
    "section": "",
    "text": "Philosophies and frameworks\nStatistical Process Control (SPC) with Control Charts for\n\nProcess mean (\\(\\mu\\))\nProcess variability (Range, R)\nProcess proportion of defectives (\\(p\\))\nProcess expected number of defectives (\\(np\\)) in a sample of size \\(n\\)\n\n\n\n\nAcceptance Sampling\nMultiple Sampling Plans"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#overview",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nPhilosophies and frameworks\nStatistical Process Control (SPC) with Control Charts for\n\nProcess mean (\\(\\mu\\))\nProcess variability (Range, R)\nProcess proportion of defectives (\\(p\\))\nProcess expected number of defectives (\\(np\\)) in a sample of size \\(n\\)\n\n\n\n\nAcceptance Sampling\nMultiple Sampling Plans"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality",
    "text": "Quality\nThe American Society for Quality (ASQ) defines quality as:\n\n\n“the characteristics of a product or service that bear on its ability to satisfy stated or implied needs.”\n\n\n\nU.S. Organizations recognize that they must strive for high levels of quality (Car industry in 1980’s).\nIn addition to managerial philosophy, they have increased the emphasis on statistical methods for monitoring and maintaining quality."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#total-quality",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#total-quality",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Total Quality",
    "text": "Total Quality\n\nTotal Quality (TQ) is a people-focused management system that aims at continual increase in customer satisfaction at continually lower real cost.\n\nTQ is a total system approach (not a separate work program) and an integral part of high-level strategy. TQ works horizontally across functions (Concurrent engineering).\nTQ involves all employees, top to bottom, and extends backward and forward to include both the supply and customer chains.\nTQ stresses learning and continuous improvement as keys to organizational success.\n\nLearning -&gt; Improve quality -&gt; Increased productivity -&gt; Lower cost -&gt; Gain in market share -&gt; Stay in business -&gt; Responsibility to society."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Gurus and Philosophies",
    "text": "Quality Gurus and Philosophies\n\n\n\n\n\n\n\n\n\n\n\n\nDr. Walter A. Shewhart\n\n\nDeveloped a set of principles that are the basis for what is known today as process control.\nConstructed a diagram that would now be recognized as a statistical control chart.\nBrought together the disciplines of statistics, engineering, and economics and changed the course of industrial history.\nRecognized as the father of statistical quality control."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Gurus and Philosophies",
    "text": "Quality Gurus and Philosophies\n\n\n\n\n\n\n\n\n\n\n\n\nDr. W. Edwards Deming\n\n\n“Without data, you’re just another person with an opinion.”\n\n\n\n\nHelped educate the Japanese on quality management shortly after World War II.\nFather of modern Total Quality Management: Stressed that the focus on quality must be led by managers.\nDeveloped a list of 14 points he believed represent the key responsibilities of managers.\nJapan named its national quality award the Deming Prize in his honor."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-gurus-and-philosophies-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Gurus and Philosophies",
    "text": "Quality Gurus and Philosophies\n\n\n\n\n\n\n\n\n\n\n\n\nJoseph Juran\n\n\nHelped educate the Japanese on quality management shortly after World War II.\nProposed a simple definition of quality: fitness for use\nHis approach to quality focused on three quality processes: quality planning, quality control, and quality improvement."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-malcolm-baldrige-national-quality-award",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-malcolm-baldrige-national-quality-award",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Frameworks: Malcolm Baldrige National Quality Award",
    "text": "Quality Frameworks: Malcolm Baldrige National Quality Award\n\nEstablished in 1987 and given by the U.S. president to organizations that judged to be outstanding in:\n\nLeadership\nStrategy\nCustomer measurement, analysis, and knowledge management\nWorkforce\nOperations\nResults\n\nThe first awards were presented in 1988.\nThe Award is named for Malcolm Baldrige, who was U.S. Secretary of Commerce from 1981 to 1987.\nThe U.S. Commerce Department’s National Institute of Standards and Technology (NIST) manages the Award."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-iso-9000-series",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-iso-9000-series",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Frameworks: ISO 9000 series",
    "text": "Quality Frameworks: ISO 9000 series\n\nA series of five standards published in 1987 by the International Organization for Standardization in Geneva, Switzerland.\nThe standards describe the need for:\n\nan effective quality system,\nensuring that measuring and testing equipment is calibrated regularly,\nmaintaining an adequate record-keeping system.\n\nISO 9000 registration determines whether a company complies with its own quality system."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-six-sigma",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-six-sigma",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Frameworks: Six Sigma",
    "text": "Quality Frameworks: Six Sigma\n\nEmphasizes the importance of taking measurements on critical quality characteristics.\nFocuses more on the process variation than the process mean.\nA process is a Six Sigma process if its mean is centered, and the distances between the mean and Upper and Lower Specifications are six times the process’s standard deviation (σ).\nSix sigma level of quality means that for every million opportunities, no more than 3.4 defects will occur if the process mean drifts or shifts slightly.\nThe methodology created to reach this quality goal is referred to as Six Sigma."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-six-sigma-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-six-sigma-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Frameworks: Six Sigma",
    "text": "Quality Frameworks: Six Sigma\n\n\n\nSix Sigma aims for defects to be so minimal that only 3.4 per million occur.\nThe target is represented as a bell curve centered at the mean (\\(\\mu\\)) with six standard deviations (\\(\\sigma\\)) between the mean and the specification limits.\n\n\n\\[\n\\text{Defective Rate} = \\text{Total Tail Areas}\n\\] \\[\n\\text{Defective Rate} = \\text{NORM.S.DIST(-6, TRUE) + {1 - NORM.S.DIST(6, TRUE)}} \\approx 0\n\\]\n\nWith Six Sigma, shifts in the process mean are accommodated.\n\nA shift of 1.5\\(\\sigma\\) still maintains low defect rates.\nThis shift leads to a defect rate of approximately 3.4 per million produced."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-service-sector",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-frameworks-service-sector",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Frameworks: Service Sector",
    "text": "Quality Frameworks: Service Sector\n\nQuality control is critical in service businesses (e.g., law firms, hotels, airlines, restaurants, and banks).\nFocus on customer satisfaction and improving the customer experience.\nServices are often intangible, making customer satisfaction subjective and quality measurement challenging."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-terminology-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#quality-terminology-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Quality Terminology",
    "text": "Quality Terminology\n\nQuality assurance refers to the entire system of policies, procedures, and guidelines established by an organization to achieve and maintain quality.\nQuality assurance consists of two functions:\n\nQuality engineering - its objective is to include quality in the design of products and processes and to identify potential quality problems prior to production.\nQuality control consists of making a series of inspections and measurements to determine whether quality standards are being met."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-methods-for-quality-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-methods-for-quality-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Methods for Quality",
    "text": "Statistical Methods for Quality\n\nStatistical Design of Experiments (DOEs): For process and product design.\n\nOne-factor ANOVA.\nFactorial design, etc.\n\nStatistical Process Control (SPC): Monitoring and controlling process for stability over time.\nAcceptance Sampling: Sorting products into conforming or nonconforming products, and lot sentencing."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC)",
    "text": "Statistical Process Control (SPC)\n\nCritical process quality characteristic is inspected and measured.\n\nThere will always be variation in the unit-to-unit measurements.\nTwo types of causes of variation: Common Causes and Assignable Causes.\nCommon causes are allowed for the time being, but assignable causes need to be removed immediately.\nAdjusting a process with only common cause variations will increase process variation. (The Deming’s funnel experiment.)\n\nThe goal of SPC is to detect and eliminate the assignable causes as soon as possible, based on samples from the process over time."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-common-causes",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-common-causes",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC): Common Causes",
    "text": "Statistical Process Control (SPC): Common Causes\n\nRandomly occurring variations in materials, humidity, temperature, etc.\nVariation is natural and unexplained.\nAffecting all units/outputs.\nVariations the producer cannot control (in the short-term).\nProcess is in statistical control and hence, does not need adjustment."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-assignable-causes",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-assignable-causes",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC): Assignable Causes",
    "text": "Statistical Process Control (SPC): Assignable Causes\n\nNon-random and identifiable (significant) variations in output due to tools wearing out, operator error, incorrect machine settings of a few machines, poor quality raw material from certain vendors, etc.\nAffecting certain or individual outputs.\nProcess is out of control, and the producer can and must control (immediately).\nCorrective action should be taken."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-applications",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-applications",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC): Applications",
    "text": "Statistical Process Control (SPC): Applications\n\nTemperature of a die\nWeights of bags of potato chips of a filling process\nWeekly sales figures\nCustomer complaints\nProduct responses\nInventory level\nAbsenteeism\nAccidents\nAccount receivables\nProcess defective rate"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#spc-vs.-hypothesis-testing",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#spc-vs.-hypothesis-testing",
    "title": " MGMT 30500: Business Statistics ",
    "section": "SPC vs. Hypothesis Testing",
    "text": "SPC vs. Hypothesis Testing\nWe use SPC to monitor and control the parameters (mean, variability, or proportion) of a process at each time and over time. Based on hypothesis-testing methodology, we have:\n\\[\nH_0: \\text{Process is in control } (\\mu = \\mu_0, \\text{ or } R = R_0)\n\\]\n\\[\nH_a: \\text{Process is out of control}\n\\]\n\nThe test statistic is the monitoring statistic in SPC: \\(\\overline{x}\\) for process mean, \\(\\overline{p}\\) for process proportion, etc."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-decisions-and-errors",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-decisions-and-errors",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC): Decisions and Errors",
    "text": "Statistical Process Control (SPC): Decisions and Errors\n\n\n\n\n\n\n\n\n\nDecision\nState of Production Process\n\n\n\n\n\n\nH0 True Process in Control\nH0 False Process Out of Control\n\n\nContinue Process\nCorrect decision\nType II error (allowing an out-of-control process to continue)\n\n\nAdjust Process\nType I error (adjusting an in-control process)\nCorrect decision\n\n\n\n\n\nControl the Probability of a False Alarm at \\(\\alpha\\) (the significance level)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-control-charts",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#statistical-process-control-spc-control-charts",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Process Control (SPC): Control Charts",
    "text": "Statistical Process Control (SPC): Control Charts\n\nSPC uses graphical displays known as control charts to monitor a production process (mean, variability, or percent defectives).\n\n\n\n\n\n\n\n\n\n\nThe Center Line (CL) represents what the process parameter value should be when the process is in control (denoted by \\(\\mu_0\\) or \\(R_0\\)).\nThe Upper Control Limit (UCL) and Lower Control Limit (LCL) are the two-sided critical values for the monitoring statistic.\n\nThey are chosen so that when the process is in control, there will be a high probability that the monitoring statistic value will be between the two lines.\nThey are chosen to allow common causes variation in the process and hence in the monitoring statistic.\nValues outside of the control limits provide strong evidence that the process is out of control."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known\nExample: KJW Packaging\nWhen KJW’s cereal carton filling process is in control, the weight of cartons of cereal filled by the process is normally distributed with a mean of 16.05 ounces and a standard deviation of 0.10 ounces.\n\nQuestion: What should be the control limits for \\(\\bar{X}\\) based on a sample of n = 10 observations?"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known\nAssume in-control process mean is \\(\\mu_0\\) and standard deviation is \\(\\sigma\\).\nFor each \\(\\bar{X}_j\\),\n\\[\n  \\text{UCL} = \\mu_0 + 3 \\frac{\\sigma}{\\sqrt{n}}\n  \\]\n\\[\n  \\text{CL} = \\mu_0\n  \\]\n\\[\n  \\text{LCL} = \\mu_0 - 3 \\frac{\\sigma}{\\sqrt{n}}\n  \\]\nwhere \\(\\frac{\\sigma}{\\sqrt{n}}\\) is the standard deviation of \\(\\bar{X}_j\\) with a sample size of n.\n\n3 is the z-multiplier with 99.97% confidence level, or a false alarm rate of \\(\\alpha = 0.27\\%\\)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known\nExample: KJW Packaging\n\\[\n\\mu_0 = 16.05, \\quad \\sigma = 0.10, \\quad n = 10\n\\]\n\\[\n\\frac{\\sigma}{\\sqrt{n}} = \\frac{0.10}{\\sqrt{10}} = 0.032\n\\] \\[\n\\text{UCL} = 16.05 + 3(0.032) = 16.146\n\\]\n\\[\n\\text{CL} = 16.05\n\\] \\[\n\\text{LCL} = 16.05 - 3(0.032) = 15.954\n\\]\nA sample mean based on \\(n\\) observations outside the limits indicates the process mean is out of control."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-4",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-known-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Known\nExample: KJW Packaging\n\n\nNote that the fifth sample shows there is strong evidence that the process is out of control.\nIt indicates that assignable causes of output variation are present and that underfilling is occurring."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\n\nAssume the in-control process mean and standard deviation are unknown.\n\nThey need to be estimated from an in-control process.\n\n\n\nExample: Jensen Computer Supplies Problem\nJCS manufactures 3.5-inch-diameter solid state drives. It wants to develop an X-bar (for process mean) and Range charts (for process variability) based on twenty samples of 5 drives each."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\nExample: Jensen Computer Supplies Problem\nData and Sample Summary Statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample\nObservation 1\nObservation 2\nObservation 3\nObservation 4\nObservation 5\nMean\nRange\n\n\n\n\n1\n3.5056\n3.5086\n3.5144\n3.5009\n3.5030\n3.5065\n0.0135\n\n\n2\n3.4882\n3.5085\n3.4884\n3.5250\n3.5031\n3.5026\n0.0368\n\n\n3\n3.4897\n3.4898\n3.4995\n3.5130\n3.4969\n3.4978\n0.0233\n\n\n…\n…\n…\n…\n…\n…\n…\n…\n\n\n18\n3.4959\n3.4823\n3.4964\n3.5082\n3.4871\n3.4940\n0.0259\n\n\n19\n3.4878\n3.4864\n3.4960\n3.5070\n3.4894\n3.4933\n0.0259\n\n\n20\n3.4969\n3.5144\n3.5053\n3.4985\n3.4885\n3.5007\n0.0259\n\n\n\n\n\n\n\nAverage\n3.4995\n0.0253\n\n\n\n\nTable of sample observations with 5 observations per sample and calculated means and ranges."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\nFor each \\(\\bar{X}_j\\),\n\\[\n\\text{UCL} = \\bar{\\bar{X}} + A_2 \\bar{R}\n\\]\n\\[\n  \\text{CL} = \\bar{\\bar{X}}\n\\]\n\\[\n  \\text{LCL} = \\bar{\\bar{X}} - A_2 \\bar{R}\n\\]\nwhere:\n\n\\(\\bar{\\bar{X}}\\) = overall sample mean (e.g., 3.4995)\n\\(\\bar{R}\\) = average range (e.g., 0.0253)\n\\(A_2\\) = constant depending on \\(n\\) (from the “Factors for Control Charts” table)"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#factors-for-barx-control-chart",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#factors-for-barx-control-chart",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Factors for \\(\\bar{X}\\) Control Chart",
    "text": "Factors for \\(\\bar{X}\\) Control Chart\n\nThe American Society for Testing and Materials Manual on Presentation of Data and Control Chart Analysis provides valuses for \\(d_2\\) for different sample sizes (\\(n\\)) as shown below:\n\n\n\nn\n\\(d_2\\)\n\\(A_2\\)\n\\(d_3\\)\n\\(D_3\\)\n\\(D_4\\)\n\n\n\n\n…\n…\n…\n…\n…\n…\n\n\n5\n2.326\n0.577\n0.864\n0\n2.114\n\n\n6\n2.534\n0.483\n0.848\n0\n2.004\n\n\n7\n2.704\n0.419\n0.833\n0.076\n1.924\n\n\n8\n2.847\n0.373\n0.820\n0.136\n1.864\n\n\n9\n2.970\n0.337\n0.808\n0.184\n1.816\n\n\n10\n3.078\n0.308\n0.797\n0.223\n1.777\n\n\n…\n…\n…\n…\n…\n…\n\n\n\n\n\\(d_2\\) and \\(d_3\\): Constants used for range calculations.\n\\(A_2\\): Used in \\(\\bar{X}\\) charts for control limits.\n\\(D_3\\) and \\(D_4\\): Constants for the R-chart control limits."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#factors-for-barx-control-chart-explanation",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#factors-for-barx-control-chart-explanation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Factors for \\(\\bar{X}\\) Control Chart: Explanation",
    "text": "Factors for \\(\\bar{X}\\) Control Chart: Explanation\n\n\nn: The sample size, or the number of observations within each subgroup.\n\\(d_2\\): A constant used to estimate the mean of the range (\\(\\bar{R}\\)) when the sample size \\(n\\) is known.\n\\(A_2\\): A constant for calculating control limits for the \\(\\bar{X}\\) (X-bar) chart:\n\n\n\\[\n   \\text{UCL} = \\bar{\\bar{X}} + A_2 \\bar{R}\n\\]\nand\n\\[\n   \\text{LCL} = \\bar{\\bar{X}} - A_2 \\bar{R}\n\\]\nwhere \\(\\bar{\\bar{X}}\\) is the mean of sample means, and \\(\\bar{R}\\) is the average range.\n\n\n\\(d_3\\): A constant related to the standard deviation of the range distribution, useful for control limits on range charts.\n\\(D_3\\): Used for the Lower Control Limit (LCL) on the R-chart:\n\n\n\\[\n   \\text{LCL} = D_3 \\times \\bar{R}\n\\]\nFor small sample sizes, \\(D_3\\) is often zero, indicating no lower control limit.\n\n\n\\(D_4\\): Used for the Upper Control Limit (UCL) on the R-chart:\n\n\n\\[\n   \\text{UCL} = D_4 \\times \\bar{R}\n\\]\nAdjusts the upper limit based on sample size, providing a threshold for large ranges."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-4",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\n\nGiven \\(\\bar{X} = 3.4995\\), \\(\\bar{R} = 0.0253\\), \\(n = 5\\),\n\\[\n\\text{UCL} = \\bar{X} + A_2 \\bar{R} = 3.4995 + 0.577(0.0253) = 3.514\n\\]\n\\[\n\\text{CL} = \\bar{X} = 3.4995\n\\]\n\\[\n\\text{LCL} = \\bar{X} - A_2 \\bar{R} = 3.4995 - 0.577(0.0253) = 3.485\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-5",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\n\n\n\n\n\n\n\n\n\n\n\nGraph showing the \\(\\bar{X}\\) chart with control limits at 3.485 and 3.514.\nConclusion: Process mean was in control in each time period."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-6",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#barx-chart-process-mean-and-standard-deviation-unknown-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown",
    "text": "\\(\\bar{X}\\) Chart: Process Mean and Standard Deviation Unknown\n\nIn case the process is out-of-control for some samples, exclude these samples and re-calculate the CL, UCL, and LCL to re-check the process.\nThis approach applies to other types of control charts as well."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(R\\) Chart for Process Variability",
    "text": "\\(R\\) Chart for Process Variability\n\nAssume the in-control process mean and standard deviation are unknown.\nBecause the control limits for the \\(\\bar{X}\\) chart depend on the value of the average range (\\(\\bar{R}\\)), these limits will not have much meaning unless the process range is in control.\nIn practice, the \\(R\\) chart is usually constructed before the \\(\\bar{X}\\) chart.\n\nIf the \\(R\\) chart indicates that the process variability is in control, then the \\(\\bar{R}\\) is used when constructing the \\(\\bar{X}\\) chart.\n\nThe plotting statistic is the Sample Range, \\(R_j\\)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(R\\) Chart for Process Variability",
    "text": "\\(R\\) Chart for Process Variability\nFor each \\(R_j\\),\n\\[\n\\text{UCL} = D_4 \\bar{R}\n\\]\n\\[\n\\text{CL} = \\bar{R}\n\\]\n\\[\n\\text{LCL} = D_3 \\bar{R}\n\\]\nwhere:\n\n\\(\\bar{R}\\) = average range\n\\(D_3, D_4\\) = constants that depend on \\(n\\); refer to the “Factors for Control Charts” table."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(R\\) Chart for Process Variability",
    "text": "\\(R\\) Chart for Process Variability\nExample: Jensen Computer Supplies Problem\nGiven: - \\(\\bar{\\bar{X}} = 3.4995\\), \\(\\bar{R} = 0.0253\\), \\(n = 5\\)\nCalculations:\n\\[\n\\text{UCL} = D_4 \\bar{R} = 2.114(0.0253) = 0.053\n\\]\n\\[\n\\text{CL} = \\bar{R} = 0.0253\n\\]\n\\[\n\\text{LCL} = D_3 \\bar{R} = 0(0.0253) = 0\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-4",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#r-chart-for-process-variability-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(R\\) Chart for Process Variability",
    "text": "\\(R\\) Chart for Process Variability\n\n\n\n\n\n\n\n\n\n\n\nConclusion: The process variability was in control in each sample."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#attributes-control-charts-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#attributes-control-charts-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Attributes Control Charts",
    "text": "Attributes Control Charts\nAn attributes control chart is used if the quality of the output is measured in terms of discrete/counting data such as the number of defective units (\\(X\\)) in a sample, etc.\n\n\\(X\\) is assumed to follow a Binomial distribution with a defective rate (proportion of “success”), \\(p\\). The expected value of \\(X\\) is \\(np\\).\n\\(p\\) Chart: Used to monitor \\(p\\). The monitoring statistic at time \\(j\\) is the sample proportion \\(\\overline{p_j}\\).\n\\(np\\) Chart: Used to monitor the expected number of defectives in a sample of size \\(n\\), \\(np\\). The monitoring statistic at time \\(j\\) is \\(X_j\\)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\) Chart for Process Proportion",
    "text": "\\(p\\) Chart for Process Proportion\nAssume the in-control process proportion is known as \\(p_0\\).\nFor each \\(\\bar{p}_j\\), \\[\n\\text{UCL} = p_0 + 3\\sigma_{\\overline{p}}\n\\]\n\\[\n\\text{CL} = p_0\n\\]\n\\[\n\\text{LCL} = p_0 - 3\\sigma_{\\overline{p}}\n\\]\nwhere\n\\[\n\\sigma_{\\overline{p_j}} \\approx \\sqrt{\\frac{p_0(1 - p_0)}{n}}\n\\]\nassuming \\(np_0 \\geq 5\\) and \\(n(1 - p_0) \\geq 5\\).\n\nNote: If computed LCL is negative, set LCL = 0."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\) Chart for Process Proportion",
    "text": "\\(p\\) Chart for Process Proportion\nAssume the in-control process proportion is unknown.\nExample: Automated mail-sorting process.\nThe automated mail sorting process in a post office scans the zip codes on the letters and diverts them to the proper carrier route. Suppose a sample of 200 letters is selected each hour for 24 hours to establish control limits for a p chart, where \\(p\\) is the proportion of incorrectly sorted letters."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\) Chart for Process Proportion",
    "text": "\\(p\\) Chart for Process Proportion\n\nSample Data\n\n\n\n\n\n\n\n\n\nSample\nSample Size\nNumber of Incorrects (\\(X_j\\))\nSample Proportion (\\(\\bar{P}_j\\))\n\n\n\n\n1\n200\n6\n0.03\n\n\n2\n200\n2\n0.01\n\n\n3\n200\n0\n0.00\n\n\n…\n…\n…\n…\n\n\n22\n200\n2\n0.01\n\n\n23\n200\n0\n0.00\n\n\n24\n200\n2\n0.01\n\n\nTotal\n4800\n104\n\n\n\n\n\nSample: Identifies each sample in the sequence.\nSample Size (\\(n\\)): Total number of observations in each sample. Here, each sample size is 200.\nNumber of Incorrects (\\(X_j\\)): Number of incorrect observations in each sample.\nSample Proportion (\\(\\bar{P}_j\\)): Proportion of incorrect observations in each sample, calculated as \\(X_j / n\\).\n\n\n\\[\n\\text{Estimated overall defective rate} = \\overline{p} = \\frac{\\text{Total number of incorrects}}{\\text{Total sample size}} = \\frac{104}{4800} = 0.0217\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-4",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\) Chart for Process Proportion",
    "text": "\\(p\\) Chart for Process Proportion\nExample: Automated mail-sorting process\n\\(\\overline{p} = 0.0217\\)\n\\[\n\\sigma_{\\overline{p_j}} \\approx \\sqrt{\\frac{\\overline{p}(1 - \\overline{p})}{n}} = \\sqrt{\\frac{0.0217(1 - 0.0217)}{200}} = 0.0103\n\\]\n\nUCL = \\(\\overline{p} + 3\\sigma_{\\overline{p}} = 0.0217 + 3(0.0103) = 0.0526\\)\nCL = \\(\\overline{p} = 0.0217\\)\nLCL = \\(\\overline{p} - 3\\sigma_{\\overline{p}} = 0.0217 - 3(0.0103) = -0.0092 \\rightarrow 0\\)"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-5",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#p-chart-for-process-proportion-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\) Chart for Process Proportion",
    "text": "\\(p\\) Chart for Process Proportion\n\nThe process is out-of-control in Hour 8."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#np-chart-for-expected-number-of-defectives-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#np-chart-for-expected-number-of-defectives-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(np\\) Chart for Expected Number of Defectives",
    "text": "\\(np\\) Chart for Expected Number of Defectives\nAn \\(np\\) chart is a control chart developed for the number of defective items in a sample. In this case, \\(n\\) is the sample size and \\(p\\) is the probability of observing a defective item when the process is in control.\nFor each \\(X_j\\), \\[\nUCL = np + 3\\sqrt{np(1 - \\overline{p})}\n\\]\n\\[\nCL = np\n\\]\n\\[\nLCL = np - 3\\sqrt{np(1 - \\overline{p})}\n\\]\nassuming \\(np \\geq 5\\) and \\(n(1 - \\overline{p}) \\geq 5\\).\nNote: If computed LCL is negative, set LCL = 0."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#interpretation-of-control-charts",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#interpretation-of-control-charts",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Control Charts",
    "text": "Interpretation of Control Charts\n\nThe location and pattern of points in a control chart enable us to determine, with a small probability of error, whether a process is in statistical control.\nA primary indication that a process may be out of control is a data point outside the control limits.\nCertain patterns of points within the control limits can be warning signals of quality problems (Nelson’s 8 rules):\n\nA large number of points on one side of the center line (9 points).\nSix or seven points in a row that indicate either an increasing or decreasing trend."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Acceptance Sampling",
    "text": "Acceptance Sampling\n\nAcceptance sampling is a statistical method that enables us to base the accept-reject decision on the results of inspection of a sample of items from the lot.\nThe items of interest can be incoming shipments of raw materials or purchased parts as well as finished goods from final assembly (End-of-line inspection).\nAcceptance sampling has advantages over 100% inspection including:\n\nUsually less expensive.\nLess product damage due to less handling.\nFewer inspectors required.\nProvides the only approach possible if destructive testing must be used."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-procedure",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-procedure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Acceptance Sampling Procedure",
    "text": "Acceptance Sampling Procedure"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-vs-ht",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-vs-ht",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Acceptance Sampling vs HT",
    "text": "Acceptance Sampling vs HT\n\nAcceptance sampling is based on hypothesis-testing methodology.\n\n\\[\nH_0: \\text{Good-quality lot}\n\\] \\[\nH_a: \\text{Poor-quality lot}\n\\]\n\n\n\n\n\n\n\n\nDecision/State of the Lot\n\\(H_0\\) True Good-Quality Lot\n\\(H_0\\) False Poor-Quality Lot\n\n\nAccept the Lot\nCorrect decision\nType II error (accepting a poor-quality lot)\n\n\nReject the Lot\nType I error (rejecting a good-quality lot)\nCorrect decision"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#recall-binomial-distribution",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#recall-binomial-distribution",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Recall: Binomial Distribution",
    "text": "Recall: Binomial Distribution\n\n\n\n\n\n\n\nBinomial Probability Function for Acceptance Sampling\n\n\n\\[\nX \\sim \\text{Binomial}(n, p)\n\\]\n\\[\nP(X = x) = f(x) = \\frac{n!}{x!(n - x)!} p^x (1 - p)^{(n - x)}\n\\]\n\\[\nP(X \\leq x) = f(0) + \\dots + f(x)\n\\]\nwhere\n\n\\(n\\) = the sample size\n\\(p\\) = the proportion of defective items in the lot\n\\(x\\) = the number of defective items in the sample \\(n\\)\n\\(f(x)\\) = the probability of \\(x\\) defective items in the sample\nExcel Formula: =BINOM.DIST(# successes trials, # trials, probability of success, TRUE)"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-example-kali-inc.",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-example-kali-inc.",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Acceptance Sampling: Example KALI, Inc.",
    "text": "Acceptance Sampling: Example KALI, Inc.\nKALI, Inc. manufactures home appliances that are marketed under a variety of trade names. It uses acceptance sampling plan to monitor the quality of overload protectors. Suppose a sample of 15 items is selected from each incoming shipment or lot and the policy is to accept a lot if at most one defective item is found in the sample.\n\nFind the probability of accepting the lot when the defective rate of the incoming lot is 5%."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-example-kali-inc.-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#acceptance-sampling-example-kali-inc.-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Acceptance Sampling: Example KALI, Inc.",
    "text": "Acceptance Sampling: Example KALI, Inc.\n\nA simple lot acceptance sampling plan is determined by \\((n, c)\\), where \\(n\\) is the sample size, and \\(c\\) is the acceptance number such that if the number of defectives in the sample is less than or equal to \\(c\\) (i.e., \\(X \\leq c\\)), the entire lot is accepted.\n\\[\nn = 15, \\quad c = 1.\n\\]\nWhen the defective rate of the incoming lot is 5%, \\(p = 0.05\\), the probability of accepting the lot is:\n\\[\n\\begin{align*}\nP(\\text{Accept Lot}) & = P(X \\leq 1) = f(0) + f(1)\\\\\n& = \\frac{15!}{0!(15 - 0)!} \\cdot 0.05^0 (1 - 0.05)^{15 - 0} + \\frac{15!}{1!(15 - 1)!} \\cdot 0.05^1 (1 - 0.05)^{15 - 1}\\\\\n& = 0.4633 + 0.3658 \\\\\n& = 0.8290\n\\end{align*}\n\\]\nFor its turn, the the probability of rejecting the lot is:\n\\[\nP(\\text{Reject Lot}) = 1 - 0.8290 = 0.1710\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\nIn formulating a plan, managers must consider the following:\n\nProducer’s risk: Probability of rejecting a lot with an acceptable defective rate.\nConsumer’s risk: Probability of accepting a lot with an unacceptable defective rate."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\n\n\n\n\n\np\nAcceptance Probability\n\n\n\n\n0.00\n1.0000\n\n\n0.05\n0.8290\n\n\n0.10\n0.5490\n\n\n0.15\n0.3186\n\n\n0.20\n0.1671\n\n\n0.25\n0.0802\n\n\n0.30\n0.0353\n\n\n0.35\n0.0142\n\n\n0.40\n0.0052\n\n\n0.45\n0.0017\n\n\n0.50\n0.0005\n\n\n0.55\n0.0001\n\n\n0.60\n0.0000\n\n\n0.65\n0.0000\n\n\n0.70\n0.0000\n\n\n0.75\n0.0000\n\n\n0.80\n0.0000\n\n\n0.85\n0.0000\n\n\n0.90\n0.0000\n\n\n0.95\n0.0000\n\n\n1.00\n0.0000\n\n\n\n\n\nAcceptance Probability Plot\n\n\n\n\n\n\n\n\n\nThe plot presents the probability of accepting the lot (y-axis) based on the percent of defective items in the lot (x-axis)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-2",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\nIn formulating a plan, managers must specify the following:\n\\[\n\\begin{cases}\np_0 = \\text{Maximum acceptable defective rate (under $H_0$)} \\\\\n\\alpha = \\text{The Producer's Risk: }\\text{the probability that a lot with defective rate $p_0$ will be rejected} \\\\\n\\quad\n\\end{cases}\n\\]\n\\[\n\\begin{cases}\np_1 = \\text{Minimum unacceptable defective rate (under $H_a$)} \\\\\n\\beta = \\text{The Consumer's Risk: } \\text{the probability that a lot with defective rate $p_1$ will be accepted} \\\\\n\\quad\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-3",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\nA simple sampling plan with \\((n, c)\\) is selected when it comes close to meeting both the \\(\\alpha\\) and \\(\\beta\\) requirements specified.\nExample: For the purpose of illustration, suppose we require:\n\nIf \\(p_0 = 0.03\\), \\(\\alpha = \\Pr(\\text{Reject the lot} \\mid p_0 = 0.03) = 8\\%\\) (Producer’s Risk)\nIf \\(p_1 = 0.15\\), \\(\\beta = \\Pr(\\text{Accept the lot} \\mid p_1 = 0.15) = 4\\%\\) (Consumer’s Risk)\n\n\n\n\nIs \\((n, c) = (15, 0)\\) an acceptable plan?"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-4",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\n\nIs \\((n, c) = (15, 0)\\) an acceptable plan?\n\nFor \\((n, c) = (15, 0)\\):\n\\[\n\\begin{align*}\n\\text{Producer's risk} & = P(\\text{Reject the lot} \\mid p = 0.03) = P(X &gt; 0 \\mid p = 0.03) \\\\\n& = 1 - P(X \\leq 0 \\mid p = 0.03) \\\\\n&  = 1 - \\text{Bin}(15, 0.03) = 1 - 0.633 = 0.367 \\quad \\text{(Too high)}\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\text{Consumer's risk} & = P(\\text{Accept the lot} \\mid p = 0.15) = P(X \\leq 0 \\mid p = 0.15) \\\\\n& = \\text{Bin}(15, 0.15) = 0.087 \\quad \\text{(Close)}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-5",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#selecting-an-acceptance-sampling-plan-example-kali-inc.-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.",
    "text": "Selecting an Acceptance Sampling Plan: Example KALI, Inc.\n\n\n\nIs \\((n, c) = (15, 0)\\) an acceptable plan?\n\n\n\nProducer’s Risk: The calculated producer’s risk is 36.7%, which is significantly higher than the acceptable level of 8%. This means there is a high probability that a lot with an acceptable defect rate (\\(p_0 = 0.03\\)) will be incorrectly rejected, resulting in an unacceptably high risk for the producer.\nConsumer’s Risk: The consumer’s risk is 8.7%, which is close to the acceptable level of 4%. This indicates that the plan is nearly adequate in terms of the consumer’s risk, but it is still slightly above the target.\nConclusion: The acceptance sampling plan \\((n, c) = (15, 0)\\) is not acceptable because it does not adequately meet the producer’s risk requirement. The producer’s risk is too high, resulting in a high probability of rejecting acceptable lots.\nRecommendation: Adjustments to the sampling plan are needed to better balance both the producer’s and consumer’s risk requirements. This may involve increasing the acceptance number \\(c\\) or adjusting the sample size \\(n\\)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#multiple-sampling-plans-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#multiple-sampling-plans-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Sampling Plans",
    "text": "Multiple Sampling Plans\n\nA multiple sampling plan uses two or more stages of sampling.\nAt each stage, decisions include:\n\nStopping and accepting the lot,\nStopping and rejecting the lot,\nContinuing sampling.\n\nMultiple sampling plans can reduce total sample size while maintaining Type I and Type II error levels."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#multiple-sampling-plans-two-stage-acceptance-sampling-plan-procedure",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#multiple-sampling-plans-two-stage-acceptance-sampling-plan-procedure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiple Sampling Plans: Two Stage Acceptance Sampling Plan Procedure",
    "text": "Multiple Sampling Plans: Two Stage Acceptance Sampling Plan Procedure\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStage 1:\n\nTake an initial sample of \\(n_1\\) items.\nFind the number of defectives \\(x_1\\) in this sample.\nDecision criteria:\n\nIf \\(x_1 \\leq c_1\\): Accept the lot.\nIf \\(x_1 \\geq c_2\\): Reject the lot.\nIf \\(c_1 &lt; x_1 &lt; c_2\\): Proceed to Stage 2.\n\n\nStage 2:\n\nTake an additional sample of \\(n_2\\) items.\nFind the number of defectives \\(x_2\\) in this second sample.\nDecision criteria:\n\nIf \\(x_1 + x_2 \\leq c_3\\): Accept the lot.\nIf \\(x_1 + x_2 &gt; c_3\\): Reject the lot.\n\n\nAcceptance Criteria: The lot is accepted if the defectives in Stage 1 are within \\(c_1\\), or if the combined defectives in both stages are within \\(c_3\\).\nRejection Criteria: The lot is rejected if the defectives in Stage 1 exceed \\(c_2\\), or if the combined defectives in both stages exceed \\(c_3\\)."
  },
  {
    "objectID": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#summary-1",
    "href": "lecture_slides/19_chapter_quality_control/19_chapter_quality_control.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nImportance of Quality Control: Quality control is essential for ensuring products meet customer expectations and can enhance a company’s competitiveness. Tools like control charts, SPC, and acceptance sampling are critical.\nStatistical Process Control (SPC): SPC uses control charts to monitor and maintain process stability by identifying common and assignable causes of variation.\nControl Charts: Used to monitor different quality metrics, such as the mean (\\(\\bar{X}\\)), variability (R-chart), and defect proportion (p-chart). Control limits are established to detect out-of-control conditions and require adjustments only for assignable causes.\nAcceptance Sampling: Provides a practical method for lot quality decisions without inspecting every item. It balances producer’s and consumer’s risks by setting limits on acceptable defect rates.\nMultiple Sampling Plans: These plans, including the two-stage acceptance sampling plan, can minimize sample size while maintaining error controls, improving efficiency over single-stage plans."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html",
    "title": " MGMT 30500: Business Statistics ",
    "section": "",
    "text": "Statistical Inference\nCentral Limit Theorem\nPopulation Mean: \\(\\sigma\\) Known\n\n\n\nPopulation Mean: \\(\\sigma\\) Unknown\nPopulation Proportion\nSample Size Determination"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#overview",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nStatistical Inference\nCentral Limit Theorem\nPopulation Mean: \\(\\sigma\\) Known\n\n\n\nPopulation Mean: \\(\\sigma\\) Unknown\nPopulation Proportion\nSample Size Determination"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#statistical-inference-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#statistical-inference-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\n\n\n\nInterval Estimation\n\n\nConfidence level: 95% \\((1-\\alpha)\\) (Middle area; Confidence level)\nConfidence multipliers\nUpper/lower tail areas\nOne- or 2-sided intervals\nSampling errors and Margin of Error (MOE)\nFind range of all reasonable parameter values\n\n\n \n\n\n\nHypothesis Testing\n\n\nSignificance level: 5% \\((\\alpha)\\) (Tail area(s); Risk)\nCritical values\np-values\nWhich side \\((H_a)\\) depends mostly on data\nStrength of sample evidence against the hypothesized value (via p-value)\nTest a specific hypothesized parameter value"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate and Margin of Error",
    "text": "Interval Estimate and Margin of Error\n\nParameter Estimation\n\nWe are often interested in population parameters.\nSince complete populations are difficult (or impossible) to collect data on, we use sample statistics as point estimates for the unknown population parameters of interest.\nSample statistics vary from sample to sample.\nQuantifying how sample statistics vary provides a way to estimate the margin of error associated with our point estimate.\n\n\nSuppose we randomly sample 1,000 adults from each state in the US. Would you expect the sample means of their heights to be the same, somewhat different, or very different?\n\nNot the same, but only somewhat different."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate and Margin of Error",
    "text": "Interval Estimate and Margin of Error\n\n\n\nA plausible range of values for the population parameter is called a confidence interval.\nUsing only a sample statistic to estimate a parameter is like fishing in a murky lake with a spear, and using a confidence interval is like fishing with a net."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#central-limit-theorem",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#central-limit-theorem",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\n\n\n\nSeeing Theory\nhttps://seeing-theory.brown.edu/\n\n\nBunnies, Dragons and the ‘Normal’ World: Central Limit Theorem | The New York Times\n(video)"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate and Margin of Error",
    "text": "Interval Estimate and Margin of Error\n\nA point estimator cannot be expected to provide the exact value of the population parameter with a given level of confidence; but it is a good starting point to construct an interval estimate.\nAn interval estimate for mean can be computed by adding and subtracting a margin of error (MOE) to the point estimate.\n\\[\n\\text{Point Estimate} \\pm \\text{Margin of Error}\n\\]\nThe purpose of an interval estimate is to provide information about how close the point estimate is to the true value of the unknown population parameter with a certain level of confidence."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-3",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-and-margin-of-error-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate and Margin of Error",
    "text": "Interval Estimate and Margin of Error\n\n\n\n\n\n\n\n\n\n\n\nSimulation\nhttps://rpsychologist.com/d3/ci/"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean",
    "text": "Interval Estimate of a Population Mean\n\nIn order to develop an interval estimate of a population mean, the margin of error (the maximum error due to sampling in order to control the confidence level) must be computed using either:\n\nthe population standard deviation \\(\\sigma\\) (if known), or\nthe sample standard deviation \\(s\\)\n\n\\(\\sigma\\) is rarely known exactly, but often a good estimate can be obtained based on historical data or other information.\nWe refer to such cases as the \\(\\sigma\\) known case."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#margin-of-error-and-the-interval-estimate",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#margin-of-error-and-the-interval-estimate",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Margin of Error and the Interval Estimate",
    "text": "Margin of Error and the Interval Estimate\n\nThe general form of an interval estimate of a population mean is\n\\[\n\\bar{X} \\pm \\text{Margin of Error}\n\\]\nThe Margin of Error (MOE) depends on the sampling distribution (sampling variation) of the point estimate \\(\\bar{X}\\)."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sampling-distribution-of-barx",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sampling-distribution-of-barx",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sampling Distribution of \\(\\bar{X}\\)",
    "text": "Sampling Distribution of \\(\\bar{X}\\)\n\n\nIt will be symmetric if:\n\n\\(n\\) is large (Central Limit Teorem) or\nPopulation of \\(X\\) is normal"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-known-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-known-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Known",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Known\n\nWhen the population standard deviation (\\(\\sigma\\)) is known, we can compute a 95% confidence that the population parameter \\((\\mu)\\) will fall within \\(1.96 \\times \\sigma_{\\bar{X}}\\) from the \\(\\bar{X}\\); i.e., \\(\\mu\\) is in the following interval\n\n\\[\n\\bar{X} \\pm 1.96 \\frac{\\sigma}{\\sqrt{n}}\n\\]\n\nWhen the quantities are replaced by numbers, the interval is called a 95% confidence interval for \\(\\mu\\).\n95% is called the confidence level (\\(= 1- \\alpha\\)). What means that \\(\\alpha = 0.05\\).\n1.96 is referred to as the 95% z-confidence multiplier, denoted by \\(z_{0.025}\\) (or \\(z_{\\alpha/2}\\)). This value represents the number of standard deviations one must move from the mean in both directions to capture the central 95% of the standard normal distribution, thereby defining the 95% confidence interval.\n\\(\\frac{\\sigma}{\\sqrt{n}}\\) Standard Error of the Mean"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#confidence-multipliers",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#confidence-multipliers",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Multipliers",
    "text": "Confidence Multipliers\n\n\nValues of \\(Z_{\\alpha/2}\\) for the Most Commonly Used Confidence Levels\n\n\n\n\nConfidence level\n\\(\\alpha\\)\n\\(\\alpha/2\\)\n\\(Z_{\\alpha/2}\\)\n\n\n\n\n90%\n0.1\n0.05\n1.645\n\n\n95%\n0.05\n0.025\n1.960\n\n\n99%\n0.01\n0.005\n2.576\n\n\n\n\nExcel: \\(= \\text{norm.s.inv}(1 - \\alpha/2)\\)"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown\n\nWhen \\(\\sigma\\) of a normal population is unknown, it is replaced by the sample standard deviation \\(S\\) and the distribution involved will be a \\(t\\)-distribution.\nThe degrees of freedom of the \\(t\\)-distribution is the sample size minus 1 (i.e., \\(n-1\\)).\nThe \\(1 - \\alpha\\) confidence multiplier is \\(t_{\\alpha/2, n-1}\\)\nExcel: = T.INV(1-\\(\\alpha\\)/2, \\(n-1\\))."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown\nThis formula is used to construct a confidence interval for the population mean when the population standard deviation is unknown and the sample size is relatively small.\n\\[\n\\bar{X} \\pm t_{\\alpha/2, n-1} \\times \\frac{s}{\\sqrt{n}}\n\\]\n\n\\(\\bar{X}\\): The sample mean, which serves as the point estimate of the population mean.\n\\(t_{\\alpha/2, n-1}\\): The t-value for the chosen confidence level with \\(n-1\\) degrees of freedom. It represents the number of standard deviations (from the t-distribution) needed to capture the central \\((1-\\alpha)\\%\\) of the data.\n\\(s\\): The sample standard deviation, which measures the amount of variation or dispersion in the sample.\n\\(n\\): The sample size, representing the number of observations in the sample.\n\\(\\frac{s}{\\sqrt{n}}\\): The standard error of the mean, which estimates the standard deviation of the sampling distribution of the sample mean."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example\n\nExample: Credit card debt for the population of US households\n\nThe credit card balances of a sample of 70 households provided a mean credit card debt of $9,312 with a sample standard deviation of $4,007.\n\nLet us provide a 95% confidence interval estimate of the mean credit card debt for the population of US households. We will assume this population to be normally distributed."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example\n\\[\n\\bar{x} \\pm t_{.025, 69} \\times \\frac{s}{\\sqrt{n}}\n\\]\n\\[\n\\bar{x} \\pm =T.INV(1-0.025,69) \\times \\frac{s}{\\sqrt{n}}\n\\]\n\\[\n9,312 \\pm 1.995 \\times \\frac{4007}{\\sqrt{70}} = 9,312 \\pm 955 = (8,357,10,267)\n\\]\nWe are 95% confident that the mean credit card debt for the entire population of U.S. households is between $8,357 and $10,267. The margin of error (maximum error) of the sample mean (as an estimate of the unknown population mean) is $955."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-mean-sigma-unknown---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "Interval Estimate of a Population Mean: \\(\\sigma\\) Unknown - Example\nAdequate Sample Size\nUsually, a sample size of \\(n \\geq 30\\) is adequate when using the expression\n\\[\n\\bar{x} \\pm t_{\\alpha/2} \\frac{s}{\\sqrt{n}}\n\\]\nto develop an interval estimate of a population mean \\(\\mu\\).\n\nIf the population distribution is highly skewed or contains outliers, a sample size of 50 or more is recommended.\nIf the population is not normally distributed but is roughly symmetric, a sample size as small as 15 will suffice.\nIf the population is believed to be at least approximately normal, a sample size of less than 15 can be used."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion",
    "text": "Interval Estimate of a Population Proportion\n\nThe general form of an interval estimate of a population proportion is:\n\n\\[\n\\bar{p} \\pm \\text{Margin of Error}\n\\]\n\nwhere \\(\\bar{p}\\) is the sample proportion of the event of interest."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion",
    "text": "Interval Estimate of a Population Proportion\n\nThe sampling distribution of \\(\\bar{p}\\) plays a key role in computing the margin of error for this interval estimate.\nThe sampling distribution of \\(\\bar{p}\\) can be approximated by a normal distribution whenever \\(np \\geq 5\\) and \\(n(1-p) \\geq 5\\).This is known as success failure condition.\nUnlike the population mean, there is no \\(t\\)-distribution in this case."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-3",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion",
    "text": "Interval Estimate of a Population Proportion"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-4",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion",
    "text": "Interval Estimate of a Population Proportion\nThis formula is used to construct a confidence interval for the population proportion.\n\\[\n\\bar{p} \\pm z_{\\alpha/2} \\times \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\n\\]\n\n\\(\\bar{p}\\): The sample proportion, which serves as the point estimate of the population proportion.\n\\(z_{\\alpha/2}\\): The z-value for the chosen confidence level. It represents the number of standard deviations (from the standard normal distribution) needed to capture the central \\((1-\\alpha)\\%\\) of the data.\n\\(\\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\\): The standard error of the proportion, which estimates the standard deviation of the sampling distribution of the sample proportion.\n\n\\(\\bar{p}(1 - \\bar{p})\\): The variance of the sample proportion.\n\\(n\\): The sample size, representing the number of observations in the sample."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---example",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion - Example",
    "text": "Interval Estimate of a Population Proportion - Example\nExample: Survey of women golfers\n\nA national survey of 900 women golfers was conducted to learn how women golfers view their treatment at golf courses in United States. The survey found that 396 of the women golfers were satisfied with the availability of tee times.\n\nSuppose one wants to develop a 95% confidence interval estimate for the proportion of the population of women golfers satisfied with the availability of tee times."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---example-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion - Example",
    "text": "Interval Estimate of a Population Proportion - Example\n\\[\n\\bar{p} \\pm z_{\\alpha/2} \\times \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\n\\]\nwhere:\n\n\\(n = 900\\),\n\\(\\bar{p} = \\frac{396}{900} = 0.44\\),\n\\(z_{\\alpha/2} = 1.96\\)\n\n\\[\n0.44 \\pm 1.96 \\times \\sqrt{\\frac{0.44(1 - 0.44)}{900}} = 0.44 \\pm 0.0324\n\\]\nSurvey results enable us to state with 95% confidence that between 40.76% and 47.24% of all women golfers are satisfied with the availability of tee times."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---excel-example",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#interval-estimate-of-a-population-proportion---excel-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimate of a Population Proportion - Excel Example",
    "text": "Interval Estimate of a Population Proportion - Excel Example"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Size for an Interval Estimate of a Population Proportion",
    "text": "Sample Size for an Interval Estimate of a Population Proportion\n\nMargin of Error\n\\[\nE = z_{\\alpha/2} \\times \\sqrt{\\frac{\\bar{p}(1-\\bar{p})}{n}}\n\\]\nSolving for the necessary sample size \\(n\\), we get:\n\\[\nn = \\left( \\frac{z_{\\alpha/2}^2 \\times \\bar{p}(1-\\bar{p})}{E^2} \\right)\n\\]\nHowever, \\(\\bar{p}\\) will not be known until after we have selected the sample. We can use the planning value \\(p^*\\) for \\(\\bar{p}\\)."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Size for an Interval Estimate of a Population Proportion",
    "text": "Sample Size for an Interval Estimate of a Population Proportion\n\nNecessary Sample Size:\n\\[\nn = \\left( \\frac{z_{\\alpha/2}^2 \\times p^*(1-p^*)}{E^2} \\right)\n\\]\nThe planning value \\(p^*\\) can be chosen by one of the following procedures:\n\n\nPrevious Studies: Use the sample proportion from a previous study or similar survey as \\(p^*\\).\nPilot Study: Conduct a preliminary survey and use the sample proportion from that study as \\(p^*\\).\nBest Guess: Use a judgment or “best guess” based on available information or expert opinion.\nConservative Approach: If no prior information is available, use \\(p^* = 0.5\\) as it maximizes the sample size and provides the most conservative estimate. This is because the product \\(p^*(1 - p^*)\\) is maximized when \\(p^* = 0.5\\)."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Size for an Interval Estimate of a Population Proportion - Example",
    "text": "Sample Size for an Interval Estimate of a Population Proportion - Example\nExample: Survey of women golfers\n\nA national survey of 900 women golfers was conducted to learn how women golfers view their treatment at golf courses in United States. The survey found that 396 of the women golfers were satisfied with the availability of tee times.\n\nLet us provide a 95% confidence interval estimate of the mean credit card debt for the population of US households. We will assume this population to be normally distributed."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Size for an Interval Estimate of a Population Proportion - Example",
    "text": "Sample Size for an Interval Estimate of a Population Proportion - Example\nCalculations:\n\\[\n  E = z_{\\alpha/2} \\times \\sqrt{\\frac{p^*(1-p^*)}{n}} = .025\n  \\]\nAt 95% confidence \\(z_{0.0125} = 1.96\\). Assume \\(p^* = 0.44\\).\n\\[\n  n = \\left( \\frac{z_{\\alpha/2}^2 \\times p^*(1-p^*)}{E^2} \\right) = \\left( \\frac{(1.96)^2 (0.44)(0.56)}{(0.025)^2} \\right) = 1,514.5\n  \\]\nConclusion: A sample of size 1,515 is needed to reach a desired precision of \\(\\pm\\) 0.025 at 95% confidence."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#sample-size-for-an-interval-estimate-of-a-population-proportion---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Size for an Interval Estimate of a Population Proportion - Example",
    "text": "Sample Size for an Interval Estimate of a Population Proportion - Example\n\nWe used 0.44 as the best estimate of \\(p\\) in the preceding expression.\nIf no information is available about \\(p\\), then 0.5 is often assumed because it provides the highest possible (conservative) sample size.\nIf we had used \\(p = 0.5\\), the recommended \\(n\\) would have been 1537."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#concepts-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#concepts-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Concepts",
    "text": "Concepts\n\n\n\n\n\n\n\n\n\nConcept\nDefinition\nPurpose\n\n\n\n\nStandard Deviation\nA measure of the amount of variation or dispersion in a set of values.\nTo quantify the dispersion of data points around the mean.\n\n\nStandard Error\nThe standard deviation of the sample distribution of a statistic (e.g. the sample mean).\nTo estimate how much sample statistics will vary from the true population parameter.\n\n\nMargin of Error\nA measure of the range within which the true population parameter is expected to lie, with a given level of confidence.\nTo quantify the uncertainty in estimates of population parameters.\n\n\nConfidence Level\nThe probability that if a random sample were taken and a confidence interval calculated, that interval would contain the true population parameter.\nTo indicate the degree of confidence that the interval contains the true parameter.\n\n\nConfidence Interval\nAn interval estimate of a population parameter that provides an estimated range of values which is likely to include an unknown population parameter.\nTo provide a range in which we are fairly confident the true population parameter lies."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-1",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\n\n\n\nCI for \\(\\bar{p}\\)\n\n\nCheck assumptions.\n\nRandomization\nIndependence\nThe sampling distribution of \\(\\bar{p}\\) is approximately normal. (\n\nCheck \\(n\\bar{p} \\geq 5\\) and \\(n(1 - \\bar{p}) \\geq 5\\).\n\n\nCalculate the standard error of \\(\\bar{p}\\): \\[\nse = \\sqrt{\\frac{\\bar{p}(1 - \\bar{p})}{n}}\n\\]\nIdentify \\(z\\) for your specified level of confidence.\nCalculate the interval: \\[\n\\bar{p} \\pm z \\times se\n\\]\n\n\n\nCI for \\(\\mu\\)\n\n\nCheck assumptions.\n\nRandomization\nIndependence\nThe sampling distribution of \\(\\bar{x}\\) is approximately normal.\n\nCheck \\(n \\geq 30\\) or underlying population distribution normal.\n\n\nCalculate the standard error of \\(\\bar{x}\\): \\[\nse = \\frac{s}{\\sqrt{n}}\n\\]\nIdentify \\(t\\) for your specified level of confidence \\[\n(df = n - 1)\n\\]\nCalculate the interval: \\[\n\\bar{x} \\pm t \\times se\n\\]"
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-2",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nStatistical Inference:\nInvolves using sample data to make generalizations about a population. It includes methods like interval estimation and hypothesis testing to draw conclusions with a certain level of confidence.\nCentral Limit Theorem:\nStates that the distribution of the sample mean will approximate a normal distribution as the sample size becomes large, regardless of the population’s distribution. This theorem underpins many inferential statistics techniques.\nInterval Estimation:\nProvides a range of values (confidence interval) for an unknown population parameter, giving an estimate along with an associated margin of error to quantify the uncertainty."
  },
  {
    "objectID": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-3",
    "href": "lecture_slides/08_chapter_interval_estimation/08_chapter_interval_estimation.html#summary-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nPopulation Mean (\\(\\sigma\\) Known):\nWhen the population standard deviation is known, a z-distribution is used to construct confidence intervals for the population mean.\nPopulation Mean (\\(\\sigma\\) Unknown):\nWhen the population standard deviation is unknown, a t-distribution is used. This is common in practical applications where the sample standard deviation serves as an estimate for the population standard deviation.\nPopulation Proportion:\nInvolves estimating the proportion of a population that possesses a certain characteristic. Confidence intervals for population proportions can be calculated using the sample proportion and its standard error.\nSample Size Determination:\nImportant for ensuring that estimates are accurate and reliable. The required sample size can be calculated based on desired margin of error, confidence level, and variability in the population."
  },
  {
    "objectID": "schedule_detailed.html",
    "href": "schedule_detailed.html",
    "title": "Schedule",
    "section": "",
    "text": "Week\nDay\nDate\nTopic\nBook Sections*\nSlides**\nData\nSupplementary Materials\n\n\n\n\n1\nM\nJan 13\nIntro. & Basic Stat. & Prob. Review 01\nSyl., 1.2, 1.4, 1.5\nslides\ndata\n- Video: The NBA Data Scientist- Video: Hans Rosling’s 200 Countries, 200 Years- IMS: Introduction to data\n\n\n1\nW\nJan 15\nBasic Stat. & Prob. Review 02\n1.8, 3.3 (omit Chebyshev), 3.4, 3.5\nslides\ndata\n- Video: Data Basics- Video: Summarizing and Graphing Numerical Data- Video: Exploring Categorical Data- IMS: Exploratory data analysis\n\n\n1\nF\nJan 17\nBasic Stat. & Prob. Review 03\n6.2, t Dist. Supplement\nslides\n.\n- Video: Normal Distribution\n\n\n2\nM\nJan 20\nMARTIN LUTHER KING JR. DAY (No class - TBD)\n—\n.\n.\n.\n\n\n2\nW\nJan 22\nInt. Est. Review\n8.1, 8.2, 8.3, 8.4\nslides\n.\n- Video: Point Estimates- Video: Confidence Intervals- Video: t-distribution\n\n\n2\nF\nJan 24\nHyp. Testing Review 01\n9.1, 9.2, 9.4, 9.5\nslides\n.\n- Video: Hypothesis Testing Fundamentals\n\n\n2\nS\nJan 26\nHomework 01 Due date\nBasic Stat. & Prob. Review\n.\n.\n.\n\n\n3\nM\nJan 27\nHyp. Testing Review 02\n11.1, 11.2\nslides\ndata\n- Nature: Statisticians issue warning over misuse of P-values\n\n\n3\nW\nJan 29\nQuiz 1\nReview Material\n.\n.\n.\n\n\n3\nF\nJan 31\nAnalysis of Variance\n13.1, 13.2\nslides\ndata\n- Video: ANOVA Introduction- Video: Conditions for ANOVA- Video: Multiple comparisons\n\n\n3\nS\nFeb 2\nHomework 02 Due date\nInt. Est. & Hyp. Testing Review\n.\n.\n.\n\n\n4\nM\nFeb 3\nSimple Regression\n14.1\nslides\ndata\n- Video: Line Fitting & Correlation\n\n\n4\nW\nFeb 5\nSimple Regression\n14.2, 14.3\nslides\n.\n.\n\n\n4\nF\nFeb 7\nSimple Regression\n14.4, 14.5\nslides\n.\n.\n\n\n5\nM\nFeb 10\nSimple Regression\n14.6, 14.7\nslides\n.\n.\n\n\n5\nW\nFeb 12\nSimple Regression\n14.8\nslides\n.\n.\n\n\n5\nF\nFeb 14\nSimple Regression\n14.9\nslides\n.\n.\n\n\n5\nS\nFeb 16\nHomework 03 Due date\nSimple Regression\n.\n.\n.\n\n\n6\nM\nFeb 17\nMidterm 1 Review\nAnalysis of Variance & Simple Regression\n.\n.\n.\n\n\n6\nW\nFeb 19\nMidterm 1 (TBD pm–TBD pm, TBD in class?)\nAnalysis of Variance & Simple Regression\n.\n.\n.\n\n\n6\nF\nFeb 21\nMultiple Regression\n15.1, 15.2\nslides\ndata\n- Video: Introduction to Multiple Regression\n\n\n7\nM\nFeb 24\nMultiple Regression\n15.3\nslides\n.\n.\n\n\n7\nW\nFeb 26\nMultiple Regression\n15.4\nslides\n.\n.\n\n\n7\nF\nFeb 28\nMultiple Regression\n15.5\nslides\n.\n.\n\n\n8\nM\nMar 2\nMultiple Regression\n15.6\nslides\n.\n.\n\n\n8\nW\nMar 5\nMultiple Regression\n15.7\nslides\n.\n.\n\n\n8\nF\nMar 7\nQuiz 2\nMultiple Regression\n.\n.\n.\n\n\n8\nS\nMar 9\nHomework 04 Due date\nMultiple Regression, Pt. 1\n.\n.\n.\n\n\n9\nM\nMar 10\nModel Building\n16.1\nslides\ndata\n- Video: Model Selection in Multiple Regression\n\n\n9\nW\nMar 12\nModel Building\n16.2\nslides\n.\n.\n\n\n9\nF\nMar 14\nModel Building\n16.3, 16.4\nslides\n.\n.\n\n\n10\nM\nMar 17\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nW\nMar 19\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nF\nMar 21\nSpring Break (No class)\n—\n.\n.\n.\n\n\n10\nS\nMar 23\nHomework 05 Due date\nMultiple Regression, Pt. 2\n.\n.\n.\n\n\n11\nM\nMar 24\nLogistic Regression\nSupplement in Brightspace & Slides\nslides\n.\n- Video: Basic Ideas of Logistic Regression\n\n\n11\nW\nMar 26\nLogistic Regression\nSupplement in Brightspace & Slides\nslides\n.\n.\n\n\n11\nF\nMar 28\nLogistic Regression\nSupplement in Brightspace & Slides\nslides\n.\n.\n\n\n11\nS\nMar 30\nHomework 06 Due date\nLogistic Regression\n.\n.\n.\n\n\n12\nM\nMar 31\nMidterm 2 Review\nMult. Regr., Model Bldg., Log. Regr.\n.\n.\n.\n\n\n12\nW\nApr 2\nMidterm 2 (TBD pm–TBD pm, TBD in class?)\nMult. Regr., Model Bldg., Log. Regr.\n.\n.\n.\n\n\n12\nF\nApr 4\nTime Series\n17.1, 17.2\nslides\ndata\nVideo: Time Series Forecast Using Forecast Sheet in Excel\n\n\n13\nM\nApr 7\nTime Series\n17.3\nslides\n.\n.\n\n\n13\nW\nApr 9\nTime Series\n17.4\nslides\n.\n.\n\n\n13\nF\nApr 11\nTime Series\n17.5, 17.6\nslides\n.\n.\n\n\n13\nS\nApr 13\nHomework 07 Due date\nTime Series\n.\n.\n.\n\n\n14\nM\nApr 14\nQuiz 3\nTime Series\n.\n.\n.\n\n\n14\nW\nApr 16\nQuality Control\n19.1\nslides\n.\n.\n\n\n14\nF\nApr 18\nQuality Control\n19.2, 19.3\nslides\n.\n.\n\n\n15\nM\nApr 21\nDecision Analysis\n20.1\nslides\n.\n- Video: Bayes theorem\n\n\n15\nW\nApr 23\nDecision Analysis\n20.2\nslides\n.\n.\n\n\n15\nF\nApr 25\nDecision Analysis\n20.3, 20.4\nslides\n.\n.\n\n\n15\nS\nApr 27\nHomework 08 Due date\nQuality Control & Decision Analysis\n.\n.\n.\n\n\n16\nM\nApr 28\nFinal Exam Review\nCumulative\n.\n.\n.\n\n\n16\nW\nApr 30\nFinal Exam Review\nCumulative\n.\n.\n.\n\n\n16\nF\nMay 2\nFinal Exam Preparation\nNo class\n.\n.\n.\n\n\n17\n—\nTBD\nFinal Exam (TBD pm–TBD pm, TBD)\nCumulative\n.\n.\n.\n\n\n\n\n*Section Numbers refer to sections in the course textbook.\n** Course material adapted from the textbook and previous course editions to better fit our curriculum. Thanks to Professor Jen Tang for guidance and for generously sharing the materials."
  },
  {
    "objectID": "material.html",
    "href": "material.html",
    "title": "Materials",
    "section": "",
    "text": "Topic\nBook Sections*\nSlides***\nData\nSupplementary Materials\n\n\n\n\nBasic Stat. & Prob. Rvw. 01\n1.2, 1.4, 1.5\nslidespodcast**video**\ndata\n- Video: The NBA Data Scientist- Video: Hans Rosling’s 200 Countries, 200 Years\n\n\nBasic Stat. & Prob. Rvw. 02\n1.8, 3.3 (omit Chebyshev), 3.4, 3.5\nslidespodcast**video**\ndata\n- Video: Data Basics: Observations, Variable, and Data Matrices- Video: Summarizing and Graphing Numerical Data- Video: Exploring Categorical Data\n\n\nBasic Stat. & Prob. Rvw. 03\n3.5, 6.2, t Dist. Supplement\nslidespodcast**video**\n.\n- Video: Normal Distribution\n\n\nInt. Est. Rvw.\n8.1, 8.2, 8.3, 8.4\nslidespodcast**video**\n.\n- Video: Point Estimates and Sampling Variability- Video: Confidence Intervals- Video: Inferences for Proportions- Video: t-distribution- Video: Inference for one mean\n\n\nHyp. Testing Rvw. 01\n9.1, 9.2, 9.4, 9.5\nslidespodcast**video**\n.\n- Video: Hypothesis Testing Fundamentals\n\n\nHyp. Testing Rvw. 02\n11.1, 11.2\nslidespodcast**video**\ndata\n- Nature: Statisticians issue warning over misuse of P-values\n\n\nAnalysis of Variance\n13.1, 13.2\nslidespodcast**video**\ndata\n- Video: ANOVA Introduction- Video: Conditions for ANOVA- Video: Multiple comparisons\n\n\nSimple Regression\n14.1, 14.2, 14.3, 14.4, 14.5, 14.6, 14.7, 14.8, 14.9\nslidespodcast**video**\ndata\n- Video: Line Fitting, Residuals, and Correlation- Video: Fitting a Line with Least Squares Regression- Video: Least Squares Regression- Video: Types of Outliers in Linear Regression- Video: Inference for Linear Regression\n\n\nMultiple Regression\n15.1, 15.2, 15.3, 15.4, 15.5, 15.6, 15.7, 15.8\nslidespodcast**video**\ndata\n- Video: Introduction to Multiple Regression- Video: Model Selection in Multiple Regression- Video: Checking Multiple Regression Diagnostics Using Graphs\n\n\nModel Building\n16.1, 16.2, 16.3, 16.4\nslidespodcast**video**\ndata\n- Video: Model Selection in Multiple Regression\n\n\nLogistic Regression\nSupplement in Brightspace and Slides\nslidespodcast**video**\n.\n- Video: Basic Ideas of Logistic Regression\n\n\nTime Series\n17.1, 17.2, 17.3, 17.4, 17.5, 17.6\nslidespodcast**video**\ndata\n- Video: Time Series Forecast Using Forecast Sheet in Excel\n\n\nQuality Control\n19.1, 19.2, 19.3\nslidespodcast**video**\n.\n.\n\n\nDecision Analysis\n20.1, 20.2, 20.3, 20.4\nslidespodcast**video**\n.\n- Video: Bayes theorem, the geometry of changing beliefs\n\n\n\n\n\n* Section Numbers refer to sections in the course textbook.\n** This material was generated with Google NotebookLM based on the slides prepared for the course.\n*** Course material adapted from the textbook and previous course editions to better fit our curriculum. Thanks to Professor Jen Tang for guidance and for generously sharing the materials.",
    "crumbs": [
      "Material"
    ]
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#overview",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nIntroductions\nCourse Overview and Logistics\nMotivation\nCourse Objectives\n\nUnderstand basic statistical concepts\nApply statistical methods to business problems\n\n\n\n\nKey Topics\n\nDescriptive Statistics\nInferential Statistics\nExcel4stats"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructor",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructor",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Instructor",
    "text": "Instructor\n\n\n\n\n\n\n\n\n\n\n\ndcordeir@purdue.edu\nhttps://davi-moreira.github.io/\n\n\nClinical Assistant Professor in the Management Department at Purdue University;\n\n\n\nMy academic work addresses Political Communication, Data Science, Text as Data, Artificial Intelligence, and Comparative Politics.\n\n\n\nM&E Specialist consultant - World Bank (Brazil, Mozambique, Angola, and DRC)"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructors-passions",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructors-passions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Instructor’s Passions",
    "text": "Instructor’s Passions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Most Exciting Game in History - Video"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructors-passions-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#instructors-passions-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Instructor’s Passions",
    "text": "Instructor’s Passions\n\n\nNYT - How John Travolta Became the Star of Carnival-Video."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#students",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#students",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Students",
    "text": "Students\n\n\nIt is your turn! - 5 minutes\n\n\n\nIntroduce yourself to the colleague on your left or right. Then ask them to rate, on a scale from 1 (not at all) to 5 (a lot), how much they like statistics."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#course-overview-and-logistics-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#course-overview-and-logistics-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Course Overview and Logistics",
    "text": "Course Overview and Logistics\n\nMaterials:\n\nBrightspace\nCourse Webpage\n\nSyllabus\nSlides\nPodcast\nVideos\nSupplementary Material\nSchedule"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#survey-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#survey-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Survey",
    "text": "Survey\n\n\nAttendance and Participation10 min"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#what-is-statistics-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#what-is-statistics-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What is Statistics?",
    "text": "What is Statistics?\n\n\n\n\n\n\n\n“Without data, you’re just another person with an opinion.” – W. Edwards Deming\n\n\n\n\n\n\n\n\n\n\n\nW. Edwards Deming\nWiki"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#what-is-statistics-2",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#what-is-statistics-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What is Statistics?",
    "text": "What is Statistics?\n\nStatistics can be defined as the science of collecting, analyzing, interpreting, presenting, and organizing data to make informed decisions."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#where-is-statistics-applied-in-business-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#where-is-statistics-applied-in-business-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Where is statistics applied in Business?",
    "text": "Where is statistics applied in Business?\n\nAccounting\n\nTo compare actual financial performance with budgeted amounts, identifying areas of inefficiency or unexpected costs.\n\nEconomics\n\nTo analyze employment trends, wage distributions, and the impact of income on business opportunities, helping managers make informed decisions.\n\nFinance\n\nRisk analysts to assess the probability of default on loans or bonds, aiding in the pricing of financial instruments and risk management strategies."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-sources-and-scales-of-measurement",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-sources-and-scales-of-measurement",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Data Sources and Scales of Measurement",
    "text": "Data Sources and Scales of Measurement\n\n\nElements are the entities on which data are collected.\nA variable is a characteristic of interest for the elements.\nThe set of measurements obtained for a particular element is called an observation.\nA data set with \\(n\\) elements contains \\(n\\) observations.\nThe total number of data values in a complete data set is the number of elements multiplied by the number of variables."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-types",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-types",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Data Types",
    "text": "Data Types\n\n\nCategorical Data\n\nLabels or names used to identify an attribute of each element\nOften referred to as qualitative data\nUse either the nominal or ordinal scale of measurement\nCan be either numeric or nonnumeric\nAppropriate statistical analysis is rather limited\n\n\nQuantitative Data\n\nQuantitative data indicate how many or how much:\n-  discrete, if measuring how many\n- continuous, if measuring how much\nQuantitative data are always numeric.\nOrdinary arithmetic operations (+, -, ×, ÷) are meaningful for quantitative data"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-types-examples",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-types-examples",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Data Types: Examples",
    "text": "Data Types: Examples\n\n\n\n\n\n\n\n\n\n\nCategorical: Nominal\nCategorical: Ordinal\nQuantitative: Continuous or Discrete\n\n\n\n\nVehicle Type\nSatisfaction Level\nTemperature\n\n\nBeverage\nEducation Level\nNumber of Transactions\n\n\nMusic Genre\nCustomer Feedback\nRevenue\n\n\nNationality\nJob Position\nProduct Weight\n\n\nRelationship Status\nMilitary Rank\nDistance Traveled\n\n\nOperating System\nPriority Level\nMarket Share\n\n\n\n\n\n\nCategorical: Nominal refers to variables that categorize data without a specific order.\nCategorical: Ordinal refers to variables that categorize data with a meaningful order but without a consistent difference between categories.\nQuantitative: Continuous or Discrete refers to variables that are numerical, where discrete variables are countable and continuous variables can take any value within a range."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#scales-of-measurement",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#scales-of-measurement",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scales of Measurement",
    "text": "Scales of Measurement"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#scales-of-measurement-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#scales-of-measurement-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scales of Measurement",
    "text": "Scales of Measurement\n\n\n\n\nCategorical Data\n\nDefinition: Data that can be sorted into categories or groups.\nSubcategories:\n\nNumeric: Categorical data represented by numbers, but the numbers do not have inherent numerical value.\n\nNominal: Categories that have no inherent order. Examples include gender, type of car, and nationality.\nOrdinal: Categories that have a specific order or ranking. Examples include satisfaction levels (e.g., satisfied, neutral, dissatisfied) and education levels (e.g., high school, bachelor’s, master’s).\n\nNon-numeric: Categorical data not represented by numbers.\n\nNominal: Similar to numeric nominal data but represented with non-numeric labels. Examples include types of cuisine (e.g., Italian, Chinese, Indian).\nOrdinal: Similar to numeric ordinal data but represented with non-numeric labels. Examples include rankings such as job positions (e.g., intern, junior, senior).\n\n\n\n\n\n\n\nQuantitative Data\n\nDefinition: Data that can be measured and expressed numerically.\nSubcategories:\n\nNumeric: Quantitative data always represented by numbers.\n\nInterval: Numerical data with meaningful differences between values but no true zero point. Examples include temperature in Celsius or Fahrenheit.\nRatio: Numerical data with meaningful differences between values and a true zero point. Examples include height, weight, and sales figures."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#cross-sectional-data-time-series",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#cross-sectional-data-time-series",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Cross-Sectional Data: Time Series",
    "text": "Cross-Sectional Data: Time Series"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Study Design",
    "text": "Study Design\n\n\nObservational\nIn observational studies, no attempt is made to control or influence the variables of interest. A survey is a good example.\n  \n\nAn example of an observational study is researchers observing a randomly selected group of customers that enter a Walmart Supercenter to collect data on variables such as time spent in the store, gender of the customer, and the amount spent.\n\n\nExperimental (Chapter 13)\nIn experimental studies, the variable of interest is first identified. Then, the values or levels (categories) of the variable are identified and controlled so that data from the experimental units (subjects) can be obtained about how they influence the variable of interest. Can have multiple variables.\n\nThe largest experimental study ever conducted is believed to be the 1954 Public Health Service experiment for the Salk polio vaccine. Nearly two million U.S. children (grades 1 through 3) were selected."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-random-assignment-vs.-random-sampling",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-random-assignment-vs.-random-sampling",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Study Design: Random Assignment vs. Random Sampling",
    "text": "Study Design: Random Assignment vs. Random Sampling"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-2",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#study-design-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Study Design",
    "text": "Study Design"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summarizing and Presenting Data",
    "text": "Summarizing and Presenting Data\n\n\n\n\nJune 9th Apple CEO Steve Jobs - Post"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summarizing and Presenting Data",
    "text": "Summarizing and Presenting Data\n\n\n\nProblems with pie charts - Post"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data-2",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summarizing-and-presenting-data-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summarizing and Presenting Data",
    "text": "Summarizing and Presenting Data"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#example-hudson-auto-repair",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#example-hudson-auto-repair",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Hudson Auto Repair",
    "text": "Example: Hudson Auto Repair\nThe manager of Hudson Auto would like to have a better understanding of the cost of parts used in the engine tune-ups performed in her shop. She examines 50 customer invoices for tune-ups. The costs of parts, rounded to the nearest dollar, are listed on the next slide."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#tabular-summary-frequency-and-percent-frequency---example",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#tabular-summary-frequency-and-percent-frequency---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tabular Summary: Frequency and Percent Frequency - Example",
    "text": "Tabular Summary: Frequency and Percent Frequency - Example\n\n\n\n\nParts Cost ($)\nFrequency\nPercent Frequency\n\n\n\n\n50 to 59\n2\n4%\n\n\n60 to 69\n13\n26%\n\n\n70 to 79\n16\n32%\n\n\n80 to 89\n7\n14%\n\n\n90 to 99\n7\n14%\n\n\n100 to 109\n5\n10%\n\n\nTOTAL\n50\n100%"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Graphical Summary: Bar Chart or Histogram - Example",
    "text": "Graphical Summary: Bar Chart or Histogram - Example\n\n\n\n\n\n\nhudson_auto_repair.xlsx\n\n\nFile -&gt; Options -&gt; Add-ins -&gt; Select Analysis ToolPak and Analysis ToolPak-VBA (also select StatTools 7.5, if available) -&gt; Go -&gt; Data -&gt; Data Analysis (to conduct analyses)"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Graphical Summary: Bar Chart or Histogram - Example",
    "text": "Graphical Summary: Bar Chart or Histogram - Example\n \n\n\n\nOpen Data Analysis Add-in\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelect Histogram"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example-2",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#graphical-summary-bar-chart-or-histogram---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Graphical Summary: Bar Chart or Histogram - Example",
    "text": "Graphical Summary: Bar Chart or Histogram - Example\n\n\n\nInput the ranges (data, bin limits, output cell)\n\n\n\n\n\n\n\n\n\n\n\n\n\nResult"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Numerical Descriptive Statistics",
    "text": "Numerical Descriptive Statistics\n\n\nThe most common numerical descriptive statistic is the mean (or average).\nThe mean demonstrates a measure of the central tendency, central location, or center of mass of the data for a variable.\nHudson’s mean cost of parts, based on the 50 tune-ups studied, is $79 (found by summing up the 50 cost values and then dividing by 50).\nThere are other descriptive statistics (next chapter)."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics---example",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Numerical Descriptive Statistics - Example",
    "text": "Numerical Descriptive Statistics - Example\n\n\n\nOpen Data Analysis Add-in and select the Descriptive Statistics analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nInput the ranges (data, bin limits, output cell) and options"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics---example-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#numerical-descriptive-statistics---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Numerical Descriptive Statistics - Example",
    "text": "Numerical Descriptive Statistics - Example\n\n\n\nResult\n\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s check the result\n\n\n\n\n\n\n\n\n\n\n\nFor percentiles: = percentile.exc(Data Array, %)"
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#statistical-inference-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#statistical-inference-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation: the set of all elements of interest in a particular study.\nSample: a subset of the population.\nDescriptive Statistics: Tabular, graphical, and numerical summaries of data.\nInferential Statistics: The process of using data from the sample to make estimates or test hypotheses about the characteristics of a population\nEstimation: Using sample data to approximate population parameters.\nHypotheses Testing: Determining if there is enough evidence in a sample to support a claim about a population.\nPrediction: Forecasting future events based on historical data."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-science-big-data-and-data-mining---definitions",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#data-science-big-data-and-data-mining---definitions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Data Science, Big Data, and Data Mining - Definitions",
    "text": "Data Science, Big Data, and Data Mining - Definitions\n\nData Science:\n\nThe interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data.\n\nBig Data:\n\nExtremely large datasets that may be analyzed computationally to reveal patterns, trends, and associations, especially relating to human behavior and interactions.\n\nData Mining:\n\nThe practice of examining large databases to generate new information, involving methods at the intersection of machine learning, statistics, and database systems."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#how-data-science-big-data-and-data-mining-are-used",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#how-data-science-big-data-and-data-mining-are-used",
    "title": " MGMT 30500: Business Statistics ",
    "section": "How Data Science, Big Data, and Data Mining are Used",
    "text": "How Data Science, Big Data, and Data Mining are Used\n\n\nData Science:\n\nPersonalizing marketing efforts by analyzing customer data to predict preferences and buying behavior.\nOptimizing supply chain management through predictive analytics.\n\nBig Data:\n\nAnalyzing customer feedback and social media interactions to improve customer service and develop new products.\nEnhancing risk management in financial institutions by monitoring transaction patterns and detecting fraudulent activities.\n\nData Mining:\n\nIdentifying potential leads and sales opportunities by analyzing past sales data and customer demographics.\nEnhancing customer retention by understanding churn patterns and developing targeted retention strategies."
  },
  {
    "objectID": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summary-1",
    "href": "lecture_slides/01_chapter_data_statistics/01_chapter_data_statistics.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nCourse Overview:\n\nMaterials and resources available on Brightspace and the course webpage.\nYou are welcome to join virtual office hours!\nIf you need an individual appointment, e-mail me!\n\nKey Concepts:\n\nImportance of statistics in business decision-making.\nStudy Design.\nData summary and visualization good practices.\nDistinction between Descriptive and Inferential Statistics.\nData Science, Big Data, and Data Mining"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#overview",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nDescriptive Statistics\nMeasures of Central Location and Variability\nDistribution Shape\n\nSkewness\nSymmetry\n\nRelative Location and z-Scores\n\nCalculation and Interpretation\nExamples\n\nEmpirical Rule\n\n68-95-99.7 Rule\nDetecting Outliers\n\n\n\n\nFive-Number Summaries and Boxplots\nMeasures of Association Between Two Variables\n\nCovariance\nCorrelation"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#central-location",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#central-location",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Central Location",
    "text": "Central Location\n\n\n\n\n\n\n\n\nStatistic\nDefinition\nFormula\n\n\n\n\nMean\nThe average of all values of a variable\n\\(\\bar{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}\\)\n\n\nMode\nThe most frequently occurring value\n\n\n\nkth Percentile\nRoughly k% of the data is at or below this value\n\n\n\nQuartile\nThe first, second, and third quartiles are 25th, 50th, and 75th percentiles\n\\(Q1, Q2, Q3\\)\n\n\nMedian\nThe “middle” observation when the data are listed from smallest to largest\n\\(Q2\\)\n\n\nMaximum\nThe largest value\n\n\n\nMinimum\nThe smallest value\n\n\n\nMidrange\nThe middle of the maximum and minimum\n\\(\\frac{Max + Min}{2}\\)\n\n\nMidhinge\nThe middle of the first and third quartiles\n\\(\\frac{Q3 + Q1}{2}\\)"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#variability-sampling-variation",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#variability-sampling-variation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Variability (Sampling Variation)",
    "text": "Variability (Sampling Variation)\n\nSample Variance: “Average” squared deviation of observations from the mean of all observations (\\(n-1\\) is called the degrees of freedom, df):\n\\[\nS^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1}\n\\]\n\nWhy do we compute the sample variance using \\(n-1\\) instead of \\(n\\)?\nTo not underestimate the True Population Variance \\(\\sigma^2\\)\nWhat is an unbiased estimator? Video\nVideo and Simulation\n\nSample Standard Deviation:\n\\[\nS = \\sqrt{S^2}\n\\]\nRange = Maximum – Minimum.\nInterquartile Range (IQR) = 3rd Quartile – 1st Quartile\n(Range of the middle 50% of data.)"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Distribution Shape: Skewness",
    "text": "Distribution Shape: Skewness\n\nAn important measure of the shape of a distribution is called skewness.\nThe formula for the skewness of sample data is:\n\\[\n\\text{Skewness} = \\frac{n}{(n - 1)(n - 2)} \\sum \\left(\\frac{x_i - \\bar{x}}{s}\\right)^3\n\\]\nSkewness can be easily computed using statistical software."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Distribution Shape: Skewness",
    "text": "Distribution Shape: Skewness\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nSymmetric (not skewed)\n\nSkewness is zero.\nMean and median are equal."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Distribution Shape: Skewness",
    "text": "Distribution Shape: Skewness\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nModerately Skewed Left\n\nSkewness is negative.\nMean will usually be less than the median."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-3",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Distribution Shape: Skewness",
    "text": "Distribution Shape: Skewness\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nModerately Skewed Right\n\nSkewness is positive.\nMean will usually be more than the median."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-4",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#distribution-shape-skewness-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Distribution Shape: Skewness",
    "text": "Distribution Shape: Skewness\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nHighly Skewed Right\n\nSkewness is positive (often above 1.0).\nMean will usually be more than the median."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores",
    "title": " MGMT 30500: Business Statistics ",
    "section": "z-Scores",
    "text": "z-Scores\n\nThe z-score is often called the standardized value.\nIt describes the relative location of a data value relative to the mean.\nIt denotes the number of standard deviations a data value \\(x_i\\) is from the mean.\n\\[\nZ_i = \\frac{x_i - \\bar{x}}{s}\n\\]\n=STANDARDIZE(x, mean, standard deviation)"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "z-Scores",
    "text": "z-Scores\n\nAn observation’s z-score is a measure of the relative location of the observation in a data set.\nA data value less than the sample mean will have a z-score less than zero.\nA data value greater than the sample mean will have a z-score greater than zero.\nA data value equal to the sample mean will have a z-score of zero."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#z-scores-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "z-Scores",
    "text": "z-Scores\n\nExample: class_size_data.xlsx\n\\[\nZ_i = \\frac{x_i - \\bar{x}}{s}\n\\]\n\n\n\nNumber of students in class\nDeviation about the Mean\nZ score\n\n\n\n\n46\n2\n\\(\\frac{2}{8} = 0.25\\)\n\n\n54\n10\n\\(\\frac{10}{8} = 1.25\\)\n\n\n42\n-2\n\\(\\frac{-2}{8} = -0.25\\)\n\n\n46\n2\n\\(\\frac{2}{8} = 0.25\\)\n\n\n32\n-12\n\\(\\frac{-12}{8} = -1.5\\)\n\n\n\n\n\n\nNote: \\(\\bar{x} = 44\\) and \\(s = 8\\) for the given data."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Empirical Rule - 68-95-99.7 Rule",
    "text": "Empirical Rule - 68-95-99.7 Rule\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen the data are believed to approximate a bell-shaped (normal) distribution:\n\nThe empirical rule can be used to determine the percentage of data values that must be within a specified number of standard deviations of the mean."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Empirical Rule - 68-95-99.7 Rule",
    "text": "Empirical Rule - 68-95-99.7 Rule\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor nearly normally distributed data,\n\nabout 68% falls within 1 SD of the mean,\nabout 95% falls within 2 SD of the mean,\nabout 99.7% falls within 3 SD of the mean.\n\nIt is possible for observations to fall 4, 5, or more standard deviations away from the mean, but these occurrences are very rare if the data are nearly normal."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule---example",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#empirical-rule---68-95-99.7-rule---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Empirical Rule - 68-95-99.7 Rule - Example",
    "text": "Empirical Rule - 68-95-99.7 Rule - Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSAT scores are distributed nearly normally with mean 1500 and standard deviation 300.\n\n~68% of students score between 1200 and 1800 on the SAT.\n~95% of students score between 900 and 2100 on the SAT.\n~$99.7% of students score between 600 and 2400 on the SAT."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#detecting-outliers-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#detecting-outliers-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Outliers",
    "text": "Detecting Outliers\n\nAn outlier is an unusually small or unusually large value in a data set.\nA data value with a z-score less than −3 or greater than +3 might be considered an outlier.\nIt might be:\n\nan incorrectly recorded data value\na data value that was incorrectly included in the data set\na correctly recorded unusual data value that belongs in the data set"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#detecting-outliers---example",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#detecting-outliers---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Outliers - Example",
    "text": "Detecting Outliers - Example\nExample: class_size_data.xlsx\n\\[\nZ_i = \\frac{x_i - \\bar{x}}{s}\n\\]\n\n\n\nNumber of students in class\nDeviation about the Mean\nZ score\n\n\n\n\n46\n2\n\\(\\frac{2}{8} = 0.25\\)\n\n\n54\n10\n\\(\\frac{10}{8} = 1.25\\)\n\n\n42\n-2\n\\(\\frac{-2}{8} = -0.25\\)\n\n\n46\n2\n\\(\\frac{2}{8} = 0.25\\)\n\n\n32\n-12\n\\(\\frac{-12}{8} = -1.5\\)\n\n\n\n\nNote: \\(-1.5\\) shows the fifth class size is farthest from the mean.\nNo outliers are present as the z values are within the \\(\\pm 3\\) guideline."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#five-number-summaries",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#five-number-summaries",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Five-Number Summaries",
    "text": "Five-Number Summaries\n\n\nSmallest Value\nFirst Quartile (25th percentile)\nMedian (50th percentile)\nThird Quartile (75th percentile)\nLargest Value\n\n\n\n\nNote: \\(k-th\\) percentile = percentile.EXC(Data Array, k), where 0 ≤ k ≤ 1."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#five-number-summaries---example",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#five-number-summaries---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Five-Number Summaries - Example",
    "text": "Five-Number Summaries - Example\nExample: Monthly starting salary\n\n\n\n\n\nMonthly Starting Salary ($)\n\n\n\n\n5,710\n\n\n5,755\n\n\n5,850\n\n\n5,880\n\n\n5,890\n\n\n5,920\n\n\n5,940\n\n\n5,950\n\n\n6,050\n\n\n6,130\n\n\n6,325\n\n\n\n\n\n \n\nLowest Value = 5,710\nThird Quartile = 6,025\nMedian = 5,905\nFirst Quartile = 5,857.5\nLargest Value = 6,325"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Boxplot",
    "text": "Boxplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichelson–Morley experiment - Wiki\n\n\n\n\nA boxplot is a graphical summary of data that is based on a five-number summary.\nA key to the development of a boxplot is the computation of the median and the quartiles, \\(Q_1\\) and \\(Q_3\\).\nBoxplots provide another way to identify outliers."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Boxplot",
    "text": "Boxplot\nExample: monthly_starting_salary.xlsx\n\n\n\n\nA box is drawn with its ends located at the first and third quartiles.\nA vertical line is drawn in the box at the location of the median (second quartile)."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Boxplot",
    "text": "Boxplot\n\n\nLimits are located using the interquartile range (IQR).\nData outside these limits are considered outliers.\nThe locations of each outlier are shown with the symbol.\nThe limits are not shown is a Boxplot."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-3",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Boxplot",
    "text": "Boxplot\n\nExample: monthly_starting_salary.xlsx\n\n\n\n\n\n\nThe lower limit is located 1.5(IQR) below \\(Q_1\\).\n\nLower Limit: \\(Q_1 - 1.5(\\text{IQR}) = 5,857.5 - 1.5(167.5) = 5,606.25\\)\n\nThe upper limit is located 1.5(IQR) above \\(Q_3\\).\n\nUpper Limit: \\(Q_3 + 1.5(\\text{IQR}) = 6,025 + 1.5(167.5) = 6,276.25\\)\n\nThere is one outlier: 6,325."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-4",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#boxplot-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Boxplot",
    "text": "Boxplot\n\n\nDistribution and Boxplot"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance",
    "text": "Covariance\n\n\n\n\nThe covariance is a measure of the linear association between two variables.\nPositive values indicate a positive relationship.\nNegative values indicate a negative relationship."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance",
    "text": "Covariance\n\n\nThe covariance is computed as follows:\nFor population:\n\\[\n\\sigma_{xy} = \\frac{\\sum (x_i - \\mu_x)(y_i - \\mu_y)}{N}\n\\]\nFor samples:\n\\[\ns_{xy} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1}\n\\]\nEXCEL for Sample covariance: =COVARIANCE.S(array1, array2)"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\n\n\nCorrelation is a unit-free measure of linear association and not necessarily causation."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\n\nSpurious Correlations!\n\n\n\nJust because two variables are highly correlated, it does not mean that one variable is the cause of the other."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\nThe correlation coefficient is computed as follows:\nFor population:\n\\[\n\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}\n\\]\nFor samples:\n\\[\nr_{xy} = \\frac{s_{xy}}{s_x s_y}\n\\]\nEXCEL: =correl(array1, array2)"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-3",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\nThe coefficient can take on values between −1 and +1.\n\nValues near −1 indicate a strong negative linear relationship.\nValues near +1 indicate a strong positive linear relationship.\n\nThe closer the correlation is to zero, the weaker the relationship.\n\n\n\n\nGuess the correlation!"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-4",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\nRules of thumb:\n\n( 0.0 &lt; |r| &lt; 0.3 ) — weak correlation\n( 0.3 &lt; |r| &lt; 0.7 ) — moderate correlation\n( 0.7 &lt; |r| &lt; 1.0 ) — strong correlation"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-5",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\n\n\n\n\nThe correlation reflects the strength and direction of a linear relationship (top row)\nThe correlation does not reflect the slope of that relationship (middle)\nNor many aspects of nonlinear relationships (bottom).\nN.B.: the figure in the center has a slope of 0 but in that case the correlation coefficient is undefined because the variance of Y is zero.\n\n\nWiki"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance and Correlation Coefficient - Example",
    "text": "Covariance and Correlation Coefficient - Example\n\n\nExample: san_francisco_electronics_store.xlsx\n\n\n\n\n\n\n\nWeek\nNumber of Commercials\nSales ($100s)\n\n\n\n\n1\n2\n50\n\n\n2\n5\n57\n\n\n3\n1\n41\n\n\n4\n3\n54\n\n\n5\n4\n54\n\n\n6\n1\n38\n\n\n7\n5\n63\n\n\n8\n3\n48\n\n\n9\n4\n59\n\n\n10\n2\n46\n\n\n\n\n\n\n\n\nThe store’s manager wants to determine the relationship between the number of weekend television commercials shown and the sales at the store during the following week."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance and Correlation Coefficient - Example",
    "text": "Covariance and Correlation Coefficient - Example\n\n\nExample: san_francisco_electronics_store.xlsx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(x_i\\)\n\\(y_i\\)\n\\(x_i - \\bar{x}\\)\n\\(y_i - \\bar{y}\\)\n\\((x_i - \\bar{x})(y_i - \\bar{y})\\)\n\n\n\n\n2\n50\n-1\n-1\n1\n\n\n5\n57\n2\n6\n12\n\n\n1\n41\n-2\n-10\n20\n\n\n3\n54\n0\n3\n0\n\n\n4\n54\n1\n3\n3\n\n\n1\n38\n-2\n-13\n26\n\n\n5\n63\n2\n12\n24\n\n\n3\n48\n0\n-3\n0\n\n\n4\n59\n1\n8\n8\n\n\n2\n46\n-1\n-5\n5\n\n\nTotals\n30\n510\n0\n99\n\n\n\n\n\n\n\n\\[\ns_{xy} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1} = \\frac{99}{10 - 1} = 11\n\\]"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example-2",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#covariance-and-correlation-coefficient---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance and Correlation Coefficient - Example",
    "text": "Covariance and Correlation Coefficient - Example\n\n\nExample: san_francisco_electronics_store.xlsx\n\n\nSample Covariance\n\\[\ns_{xy} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{n - 1} = \\frac{99}{10 - 1} = 11\n\\]\nSample Correlation Coefficient\n\\[\nr_{xy} = \\frac{s_{xy}}{s_x s_y} = \\frac{11}{1.49 \\times 7.93} = 0.93\n\\]"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-6",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#correlation-coefficient-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\\[\nr_{xy} = \\frac{s_{xy}}{s_x s_y} = \\frac{1}{n-1} \\sum \\left(\\frac{x_i - \\bar{x}}{s_x}\\right) \\left(\\frac{y_i - \\bar{y}}{s_y}\\right)\n\\] \n\nCorrelation is a unit-free measure of linear relationship.\nCorrelation is unchanged if one or both variables are linearly transformed."
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#using-excel-to-compute-covariance-and-correlation-coefficient-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#using-excel-to-compute-covariance-and-correlation-coefficient-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel to Compute Covariance and Correlation coefficient",
    "text": "Using Excel to Compute Covariance and Correlation coefficient\nExample: San Francisco Electronics Store\nExcel Formula and Value Worksheets"
  },
  {
    "objectID": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#summary-1",
    "href": "lecture_slides/03_chapter_descriptive_statistics/03_chapter_descriptive_statistics.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nDescriptive Statistics: help us to understand the data we have.\nMeasures of Central Location and Variability: Central location and variability metrics help us to summarize the data.\nDistribution Shape: skewness can be used to understand the shape of a distribution.\nRelative Location and z-Scores: z-scores to determine the relative position of data points within a distribution.\nEmpirical Rule: The 68-95-99.7 Rule for understanding data distribution in relation to the mean and standard deviation. Good for symetric distrubutions!\nCovariance and Correlation: to understand the relationship between two numerical variables."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#overview",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nContinuous Probability Distributions\n\nDefinition\nArea as a Measure of Probability\n\nNormal Probability Distribution\n\nCharacteristics\nApplications\n\n\n\n\nStandard Normal Probability Distribution\n\nStandardization\nExcel Functions\n\n\\(t\\)-distribution\n\nUse and comparison\nExcel Functions"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#continuous-probability-distributions-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#continuous-probability-distributions-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Continuous Probability Distributions",
    "text": "Continuous Probability Distributions\n\n\nA continuous random variable can assume any value in an interval on the real line or in a collection of intervals.\nWe don’t normally talk about the probability of a continuous random variable assuming a particular value, because it is always 0 \\(P(X=x)=0\\).\nInstead, we talk about the probability of the random variable assuming a value within a given interval \\(P(X \\in (a,b))\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#continuous-probability-distributions-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#continuous-probability-distributions-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Continuous Probability Distributions",
    "text": "Continuous Probability Distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\nThe probability of the random variable assuming a value within some given interval from \\(x_1\\) to \\(x_2\\) is defined to be the area under the graph of the probability density function between \\(x_1\\) and \\(x_2\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#area-as-a-measure-of-probability",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#area-as-a-measure-of-probability",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Area as a Measure of Probability",
    "text": "Area as a Measure of Probability\n\n\nThe area under the graph of \\(f(x)\\) and probability are identical.\nThis is valid for all continuous random variables.\nThe probability that \\(x\\) takes on a value between some lower value \\(x_1\\) and some higher value \\(x_2\\) can be found by computing the area under the graph of \\(f(x)\\) over the interval from \\(x_1\\) to \\(x_2\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Distribution",
    "text": "Normal Probability Distribution\n\n\nThe normal probability distribution is the most common distribution for describing a continuous random variable.\nIt is widely used in statistical inference, especially because of the Central Limit Theorem (CLT).\nIt has been used in a wide variety of applications including:\n\nHeights of people\nTest scores\nRainfall amounts\nScientific measurements\n\nAbraham de Moivre, a French mathematician, published The Doctrine of Chances in 1733. He derived the normal distribution."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Distribution",
    "text": "Normal Probability Distribution\n\n\nNormal Probability Density Function\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2}\\left(\\frac{x - \\mu}{\\sigma}\\right)^2}\n\\]\nwhere:\n\n\\(\\mu\\)= population mean\n\\(\\sigma\\)= population standard deviation\n\\(\\pi = 3.14159\\)\n\\(e = 2.71828\\)\n\nThe distribution is symmetric with respect to mean; its skewness measure is zero.\nThe graph of the distribution is a bell-shaped curve."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-3",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Distribution",
    "text": "Normal Probability Distribution\n\n\nCharacteristics\n\nThe entire family of normal probability distributions is defined by its mean $$and its standard deviation \\(\\sigma\\). Denoted by \\(N(\\mu, \\sigma)\\).\nThe highest point on the normal curve is at the mean, which is also the median and mode.\nThe mean can be any numerical value: negative, zero, or positive. The mean determines the location of the distribution."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-4",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Distribution",
    "text": "Normal Probability Distribution\n\n\nCharacteristics\n\nThe standard deviation determines the width of the curve: larger values result in wider, flatter curves.\nProbabilities for the normal random variable are given by areas under the curve. The total area under the curve is 1 (.5 to the left of the mean and .5 to the right)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-5",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#normal-probability-distribution-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Distribution",
    "text": "Normal Probability Distribution\n\n\nCharacteristics\n\nEmpirical Rule"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probability-distribution-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probability-distribution-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probability Distribution",
    "text": "Standard Normal Probability Distribution\n\n\nCharacteristics\n\nA random variable having a normal distribution with a mean of 0 and a standard deviation of 1 is said to have a standard normal probability distribution.\nAlso called a z-distribution; Denoted by \\(Z\\) or \\(N(0,1)\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probability-distribution-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probability-distribution-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probability Distribution",
    "text": "Standard Normal Probability Distribution\n\n\n\n\nStandardization: Standardize \\(X \\sim N(\\mu, \\sigma)\\) to standard Normal Distribution, \\(Z\\)\n\\[\n  Z = \\frac{X - \\mu}{\\sigma}\n  \\]\n\nWe can think of \\(Z\\) as a measure of the number of standard deviations \\(X\\) is from \\(\\mu\\). (Cf. Standardization in Chapter 1.)\n\nConversely, \\(X = \\mu + z \\cdot \\sigma\\). If \\(X\\) can be written as \\(X = \\mu + z \\cdot \\sigma\\) where \\(Z\\) is standard normal, then \\(X \\sim N(\\mu, \\sigma^2)\\)\n\nThe letter z is used to designate the standard normal random variable."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel to Compute Standard Normal Probabilities",
    "text": "Excel to Compute Standard Normal Probabilities\n\n\nExcel functions for standard normal probability distributions.\n\n=NORM.S.DIST(z, TRUE) function computes the cumulative probability for a given \\(z\\) value of the standard normal distribution.\n=NORM.S.INV(cumulative probability) function computes the \\(z\\) value for a given cumulative probability of the standard normal distribution.\n“S” in the function names reminds us that these functions relate to the standard normal probability distribution.\n“TRUE” or “1” indicates a cumulative probability is requested."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel to Compute Standard Normal Probabilities",
    "text": "Excel to Compute Standard Normal Probabilities\n\n\nThe standard normal distribution and the cumulative area up to a given \\(z\\) value using the NORM.S.DIST(z, TRUE) function in Excel. The shaded area represents the cumulative probability up to the specified \\(z\\) value."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-3",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel to Compute Standard Normal Probabilities",
    "text": "Excel to Compute Standard Normal Probabilities\n\n\n\n \nFormula\n\n\n\n\n\n\n\n\n\n\n  Results"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-4",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#excel-to-compute-standard-normal-probabilities-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel to Compute Standard Normal Probabilities",
    "text": "Excel to Compute Standard Normal Probabilities\n\n\n \nFormula\n\n\n\n\n\n\n\n\n\n\n  Results"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\nGrear Tire company has developed a new steel-belted radial tire to be sold through a chain of discount stores. But before finalizing the tire mileage guarantee policy, Grear’s managers want probability information about the number of miles of tires will last.\nIt was estimated from the historical data that the (population) mean tire mileage is 36,500 miles with a (population) standard deviation of 5000.\nQuestion 1: The manager now wants to know the probability that the tire mileage \\(x\\) will exceed 40,000."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\n\nP(x &gt; 40,000) = ?\n\n\nStep 1: Convert x to standard normal distribution.\n\\[\nz = \\frac{(x - \\mu)}{\\sigma} \\\\\nz = \\frac{(40,000 - 36,500)}{5,000} \\\\\nz = 0.7\n\\]"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\n\nStep 2: Compute the area under the standard normal curve to the right of \\(z = 0.7\\)\n\n\n\n\\[\nP(z &gt; 0.7) = 1 - P(z \\leq 0.7) \\\\\n= 1 - \\text{=NORM.S.DIST}(0.7, \\text{TRUE}) \\\\\n= 1 - 0.7580 \\\\\n= 0.2420\n\\]"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-3",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\n\nQuestion 2: What should be the guaranteed mileage if Grear wants no more than 10% of tires to be eligible for the discount guarantee?\n\n\n(Hint: Given a probability, we can use the standard normal table in an inverse fashion to find the corresponding z-value.)"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-4",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\n\nStep 2: Convert \\(z_{0.1}\\) to the corresponding value of \\(x\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-5",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#standard-normal-probabilities---example-grear-tire-company-problem-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standard Normal Probabilities - Example: Grear Tire Company Problem",
    "text": "Standard Normal Probabilities - Example: Grear Tire Company Problem\n\nStep 2: Convert \\(z_{0.1}\\) to the corresponding value of \\(x\\).\n\n\n\n\\[\nx = \\mu + z_{0.1} \\cdot \\sigma \\\\\n= 36,500 + \\text{=NORM.S.INV}(0.1) \\cdot (5000) \\\\\n= 36,500 + (-1.28155) \\cdot (5000) \\\\\n= 30,092.24\n\\]\nThus, a guarantee of 30,100 miles will meet the requirement that approximately 10% of the tires will be eligible for the guarantee."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#why-use-the-t-distribution",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#why-use-the-t-distribution",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Why use the \\(t\\)-distribution?",
    "text": "Why use the \\(t\\)-distribution?\n\nWhat can we do when dealing with small sample sizes (\\(n &lt; 30\\))?\nWhat can we do when the population standard deviation (\\(\\sigma\\)) is unknown and must be estimated from the sample?\nHow to obtain more accurate confidence intervals for the mean when dealing with small samples?\n\n\n\n\n\\(t\\)-distribution"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#why-use-the-t-distribution-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#why-use-the-t-distribution-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Why use the \\(t\\)-distribution?",
    "text": "Why use the \\(t\\)-distribution?\n\n\nSample Size Considerations\n\nWhen the sample size is small \\((n &lt; 30)\\), the \\(t\\)-distribution provides a better estimate than the normal distribution.\nWith small samples, the sample standard deviation (\\(S\\)) may not be a reliable estimate of the population standard deviation (\\(\\sigma\\)).\n\nUnknown Population Standard Deviation\n\nWhen the population standard deviation (\\(\\sigma\\)) is unknown and must be estimated from the sample, the \\(t\\)-distribution is appropriate.\nThe \\(t\\)-distribution adjusts for the additional variability introduced by using \\(S\\) instead of \\(\\sigma\\).\n\nMore Accurate Confidence Intervals\n\nProvides more accurate confidence intervals for the mean when dealing with small samples.\nReflects the increased uncertainty in estimates due to small sample sizes and unknown \\(\\sigma\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(t\\) Probability Distribution",
    "text": "\\(t\\) Probability Distribution\n\nStandardize \\(N(\\mu, \\sigma)\\) using sample mean and sample standard deviation:\n\n\\[\nt = \\frac{X - \\bar{X}}{S}\n\\]\n\nThis t-statistic has a \\(t\\)-distribution with degrees of freedom (df) = \\(n-1\\), which is the degrees of freedom of the sample standard deviation \\(S\\).\nWhen using sample mean and sample standard deviation to standardize a normal distribution, we will always have a \\(t\\)-distribution, approximately."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-2",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(t\\) Probability Distribution",
    "text": "\\(t\\) Probability Distribution\n\nSimilar to the standard normal.\nSymmetric with mean 0 and a shape parameter (the degrees of freedom, df).\nThe standard deviation is \\(\\sqrt{\\frac{df}{(df - 2)}}\\) and is always larger than 1 (Recall: 1 is the standard deviation of Z-distribution):\n\n\\(t(df)\\) has more variability than Z.\n\\(t(df)\\) has heavier tails than Z: More probability (area) in the tails than Z. (Heavier tails.)\n\\(t(df)\\) approaches Z if \\(df\\) increases. Empirical rules can be used when \\(df \\geq 5\\)."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-3",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(t\\) Probability Distribution",
    "text": "\\(t\\) Probability Distribution\n\n\nThe standard normal distribution and two \\(t\\) distributions with different degrees of freedom."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#comparing-normal-and-t-distributions",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#comparing-normal-and-t-distributions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Comparing Normal and \\(t\\)-Distributions",
    "text": "Comparing Normal and \\(t\\)-Distributions\n\nShape and Symmetry\n\nBoth distributions are symmetric and bell-shaped.\nThe \\(t\\)-distribution has heavier tails compared to the normal distribution, reflecting more variability.\n\nDependence on Sample Size\n\nThe normal distribution does not depend on sample size.\nThe \\(t\\)-distribution varies with degrees of freedom (\\(df = n - 1\\)).\nAs the degrees of freedom increase, the \\(t\\)-distribution approaches the normal distribution."
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution---example-grear-tire-company-problem",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution---example-grear-tire-company-problem",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(t\\) Probability Distribution - Example: Grear Tire Company Problem",
    "text": "\\(t\\) Probability Distribution - Example: Grear Tire Company Problem\nGrear Tire company has developed a new steel-belted radial tire to be sold through a chain of discount stores. But before finalizing the tire mileage guarantee policy, Grear’s managers want probability information about the number of miles tires will last.\nIt was estimated from a sample of size 28 that the sample mean tire mileage is 36,500 miles with a sample standard deviation of 5000.\nThe manager now wants to know:\n\nQuestion 1: What is the probability that the tire mileage \\(X\\) will exceed 40,000 miles?\nQuestion 2: What is the 10th percentile tire mileage for the new tires?"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution---example-grear-tire-company-problem-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#t-probability-distribution---example-grear-tire-company-problem-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(t\\) Probability Distribution - Example: Grear Tire Company Problem",
    "text": "\\(t\\) Probability Distribution - Example: Grear Tire Company Problem\nSolution\n\nQuestion 1: What is the probability that the tire mileage \\(X\\) will exceed 40,000 miles?\n\\(P(X &gt; 40,000) = P(t_{27} &gt; 0.7) = 1 - P(t_{27} \\leq 0.7)\\)\n\\[\n= 1 - \\text{T.DIST}(0.7, 27, \\text{TRUE}) \\\\\n= 1 - 0.7550 \\\\\n= 0.250\n\\]\nQuestion 2: What is the 10th percentile tire mileage for the new tires?\n\\[\nx_{0.1} = \\bar{X} + t_{0.1,27} \\cdot s \\\\\n= 36,500 + \\text{T.INV}(0.1, 27) \\cdot (5000) \\\\\n= 36,500 + (-1.314) \\cdot (5000) \\\\\n= 29,903 \\text{ miles}\n\\]"
  },
  {
    "objectID": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#summary-1",
    "href": "lecture_slides/06_chapter_continuous_probability_distributions/06_chapter_continuous_probability_distributions.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\n\nSome key takeaways from this session:\n\nContinuous Probability Distributions:\n\nContinuous random variables can assume any value in an interval.\nProbability is defined as the area under the probability density function.\n\nNormal Probability Distribution:\n\nMost common distribution for describing a continuous random variable.\nDefined by its mean and standard deviation.\nWidely used due to the Central Limit Theorem.\n\n\n\n\n\nStandard Normal Probability Distribution:\n\nA normal distribution with a mean of 0 and a standard deviation of 1.\nStandardization helps in comparing different normal distributions.\n\n\\(t\\)-distribution\n\nUse when the sample size is small \\((n &lt; 30)\\)\nUse when the population standard deviation is unknown\n\nExcel Functions:\n\n=NORM.S.DIST(z, TRUE) computes the cumulative probability for a given z-value.\n=NORM.S.INV(cumulative probability) computes the z-value for a given cumulative probability.\n=T.DIST(X, DF, TRUE) computes the cumulative probability for a given t-value.\n\n=T.INV(cumulative probability) computes the t-value for a given cumulative probability."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#overview",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nIntroduction to Hypothesis Testing\nFramework of Hypothesis Testing\nType I and Type II Errors\n\n\n\nHypothesis Testing for Means\nHypothesis Testing for Proportions\nUsing Excel for Hypothesis Testing"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#statistical-inference-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#statistical-inference-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\n\n\n\nInterval Estimation\n\n\nConfidence level: 95% \\((1-\\alpha)\\) (Middle area; Confidence level)\nConfidence multipliers\nUpper/lower tail areas\nOne- or 2-sided intervals\nSampling errors and Margin of Error (MOE)\nFind range of all reasonable parameter values\n\n\n\n\nHypothesis Testing\n\n\nSignificance level: 5% \\((\\alpha)\\) (Tail area(s); Risk)\nCritical values\np-values\nWhich side \\((H_a)\\) depends mostly on data\nTest a specific hypothesized parameter value\nStrength of sample evidence against the hypothesized value of the null hypothesis"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#hypothesis-testing-framework-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#hypothesis-testing-framework-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nHypothesis testing can be used to determine whether a statement about the population or a hypothesized value of the population parameter should or should not be rejected.\nWe start with a null hypothesis (\\(H_0\\)) that represents the status quo.\nWe also have an alternative hypothesis (\\(H_A\\)) that represents our research question, i.e. what we’re testing for.\nWe conduct a hypothesis test under the assumption that the null hypothesis is true.\nIf the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we stick with the null hypothesis. If they do, then we reject the null hypothesis in favor of the alternative.\nWe will never know which hypothesis is true, unless we sample the entire population."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#null-and-alternative-hypotheses-about-a-population-mean",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#null-and-alternative-hypotheses-about-a-population-mean",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Null and Alternative Hypotheses about a Population Mean",
    "text": "Null and Alternative Hypotheses about a Population Mean\nThe equality part of the hypotheses always appears in the null hypothesis.\nIn general, a hypothesis test about the value of a population mean \\(\\mu\\) takes one of the following three forms (where \\(\\mu_0\\) is the hypothesized value of the population mean).\n\n\n\n\n\n\n\n\n\nTest Type\nNull Hypothesis (\\(H_0\\))\nAlternative Hypothesis (\\(H_A\\))\n\n\n\n\nOne-tailed (lower-tail)\n\\(H_0\\): \\(\\mu \\geq \\mu_0\\)\n\\(H_A\\): \\(\\mu &lt; \\mu_0\\)\n\n\nOne-tailed (upper-tail)\n\\(H_0\\): \\(\\mu \\leq \\mu_0\\)\n\\(H_A\\): \\(\\mu &gt; \\mu_0\\)\n\n\nTwo-tailed\n\\(H_0\\): \\(\\mu = \\mu_0\\)\n\\(H_A\\): \\(\\mu \\neq \\mu_0\\)"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#building-a-null-hypothesis",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#building-a-null-hypothesis",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Building a Null Hypothesis",
    "text": "Building a Null Hypothesis\n\nFormulate the null hypothesis by stating that there is no effect, no difference, or that the effect is equal to a specific value. The null hypothesis is often a statement of equality (e.g., no difference or no association).\nKey Phrases for Null Hypothesis:\n\n“There is no difference…”\n“There is no effect…”\n“The population mean is equal to…”\n“The proportion is equal to…”\n\nExamples:\n\nSingle-Sample Test (Mean):\n\\(H_0: \\mu = \\mu_0\\)\n(The mean blood pressure reduction with the new drug is equal to a standard value.)\nProportion Test:\n\\(H_0: p = p_0\\)\n(The proportion of patients responding to the treatment is equal to 50%.)"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-i-error",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-i-error",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Type I Error",
    "text": "Type I Error\n\nBecause hypothesis tests are based on sample data, we must allow for the possibility of errors.\nA Type I error is rejecting \\(H_0\\) when \\(H_0\\) is true (but in the one-tailed tests, we still don’t know exactly the value of \\(\\mu\\)).\nThe probability of making a Type I error when the null hypothesis is true as an equality is called the level of significance \\((\\alpha)\\), which is (likely) the maximum value of the Type I probability.\nLevel of significance \\((\\alpha)\\) is predetermined by the user (normally, 1%, 5%, or 10%) to control the probability of making a Type I error: Significance tests."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-ii-error",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-ii-error",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Type II Error",
    "text": "Type II Error\n\nA Type II error is an error of accepting \\(H_0\\) when \\(H_0\\) is false. (Or, rejecting \\(H_A\\) when \\(H_A\\) is true.)\nNormally, we don’t control the probability of making a Type II error.\nStatisticians avoid the risk of making a Type II error by using “do not reject \\(H_0\\)” instead of “accept \\(H_0\\)”."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-i-and-type-ii-errors-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#type-i-and-type-ii-errors-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Type I and Type II Errors",
    "text": "Type I and Type II Errors\nExample: A researcher sets out to test whether a new teaching method increases students’ average scores above the previous benchmark of 12 (\\(H_A\\)), challenging the long-held belief that the average score remains at or below 12 (\\(H_0\\)).\nHypotheses:\n\n\\(H_0\\): \\(\\mu \\leq 12\\)\n\\(H_A\\): \\(\\mu &gt; 12\\)"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-values",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-values",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p\\)-values",
    "text": "\\(p\\)-values\n\nThe \\(p-value\\) is the probability computed using the test statistic, that provides the probability of obtaining test results at least as extreme as the results actually observed, assuming that the null hypothesis is true.\nIf the \\(p-value\\) is low (lower than the significance level, \\(\\alpha\\), which is usually 5%) we say that it would be very unlikely to observe the data if the null hypothesis were true, and hence reject \\(H_0\\).\nIf the \\(p-value\\) is high (higher than \\(\\alpha\\)) we say that it is likely to observe the data even if the null hypothesis were true, and hence do not reject \\(H_0\\)."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests about a Population Mean: \\(\\sigma\\) Unknown",
    "text": "Tests about a Population Mean: \\(\\sigma\\) Unknown\nTwo approaches to decide about the Null Hypothesis (\\(H_0\\)).\n\nCritical Value Approach:\n\nIt uses critical values from the \\(t-distribution\\) to determine whether to reject the null hypothesis (\\(H_0\\)). Depending on the direction of the test (one-tailed or two-tailed), the critical value is compared to the calculated t-statistic.\nDecision Rule:\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\geq \\mu_0; \\quad H_a: \\mu &lt; \\mu_0 \\quad \\text{(left/lower-tail)} \\quad &\\text{Reject } H_0 \\text{ if } t \\leq -t_{\\alpha, n-1} \\\\\nH_0 &: \\mu \\leq \\mu_0; \\quad H_a: \\mu &gt; \\mu_0 \\quad \\text{(right/upper-tail)} \\quad &\\text{Reject } H_0 \\text{ if } t \\geq t_{\\alpha, n-1} \\\\\nH_0 &: \\mu = \\mu_0; \\quad H_a: \\mu \\neq \\mu_0 \\quad \\text{(two-tail)} \\quad &\\text{Reject } H_0 \\text{ if } t \\leq -t_{\\alpha/2, n-1} \\text{ or } t \\geq t_{\\alpha/2, n-1}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown-2",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests about a Population Mean: \\(\\sigma\\) Unknown",
    "text": "Tests about a Population Mean: \\(\\sigma\\) Unknown\n\n\\(p-value\\) Approach:\n\n\nCalculate the p-value, which is the probability of obtaining a test statistic at least as extreme as the one observed, assuming the null hypothesis is true.\n\nDecision Rule:\n\\[\n\\text{Reject } H_0 \\text{ if } p\\text{-value} \\leq \\alpha\n\\]\n\nIf the p-value is less than or equal to the significance level (\\(\\alpha\\)), reject the null hypothesis."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-values-and-critical-value---excel",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-values-and-critical-value---excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p-values\\) and Critical Value - Excel",
    "text": "\\(p-values\\) and Critical Value - Excel\n\nEXCEL functions:\n\np-value is a probability: =T.DIST\nCritical value is a point or value on the horizontal or \\(t\\) axis: =T.INV"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown---example",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-mean-sigma-unknown---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests about a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "Tests about a Population Mean: \\(\\sigma\\) Unknown - Example\nA business travel magazine wants to classify transatlantic gateway airports according to the mean rating for the population of business travelers. A rating scale with a low score of 0 and a high score of 10 will be used, and airports with a population mean rating greater than 7 will be designated as superior service airports.\nA sample of 60 business travelers were surveyed at London’s Heathrow Airport, which provided a sample mean rating of \\(\\bar{x} = 7.25\\) and a sample standard deviation of \\(s = 1.052\\).\nQuestion: Do the data indicate that Heathrow should be designated as a superior service airport?"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-tailed-test-about-a-population-mean-sigma-unknown---example",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-tailed-test-about-a-population-mean-sigma-unknown---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-Tailed Test about a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "One-Tailed Test about a Population Mean: \\(\\sigma\\) Unknown - Example\n\nDetermine the hypotheses.\n\n\\[\n\\begin{aligned}\nH_0 &: \\mu \\leq 7 \\\\\nH_a &: \\mu &gt; 7 \\quad \\text{(upper tail)}\n\\end{aligned}\n\\]\n\nSpecify the level of significance.\n\n\\[\n\\alpha = 0.05\n\\]\n\nCompute the value of the test statistic.\n\n\\[\nt = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}} = \\frac{7.25 - 7}{1.052 / \\sqrt{60}} = 1.84\n\\]"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#critical-value-approach-visualization-upper-tailed---example",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#critical-value-approach-visualization-upper-tailed---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Critical Value Approach Visualization (Upper-tailed) - Example",
    "text": "Critical Value Approach Visualization (Upper-tailed) - Example"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-value-approach-visualization-upper-tailed---example",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#p-value-approach-visualization-upper-tailed---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "\\(p-value\\) Approach Visualization (Upper-tailed) - Example",
    "text": "\\(p-value\\) Approach Visualization (Upper-tailed) - Example"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-tailed-test-about-a-population-mean-sigma-unknown---example-2",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-tailed-test-about-a-population-mean-sigma-unknown---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-Tailed Test about a Population Mean: \\(\\sigma\\) Unknown - Example",
    "text": "One-Tailed Test about a Population Mean: \\(\\sigma\\) Unknown - Example\np-value Approach\n\nCompute the p-value = 0.0354.\nBecause p-value \\(\\leq \\alpha = 0.05\\), we reject \\(H_0\\).\n\nBased on the current sample, we have significant statistical evidence to reject the null hypothesis and conclude that Heathrow should be classified as a superior service airport. The significance level is 5%. The sample evidence against \\(H_0\\) is strong."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#null-and-alternative-hypotheses-about-a-population-proportion",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#null-and-alternative-hypotheses-about-a-population-proportion",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Null and Alternative Hypotheses about a Population Proportion",
    "text": "Null and Alternative Hypotheses about a Population Proportion\n\nThe equality part of the hypotheses always appears in the null hypothesis.\nIn general, a hypothesis test about the value of a population proportion \\(p\\) must take one of the following three forms (where \\(p_0\\) is the hypothesized value of the population proportion).\n\n\\[\n\\begin{aligned}\n\\text{One-tailed (lower tail)} & \\quad H_0: p \\geq p_0 \\quad H_a: p &lt; p_0 \\\\\n\\text{One-tailed (upper tail)} & \\quad H_0: p \\leq p_0 \\quad H_a: p &gt; p_0 \\\\\n\\text{Two-tailed} & \\quad H_0: p = p_0 \\quad H_a: p \\neq p_0\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests about a Population Proportion",
    "text": "Tests about a Population Proportion\n\nTest Statistic:\nThe Z-test for a population proportion is used to determine whether the observed sample proportion (\\(\\bar{p}\\)) is significantly different from the hypothesized population proportion (\\(p_0\\)). By calculating the z-value, we can compare it to critical values from the standard normal distribution to decide whether to reject the null hypothesis.\n\\[\nz = \\frac{\\bar{p} - p_0}{\\sigma_{\\bar{p}}}\n\\]\nwhere:\n\\[\n\\sigma_{\\bar{p}} = \\sqrt{\\frac{p_0 (1 - p_0)}{n}}\n\\]\nassuming \\(np_0 \\geq 5\\) and \\(n(1 - p_0) \\geq 5\\).\n\n\\(\\bar{p}\\): Sample proportion\n\\(p_0\\): Hypothesized population proportion\n\\(\\sigma_{\\bar{p}}\\): Standard error of the sample proportion\n\\(p_0\\): Hypothesized population proportion\n\\(n\\): Sample size"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests About a Population Proportion - Example",
    "text": "Tests About a Population Proportion - Example\n\nExample: Pine Creek Golf Course\n\nOver the past year, 20% of the players at Pine Creek were women. In an effort to increase the proportion of women players, Pine Creek implemented a special promotion design to attract women golfers. The manager now wants to determine if the proportion of women players has increased.\n\nA random sample of 400 players were selected and 100 of the players were women. The level of significance is \\(\\alpha = .05\\)."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests About a Population Proportion - Example",
    "text": "Tests About a Population Proportion - Example\n\nDetermine the hypotheses\n\n\\(H_0: p \\le .20\\) and \\(H_a: p &gt; .20\\) (upper tail)\n\n\n\n\nSpecify the level of significance. \\(\\alpha = .05\\)\n\n\n\nCompute the value of the z test statistic.\n\n\\(\\sigma_{\\bar{p}} = \\sqrt{\\frac{p_0(1-p_0)}{n}} = \\sqrt{\\frac{.2(1-.2)}{400}} = .02\\)\n\\(z = \\frac{\\bar{p} - p_0}{\\sigma_{\\bar{p}}} = \\frac{(.25) - .20}{.02} = 2.50\\)"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-2",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests About a Population Proportion - Example",
    "text": "Tests About a Population Proportion - Example\nCritical Value Approach\n\nDetermine the critical values and rejection rule.\n\n\\(z_{0.05} = \\text{NORM.S.INV}(0.95) = 1.645\\)\nDecision Rule: Reject \\(H_0\\) if \\(z \\ge 1.645\\)\n\n\n\n\nDetermine whether to reject \\(H_0\\) because \\(z = 2.5 &gt; 1.645\\), we reject \\(H_0\\)."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-3",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#tests-about-a-population-proportion---example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tests About a Population Proportion - Example",
    "text": "Tests About a Population Proportion - Example\np-value Approach\n\nCompute the p-value for \\(z = 2.50\\) (an upper tail problem).\n\n\\(p\\)-value \\(= 1 - \\text{NORM.S.DIST}(2.50, \\text{TRUE}) = 1 - .9938 = .0062\\)\n\n\n\n\nBecause \\(p\\)-value \\(= .0062 &lt; \\alpha = .05\\), we reject \\(H_0\\).\n\nBased on the current sample, we have significant statistical evidence to conclude that the proportion of women players has increased from 20%. The significance level is 5%. The evidence against \\(H_0\\) is overwhelming."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-sided-and-two-sided-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#one-sided-and-two-sided-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-sided and Two-sided",
    "text": "One-sided and Two-sided\n\nFor a left/lower-tailed test, we calculate the tail area and critical value on the left side.\nFor a two-tailed test,\n\nDouble the tail area to obtain the \\(p\\)-value (Note: p-value is a probability and, hence, must be between 0 and 1, inclusively.)\nDivide the significance level \\(\\alpha\\) and assign to each side to obtain two critical values."
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#using-excel-to-determine-p-values-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#using-excel-to-determine-p-values-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel to Determine \\(p-values\\)",
    "text": "Using Excel to Determine \\(p-values\\)"
  },
  {
    "objectID": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#summary-1",
    "href": "lecture_slides/09_chapter_hypothesis_tests/09_chapter_hypothesis_tests.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nDeveloping a null hypothesis involves stating the parameter of interest, its hypothesized value, and forming \\(H_0\\) to reflect no change or effect.\nThe critical value approach and p-value approach are two fundamental methods in hypothesis testing.\nCritical values are determined based on the significance level and the test statistic’s distribution.\nThe p-value approach provides a probability measure to assess the evidence against \\(H_0\\).\nBoth approaches lead to the same conclusion but offer different perspectives on the data."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#overview",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nInference about a Population Variance\nChi-Square Distribution\nInterval Estimation of \\(\\sigma^2\\)\n\n\n\nHypothesis Testing about a Population Variance\nInferences about Two Population Variances\nF-Test Two-Sample for Variances - Example Excel"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#statistical-inference-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#statistical-inference-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Statistical Inference",
    "text": "Statistical Inference\n\n\n\n\nInterval Estimation\n\n\nConfidence level: 95% \\((1-\\alpha)\\) (Middle area; Confidence level)\nConfidence multipliers\nUpper/lower tail areas\nOne- or 2-sided intervals\nSampling errors and Margin of Error (MOE)\nFind range of all reasonable parameter values\n\n\n\n\nHypothesis Testing\n\n\nSignificance level: 5% \\((\\alpha)\\) (Tail area(s); Risk)\nCritical values\np-values\nWhich side \\((H_a)\\) depends mostly on data\nStrength of sample evidence against the hypothesized value (via p-value)\nTest a specific hypothesized parameter value"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-framework-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-framework-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\nHypothesis testing can be used to determine whether a statement about the population or a hypothesized value of the population parameter should or should not be rejected.\nWe start with a null hypothesis (\\(H_0\\)) that represents the status quo.\nWe also have an alternative hypothesis (\\(H_A\\)) that represents our research question, i.e. what we’re testing for.\nWe conduct a hypothesis test under the assumption that the null hypothesis is true.\nIf the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, we stick with the null hypothesis. If they do, then we reject the null hypothesis in favor of the alternative.\nWe will never know which hypothesis is true, unless we sample the entire population."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#inference-about-a-population-variance-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#inference-about-a-population-variance-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Inference about a Population Variance",
    "text": "Inference about a Population Variance\n\nA variance can provide important decision-making information.\nConsider the production process of filling containers with a liquid detergent product.\n\nThe mean filling weight is important, but so too is the variance of the filling weights.\nBy selecting a sample of containers, we can compute a sample variance for the amount of detergent placed in a container.\nIf the sample variance is excessive, overfilling and underfilling may be occurring even though the mean is correct."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Chi-Square Distribution",
    "text": "Chi-Square Distribution\n\nWe can use the chi-square distribution to develop interval estimates and conduct hypothesis tests about a population variance \\(\\sigma^2\\).\nThe chi-square (\\(\\chi^2\\)) distribution is the sum of squared standardized normal random variables (a variable that follows a normal distribution) such as \\((z_1)^2 + (z_2)^2 + (z_3)^2\\) and so on.\nThe chi-square distribution is based on sampling from a normal population.\nThe sampling distribution of \\((n-1)S^2/\\sigma^2\\) has a chi-square distribution with \\(n-1\\) degrees of freedom whenever a simple random sample of size \\(n\\) is selected from a normal population with population variance \\(\\sigma^2\\). \\(S^2\\) is the sample variance."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distributions-with-different-degrees-of-freedom",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distributions-with-different-degrees-of-freedom",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Chi-Square Distributions with different degrees of Freedom",
    "text": "Chi-Square Distributions with different degrees of Freedom"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Chi-Square Distribution",
    "text": "Chi-Square Distribution\nWe will use the notation \\(\\chi^2_{\\alpha}\\) to denote the value for the chi-square distribution that provides an area of \\(\\alpha\\) to the right of the stated \\(\\chi^2_{\\alpha}\\) value."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#chi-square-distribution-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Chi-Square Distribution",
    "text": "Chi-Square Distribution"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimation of \\(\\sigma^2\\)",
    "text": "Interval Estimation of \\(\\sigma^2\\)\n\nThere is a \\((1-\\alpha)\\) probability of obtaining a \\((n-1)S^2/\\sigma^2\\) value such that\n\\[\n\\chi^2_{(1-\\alpha/2)} \\leq \\frac{(n-1)S^2}{\\sigma^2} \\leq \\chi^2_{\\alpha/2}\n\\]\nPerforming algebraic manipulation, we obtain an \\(1-\\alpha\\) interval estimate of the population variance \\[\n\\frac{(n-1)S^2}{\\chi^2_{\\alpha/2}} \\leq \\sigma^2 \\leq \\frac{(n-1)S^2}{\\chi^2_{(1-\\alpha/2)}}\n\\]\nTaking the square root of the upper and lower limits of the variance interval provides the confidence interval for the population standard deviation. \\[\n\\sqrt{\\frac{(n-1)S^2}{\\chi^2_{\\alpha/2}}} \\leq \\sigma \\leq \\sqrt{\\frac{(n-1)S^2}{\\chi^2_{(1-\\alpha/2)}}}\n\\]"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimation of \\(\\sigma^2\\) - Example",
    "text": "Interval Estimation of \\(\\sigma^2\\) - Example\nExample: Liquid detergent product filling process\nThe filling mechanism for the process of filling liquid detergent product in a container is adjusted such that mean filling weight is 16 ounces per container. A sample of 20 containers was taken to test this. If the sample variance is modest, the production process will be continued. If the sample variance is excessive, the filling mechanism will be readjusted to reduce the filling variance.\nThe sample variance for the filling quantities is found to be \\(s^2 = .0025\\).\nChoose \\(\\alpha = .05\\)."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimation of \\(\\sigma^2\\) - Example",
    "text": "Interval Estimation of \\(\\sigma^2\\) - Example\n\nTwo confidence multipliers: (df = n-1 = 20-1 = 19) \\[\n\\chi^2_{0.025} = \\text{CHISQ.INV}(0.975, 19) = 32.852\n\\] \\[\n\\chi^2_{0.975} = \\text{CHISQ.INV}(0.025, 19) = 8.907\n\\]"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimation of \\(\\sigma^2\\) - Example",
    "text": "Interval Estimation of \\(\\sigma^2\\) - Example\n\nA 95% confidence interval for the population variance is given by: \\[\n\\frac{(20-1)0.0025}{32.852} \\leq \\sigma^2 \\leq \\frac{(20-1)0.0025}{8.907}\n\\]\n\\[\n0.0014 \\leq \\sigma^2 \\leq 0.0053\n\\]\nTaking the square root of these values provides a 95% confidence interval for the population standard deviation.\n\\[\n0.0380 \\leq \\sigma \\leq 0.0730\n\\]\nWe are 95% confident that the process standard deviation of the filling weight per container is between 0.0380 ounces and 0.0730 ounces."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-excel",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#interval-estimation-of-sigma2---example-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interval Estimation of \\(\\sigma^2\\) - Example Excel",
    "text": "Interval Estimation of \\(\\sigma^2\\) - Example Excel"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance",
    "text": "Hypothesis Testing about a Population Variance\n\n\nHypotheses\n\n\\(H_0: \\sigma^2 \\geq \\sigma_0^2\\)\n\\(H_a: \\sigma^2 &lt; \\sigma_0^2\\) (Left-tailed)\n\nwhere \\(\\sigma_0^2\\) is the hypothesized value for the population variance.\n\nTest Statistic\n\\[\n\\chi^2 = \\frac{(n-1)S^2}{\\sigma_0^2}\n\\]\n\n\n\nRejection Rule (Left-tailed test)\n\nCritical-value approach:\n\nReject \\(H_0\\) if \\(\\chi^2 \\leq \\chi^2_{(1-\\alpha)}\\)\n\n\n\n\np-value approach:\n\nReject \\(H_0\\) if p-value \\(\\leq \\alpha\\)\n\n\nwhere \\(\\chi^2_{(1-\\alpha)}\\) is based on a chi-square distribution with \\(n-1\\) df."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance",
    "text": "Hypothesis Testing about a Population Variance\n\n\nHypotheses\n\\[\n\\begin{aligned}\nH_0 &: \\sigma^2 \\leq \\sigma^2_0 \\\\\nH_a &: \\sigma^2 &gt; \\sigma^2_0 \\quad \\text{(Right-tailed)}\n\\end{aligned}\n\\]\nwhere \\(\\sigma^2_0\\) is the hypothesized value for the population variance.\n\nTest Statistic\n\\[\n\\chi^2 = \\frac{(n-1)S^2}{\\sigma^2_0}\n\\]\n\n\n\nRejection Rule (Right-tailed test)\n\nCritical-value approach:\nReject \\(H_0\\) if \\(\\chi^2 \\geq \\chi^2_\\alpha\\)\n\n\n\np-value approach:\nReject \\(H_0\\) if p-value \\(\\leq \\alpha\\)\n\nwhere \\(\\chi^2_\\alpha\\) is based on a chi-square distribution with \\(n-1\\) df."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance",
    "text": "Hypothesis Testing about a Population Variance\n\n\nHypotheses\n\\[\n\\begin{aligned}\nH_0 &: \\sigma^2 = \\sigma^2_0 \\\\\nH_a &: \\sigma^2 \\neq \\sigma^2_0 \\quad \\text{(Two-tailed)}\n\\end{aligned}\n\\]\nwhere \\(\\sigma^2_0\\) is the hypothesized value for the population variance.\n\nTest Statistic\n\\[\n\\chi^2 = \\frac{(n-1)S^2}{\\sigma^2_0}\n\\]\n\n\n\nRejection Rule (Two-tailed test)\n\nCritical-value approach:\nReject \\(H_0\\) if \\(\\chi^2 \\leq \\chi^2_{(1-\\alpha/2)}\\) or \\(\\chi^2 \\geq \\chi^2_{\\alpha/2}\\)\n\n\n\np-value approach:\nReject \\(H_0\\) if p-value \\(\\leq \\alpha\\)\n\nwhere \\(\\chi^2_{(1-\\alpha/2)}\\) and \\(\\chi^2_{\\alpha/2}\\) are based on a chi-square distribution with \\(n-1\\) df."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance - Example",
    "text": "Hypothesis Testing about a Population Variance - Example\nExample: St. Louis Metro Bus Company\nSt. Louis Metro Bus Company wants to promote an image of reliability by encouraging its drivers to maintain consistent schedules. The company specifies an arrival time variance of 4 or less when arrival times are measured in minutes.\nWe will conduct a hypothesis test (with \\(\\alpha = 0.05\\)) to determine whether the arrival time population variance is excessive."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance - Example",
    "text": "Hypothesis Testing about a Population Variance - Example\nHypotheses: \\[\nH_0: \\sigma^2 \\leq 4\n\\] \\[\nH_a: \\sigma^2 &gt; 4\n\\]\nA random sample of 24 bus arrivals taken at a downtown intersection provided a sample variance of \\(s^2 = 4.9\\).\nTest Statistic\n\\[\n\\chi^2 = \\frac{(n-1)S^2}{\\sigma_0^2} = \\frac{(24-1)(4.9)}{4} = 28.18\n\\]"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance - Example",
    "text": "Hypothesis Testing about a Population Variance - Example\n\n\\(p\\)-value Approach:\n\n\n\n\\(p\\)-value = 1-CHISQ.DIST(28.18, 23, TRUE) = 0.209 &gt; 5%. Fail to reject \\(H_0\\)."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance - Example",
    "text": "Hypothesis Testing about a Population Variance - Example\n\n5% Critical Value = CHI.INV(0.95, 23) = 35.172\n\nRejection Rule:\nReject \\(H_0\\) if \\(\\chi^2 \\geq 35.172\\)\n\n\nBecause \\(\\chi^2 = 28.18\\), we fail to reject the null hypothesis.\n\nConclusion: Based on the current sample, we do not have significant statistical evidence to conclude that the arrival time variance is greater than 4. The significance level is 5%."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-excel",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-a-population-variance---example-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about a Population Variance - Example Excel",
    "text": "Hypothesis Testing about a Population Variance - Example Excel"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#inferences-about-two-population-variances-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#inferences-about-two-population-variances-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Inferences about Two Population Variances",
    "text": "Inferences about Two Population Variances\n\nWe may want to compare the population variances (variation) in:\n\nproduct quality resulting from two different production processes,\ntemperatures for two heating devices, or\nassembly times for two assembly methods.\n\nWe use sample data collected from two independent normal populations.\nThe two sample variances will be the basis for making inferences about the two normal population variances."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations",
    "text": "Hypothesis Testing about the Variances of Two Populations\nOne-Tailed Test: (Right tail)\nHypotheses: \\[\n  H_0: \\sigma_1^2 \\leq \\sigma_2^2 \\quad \\left( \\frac{\\sigma_1^2}{\\sigma_2^2} \\leq 1 \\right)\n  \\] \\[\n  H_a: \\sigma_1^2 &gt; \\sigma_2^2 \\quad \\left( \\frac{\\sigma_1^2}{\\sigma_2^2} &gt; 1 \\right)\n  \\]\n\nThe population providing the larger sample variance is designated as Population 1.\nThe Null Hypothesis is based on the assumption that the variances are equal.\nTest Statistic:\n\\[\nF = \\frac{S_1^2}{S_2^2} \\quad \\text{follows F-distribution } (n_1-1, n_2-1), \\text{ if } H_0(=) \\text{ is true}.\n\\]"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations",
    "text": "Hypothesis Testing about the Variances of Two Populations\nRejection Rule:\n\nCritical-value approach:\n\nReject \\(H_0\\) if \\(F \\geq F_{\\alpha, n_1-1, n_2-1}\\).\nwhere the value of \\(F_{\\alpha, n_1-1, n_2-1}\\) is based on an \\(F\\) distribution with \\(n_1 - 1\\) (numerator) and \\(n_2 - 1\\) (denominator) d.f., such that the upper tail area is \\(\\alpha\\).\n\np-value approach:\n\nReject \\(H_0\\) if p-value \\(\\leq\\alpha\\)."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations",
    "text": "Hypothesis Testing about the Variances of Two Populations\nTwo-Tailed Test\nHypotheses:\n\\[ H_0 : \\sigma^2_1 = \\sigma^2_2 \\] \\[ H_a : \\sigma^2_1 \\neq \\sigma^2_2 \\]\n\nDenote the population providing the larger sample variance as population 1.\nThe Null Hypothesis is based on the assumption that the variances are equal.\n\nTest Statistic:\n\\[ F = \\frac{S^2_1}{S^2_2} \\]\nfollows F-distribution \\((n_1-1, n_2-1)\\), if \\(H_0 ( =)\\) is true."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations",
    "text": "Hypothesis Testing about the Variances of Two Populations\nDecision Rule:\n\nCritical-value approach:\n\nReject \\(H_0\\) if \\(F \\geq F_{\\alpha/2, n_1-1, n_2-1}\\).\nwhere the value of \\(F_{\\alpha/2, n_1-1, n_2-1}\\) is based on an \\(F\\) distribution with \\(n_1 - 1\\) (numerator) and \\(n_2 - 1\\) (denominator) d.f.\n\np-value approach:\n\nReject \\(H_0\\) if p-value \\(\\leq \\alpha\\)."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations - Example",
    "text": "Hypothesis Testing about the Variances of Two Populations - Example\nExample: Dullus County School\nDullus County school wants to select one among the Milbank Company and Gulf Park Company for the bus service contract for the coming year. The variance of arrival/pickup time will be used as a primary measure of the quality of service.\nWe will conduct a hypothesis test with \\(\\alpha = 10\\%\\) to see if the variances are equal for Milbank Company and Gulf Park Company."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations - Example",
    "text": "Hypothesis Testing about the Variances of Two Populations - Example\nHypotheses:\n\n\\(H_0\\): Milbank and Gulf Park have same arrival time variance\n\\(H_a\\): Their variances are not equal- Two-Tailed\n\n\\[ H_0 : \\sigma^2_1 = \\sigma^2_2\\]\n\\[ H_a : \\sigma^2_1 \\neq \\sigma^2_2 \\]\nA sample of 26 arrival times for the Milbank service provided a sample variance of 48 and a sample of 16 arrival times for the Gulf Park service provided a sample variance of 20.\nBecause the Milbank sample provided a larger sample variance, we will denote Milbank as Population 1.\nHence, \\(n_1 = 26, n_2 = 16\\).\nRecall \\(\\alpha = 10\\%\\)."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations - Example",
    "text": "Hypothesis Testing about the Variances of Two Populations - Example\nTest statistic \\(F\\) has 25 d.f. (numerator), and 15 d.f. (denominator)\n\\[ F = \\frac{S^2_1}{S^2_2} = \\frac{48}{20} = 2.40 \\]\nCritical Value"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations - Example",
    "text": "Hypothesis Testing about the Variances of Two Populations - Example\nCritical-value approach:\n\\[\\alpha / 2 = 0.05\\]\n\nUpper-tailed critical value = F.INV(0.95, 25, 15) = 2.28\nDecision rule:\n\nReject \\(H_0\\) if \\(F \\geq 2.28\\).\n\nBecause \\(F = 2.40\\) is greater than 2.28, we reject null hypothesis."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-4",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#hypothesis-testing-about-the-variances-of-two-populations---example-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Hypothesis Testing about the Variances of Two Populations - Example",
    "text": "Hypothesis Testing about the Variances of Two Populations - Example\np-value approach:\n\n\n25 d.f. (numerator), and 15 d.f. (denominator),\np-value = 2*(1- F.DIST(2.40, 25,15, TRUE)) = 2*0.041 = 0.082.\nBecause \\(\\alpha = 0.10\\), we have p-value \\(&lt; \\alpha\\) and therefore, null hypothesis is rejected."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#f-test-two-sample-for-variances---example-excel-2",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#f-test-two-sample-for-variances---example-excel-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "F-Test Two-Sample for Variances - Example Excel",
    "text": "F-Test Two-Sample for Variances - Example Excel\n\n\nExample: Dullus County School\n\nEnter A1: A27 in the Variable 1\nRange box.\nEnter B1:B17 in the Variable 2\nRange box.\nSelect Labels.\nEnter .05 in the Alpha box.\nSelect Output Range and enter\nD1 in the box.\nClick OK."
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#f-test-two-sample-for-variances---example-excel-3",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#f-test-two-sample-for-variances---example-excel-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "F-Test Two-Sample for Variances - Example Excel",
    "text": "F-Test Two-Sample for Variances - Example Excel\nResult:"
  },
  {
    "objectID": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#summary-1",
    "href": "lecture_slides/11_chapter_inference_pop_variance/11_chapter_inference_pop_variance.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nChi-Square Distribution\n\nThe chi-square distribution is used for interval estimation and hypothesis testing about a population variance.\nIt is the sum of squared standardized normal random variables.\nUnderstanding its dependence on sampling from a normal population and degrees of freedom.\n\nInterval Estimation of \\(\\sigma^2\\)\n\nIt is easy to convert the interval estimate of variance to an interval estimate of standard deviation.\n\nHypothesis Testing about a Population Variance\n\nWe use the chi-square distribution for the test statistic.\nWe can interpret results using both the critical value approach and the p-value approach."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#overview",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nIntroducion to Experimental Design\nAnalysis of Variance (ANOVA)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design",
    "text": "Experimental Design\n\n\nStatistical studies can be classified as being either experimental or observational.\nIn an experimental study, the levels of one or more factors are controlled so that data can be obtained about how the factors influence the response variables of interest.\n\nCause-and-effect relationships are easier to establish in experimental studies.\nAnalysis of variance (ANOVA) can be used to analyze the data obtained from experimental studies.\n\nIn an observational study, no attempt is made to control levels of the factors."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\nChemitech developed a new filtration system for municipal water supplies. There are different methods that can be used to assemble the system.\nChemitech has narrowed down to three methods: A, B, and C and wants to determine which assembly method can produce the greatest mean number of filtration systems per week."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\nRandomization and Replications\nFor the purpose, the company randomly selected 15 workers and randomly divided them into 3 groups, and then randomly assigned one of the three treatments to each group 5 of the workers.\n\n\n\nFactor\nAssembly method\n\n\n\n\nTreatments/Levels/Values\nA, B, and C\n\n\nResponse\nNumber of units produced\n\n\nExperimental units\nEmployees"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-2",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\nTerminology\n\nA factor is a variable that the experimenter has selected for investigation.\nA treatment is a level (value) of a factor.\nResponse or performance variable is a dependent/outcome variable affected by the factor.\nExperimental units are the objects of interest in the experiment.\nA completely randomized design is an experimental design in which the treatments are randomly assigned to the experimental units."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-3",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\n\n\n\nObservation\nA\nB\nC\n\n\n\n\n1\n58\n58\n48\n\n\n2\n64\n69\n57\n\n\n3\n55\n71\n59\n\n\n4\n66\n64\n47\n\n\n5\n67\n68\n49\n\n\nSample mean \\(\\bar{x}_j\\)\n62\n66\n52\n\n\nSample variance \\(s_j^2\\)\n27.5\n26.5\n31.0\n\n\nSample standard deviation \\(s_j\\)\n5.244\n5.148\n5.568\n\n\n\n\n\nGrand sample mean \\(\\bar{x}\\) = 60"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-4",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\n\nOne-way Analysis of Variance (ANOVA) can be used to test for the equality of means (mean responses) of two or more normal populations.\n\n\n\nThe hypotheses:\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3 = ... = \\mu_k\\)\n\\(H_a:\\) Not all population means are equal.\n\n where,\n\\((\\mu_1, \\mu_2, \\mu_3, ..., \\mu_k\\) are mean responses for the \\(k\\) populations.)\n\\((k = 3\\) for the motivating example.)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-5",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#experimental-design---example-chemitech-experiment-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Experimental Design - Example: Chemitech Experiment",
    "text": "Experimental Design - Example: Chemitech Experiment\n\n\nIf \\(H_0\\) is rejected, we cannot conclude that all population means are different.\n\n\n\nRejecting \\(H_0\\) means that at least two population means have different values, or not all means are equal."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-model-assumptions",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-model-assumptions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Model Assumptions",
    "text": "One-way ANOVA: Model Assumptions\n\nFor each population:\n\nThe response variable is normally distributed.\nThe mean of \\(i\\)-th population is \\(\\mu_i\\).\nThe variance of the response variable is the same for all of the populations; denoted \\(\\sigma^2\\) (unknown).\nThe observations must be independent."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-analysis-method",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-analysis-method",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Analysis Method",
    "text": "One-way ANOVA: Analysis Method\n\n\n\nIf the variation of the sample means is large, then not all population means are equal."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-analysis-method-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-analysis-method-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Analysis Method",
    "text": "One-way ANOVA: Analysis Method\n\nThere are two types of variation:\n\nBetween-treatments variation of sample means (\\(\\bar{x}_j\\)): Variation due to different treatments. (Explained variation)\nWithin-treatments variation of observations from their respective treatment means (Unexplained variation).\n\n\n\nThe F Test for \\(H_0\\) vs \\(H_a\\):\n\nIf Between-treatments variation is significantly larger than the Within-treatment variation, reject \\(H_0\\)."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-explained-between-treatments-variation-mstr",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-explained-between-treatments-variation-mstr",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Explained Between-Treatments Variation (MSTR)",
    "text": "One-way ANOVA: Explained Between-Treatments Variation (MSTR)\n\n\nThe variation in the sample means is measured by the mean square due to treatments and is denoted by MSTR.\n\n\\[\n\\text{MSTR} = \\frac{\\text{Sum of squares due to treatments (SSTR)}}{\\text{Degrees of freedom of SSTR}} = \\frac{\\sum_{j=1}^k n_j(\\bar{x}_j - \\bar{x})^2}{k - 1}\n\\]\n\\[\n= \\frac{5(62 - 60)^2 + 5(66 - 60)^2 + 5(52 - 60)^2}{3 - 1} = \\frac{520}{2} = 260\n\\]"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-unexplained-within-treatments-variation-mse",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-unexplained-within-treatments-variation-mse",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Unexplained Within-Treatments Variation (MSE)",
    "text": "One-way ANOVA: Unexplained Within-Treatments Variation (MSE)\n\nThe variation of the sample observations within each sample is called the mean square error (MSE).\nA measure of sampling variation.\n\n\\[\n\\text{MSE} = \\frac{\\text{Sum of squares due to unexplained error (SSE)}}{\\text{Degrees of freedom of SSE}} = \\frac{\\sum_{j=1}^k (n_j - 1) s_j^2}{n_T - k}\n\\]\n\\[\n= \\frac{(5-1)(27.5) + (5-1)(26.5) + (5-1)(31)}{15-3} = \\frac{340}{12} = 28.33\n\\]\n\\((n_T = 15 \\text{ is the total sample size.})\\)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-test-statistic-and-decision-rule",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-test-statistic-and-decision-rule",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Test Statistic and Decision Rule",
    "text": "One-way ANOVA: Test Statistic and Decision Rule\n\nTest statistic:\n\nIf MSTR is large, we will reject \\(H_0\\); but we need to take the sampling variation (MSE) into account.\nF statistic: \\(F = \\frac{MSTR}{MSE}\\)\n\nDecision rule:\n\nMSE is always a good estimate of the common population variance \\(\\sigma^2\\).\nIf \\(H_0\\) is false (not all means are equal), MSTR overestimates \\(\\sigma^2\\) and is expected to be much larger than MSE.\nReject \\(H_0\\) if \\(F = \\frac{MSTR}{MSE}\\) is too large."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-the-f-test",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-the-f-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: The F Test",
    "text": "One-way ANOVA: The F Test\n\nThe distribution of the test statistic:\n\n\\[\nF = \\frac{MSTR}{MSE}\n\\]\n\nIf the null hypothesis is true and the ANOVA assumptions are valid, the sampling distribution of the test statistic is an F distribution with \\(k-1\\) (numerator) and \\(n_T - k\\) (denominator) degrees of freedom.\n\n\n\nDecision Rule: Reject \\(H_0\\) if the observed \\(F &gt; F_{\\alpha, k-1, n_T-k}\\) (right-tail),\n\nwhere \\(F_{\\alpha, k-1, n_T-k} = \\text{F.INV}(1-\\alpha, k-1, n_T-k)\\)."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-the-f-test-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-the-f-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: The F Test",
    "text": "One-way ANOVA: The F Test\n\n\n\nObserved F-ratio = 9.18\np-value = 1–F.DIST(9.18,2,12,TRUE) \\(\\approx\\) 0.004"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-decision-rules",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-decision-rules",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Decision Rules",
    "text": "One-way ANOVA: Decision Rules\n\n\np-value approach: Reject \\(H_0\\) if \\(p\\)-value \\(\\leq \\alpha\\)\n\n\n\nCritical-value approach: Reject \\(H_0\\) if \\(F \\geq F_{\\alpha}\\)\n\nwhere the critical value \\(F_{\\alpha}\\) is based on an F distribution with \\(k-1\\) numerator d.f. and \\(n_T - k\\) denominator d.f.\n\nIn our example, \\(F_{0.05,2,12} = \\text{F.inv}(0.95,2,12) = 3.89\\), and \\(9.18 &gt; 3.89\\).\n\nConclusion: We have statistically significant evidence that at least one pair of the assembly methods produced different mean numbers of filtration systems per week. The significance level is 5%."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: ANOVA Table",
    "text": "One-way ANOVA: ANOVA Table\n\n\nANOVA can be viewed as the process of partitioning the total sum of squares and the degrees of freedom into their corresponding sources: treatments and error.\nDividing the sum of squares by the appropriate degrees of freedom provides the variance estimates, the \\(F\\) value, and the \\(p\\)-value used to test the hypothesis of equal population means."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: ANOVA Table",
    "text": "One-way ANOVA: ANOVA Table\n\n\nAssuming \\(H_0\\) is true, the entire data set is basically one sample from one population, the formula for computing the total sum of squares (SST) is:\n\n\\[\n\\text{SST} = \\sum_{j=1}^k \\sum_{i=1}^{n_j} (x_{ij} - \\bar{x})^2 = (n_T - 1) s_x^2 = 860\n\\]\n\\[\n= \\text{SSTR} + \\text{SSE} = 520 + 340\n\\]\n\nSST has \\(n_T - 1 = 15 - 1 = 14 (= 2 + 12)\\) degrees of freedom."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-2",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: ANOVA Table",
    "text": "One-way ANOVA: ANOVA Table\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3\\)\n\\(H_a:\\) Not all the means are equal\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\nSum of Squares\nDegrees of Freedom\nMean Square\n\\(F\\)\np-Value\n\n\n\n\nTreatments\n\\(SSTR\\)\n\\(df_1\\)\n\\(\\text{MSTR}=\\frac{\\text{SSTR}}{df_1}\\)\n\\(\\frac{MSTR}{MSE}\\)\n\\(1-\\text{F.DIST}(F, k-1, n_T-k, \\text{TRUE})\\)\n\n\nError\n\\(SSE\\)\n\\(df_2\\)\n\\(\\text{MSE}=\\frac{\\text{SSE}}{df_2}\\)\n\n\n\n\nTotal\n\\(SST=SSTR+SSE\\)\n\\(df_3=df_1+df_2\\)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-3",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: ANOVA Table",
    "text": "One-way ANOVA: ANOVA Table\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3\\)\n\\(H_a:\\) Not all the means are equal\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\nSum of Squares\nDegrees of Freedom\nMean Square\n\\(F\\)\np-Value\n\n\n\n\nTreatments\n\\(\\sum_{j=1}^k n_j (\\bar{x}_j - \\bar{x})^2\\)\n\\(k - 1\\)\n\\(\\frac{\\text{SSTR}}{k - 1}\\)\n\\(\\frac{\\text{MSTR}}{\\text{MSE}}\\)\n\\(1-\\text{F.DIST}(F, k-1, n_T-k, \\text{TRUE})\\)\n\n\nError\n\\(\\sum_{j=1}^k (n_j - 1) s_j^2\\)\n\\(n_T - k\\)\n\\(\\frac{\\text{SSE}}{n_T - k}\\)\n\n\n\n\nTotal\n\\(\\sum_{j=1}^k \\sum_{i=1}^{n_j} (x_{ij} - \\bar{x})^2\\)\n\\(n_T - 1\\)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-4",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-anova-table-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: ANOVA Table",
    "text": "One-way ANOVA: ANOVA Table\n\n\\(H_0: \\mu_1 = \\mu_2 = \\mu_3\\)\n\\(H_a:\\) Not all the means are equal\n\n\n\n\n\n\n\n\n\n\n\n\nSource of Variation\nSum of Squares\nDegrees of Freedom\nMean Square\n\\(F\\)\np-Value\n\n\n\n\nTreatments\n520\n2\n260.00\n9.18\n.004\n\n\nError\n340\n12\n28.33\n\n\n\n\nTotal\n860\n14"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-other-applications",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#one-way-anova-other-applications",
    "title": " MGMT 30500: Business Statistics ",
    "section": "One-way ANOVA: Other Applications",
    "text": "One-way ANOVA: Other Applications\n\nMean sales of companies using four (4) different advertising methods (spot TV, newspapers, flyers, magazines).\nMean quality levels of products from several vendors.\nYields of several processes (machines).\nMean completion times of different methods.\nMean waiting times of several lines in a bank.\nMean selling price of houses in different school districts.\nMean response time of a service request for several companies.\nMean ages between floor workers, middle managers, and executives.\nMean improvement or learning outcome measures between several training/teaching methods (in-person, online, hybrid, weekend program)."
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel’s ANOVA: Single Factor Tool",
    "text": "Excel’s ANOVA: Single Factor Tool\n\nStep 1: Open Assembly.xlsx, and, on Sheet 2, click the Data tab on the Ribbon\nStep 2: In the Analysis group, click Data Analysis\nStep 3: Choose Anova: Single Factor from the list of Analysis Tools\nStep 4: When the Anova: Single Factor dialog box appears: (see details on next slide)"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel’s ANOVA: Single Factor Tool",
    "text": "Excel’s ANOVA: Single Factor Tool"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool-2",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#excels-anova-single-factor-tool-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel’s ANOVA: Single Factor Tool",
    "text": "Excel’s ANOVA: Single Factor Tool\nSummary and Output data"
  },
  {
    "objectID": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#summary-1",
    "href": "lecture_slides/13_chapter_one_way_anova/13_chapter_one_way_anova.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nExperimental Design: allow for control over variables, enabling the establishment of cause-and-effect relationships.\n\nObservational studies do not control variables, limiting conclusions about causality.\n\nANOVA: Is a statistical method used to test for differences in means across multiple groups.\n\nIt partitions the variance into components due to treatments and error, facilitating hypothesis testing.\n\nANOVA Assumptions and Decision Making:\n\nAssumptions include normal distribution, equal variances, and independence of observations.\nDecision rules are based on comparing the calculated F-statistic to a critical value or p-value to accept or reject the null hypothesis."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#overview",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nSimple Linear Regression Model\nLeast Squares Method\nCoefficient of Determination\nModel Assumptions\nTesting for Significance\n\n\n\nExcel’s Regression Tool\nUsing the Estimated Regression Equation for Estimation and Prediction\nResidual Analysis: Validating Model Assumptions\nOutliers and Influential Observations"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#covariance",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#covariance",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Covariance",
    "text": "Covariance\n\n\n\n\nThe Covariance is a measure of the linear association between two variables.\nPositive values indicate a positive relationship.\nNegative values indicate a negative relationship."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#correlation-coefficient",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#correlation-coefficient",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Correlation Coefficient",
    "text": "Correlation Coefficient\n\n\n\nCorrelation is a unit-free measure of linear association and not necessarily causation.\nThe coefficient can take on values between −1 and +1.\n\nValues near −1 indicate a strong negative linear relationship.\nValues near +1 indicate a strong positive linear relationship.\n\nThe closer the correlation is to zero, the weaker the linear relationship."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-is-a-model",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-is-a-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What is a model?",
    "text": "What is a model?\n\n\n\n\n\n\n\nAll models are wrong, but some are useful.\n— George Box\n\n\n\n\n\n\n\n\n\n\n\n\nNY City Subway Map"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-does-it-mean-to-model-data",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-does-it-mean-to-model-data",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What does it mean to “model” data?",
    "text": "What does it mean to “model” data?\n\n\nLet’s start with a very simple premise:\n\nto model, we need to make explicit the conditions under which a variable \\(X\\) is related to a variable \\(Y\\).\n\n\n\n\nLet’s begin by giving specific names to these variables:\n\nDependent Variable (DV): This is our phenomenon of interest, usually denoted as \\(Y\\).\nIndependent Variable (IV): This is the phenomenon that explains/describe our dependent variable, generally denoted as \\(X\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-does-it-mean-to-model-data-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#what-does-it-mean-to-model-data-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What does it mean to “model” data?",
    "text": "What does it mean to “model” data?\n\nMathematically, we model \\(Y\\) as a function of \\(X\\). Statistically, modeling can serve two main purposes:\n\nPrediction: The possibility of using the values of \\(X\\) to predict the value of \\(Y\\). There must be a substantive connection between these two variables for one to generate reliable predictions about the values of the other.\nExplanation: Used to understand the connection and significance (both substantive and statistical) of the relationship between two variables. In this case, we aim to accurately estimate the impact of one variable on the other, preferably excluding any potential omitted variables."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Walmart Carton-Mix Optimization Study",
    "text": "Motivation: Walmart Carton-Mix Optimization Study\n\n\nWalmart is the world’s largest retailer with over 245 million customers weekly.\nIn 2000, Walmart launched its online shopping site, Walmart.com.\nA network of distribution centers was created in the US to manage packaging for online orders."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Walmart Carton-Mix Optimization Study",
    "text": "Motivation: Walmart Carton-Mix Optimization Study\n\nCarton-Mix Optimization Study\n\nLocation: Carrollton, Georgia distribution center.\nObjective: Minimize material, labor, and shipping costs by optimizing the size and number of cartons.\nConstraints:\n\nMinimum and maximum carton sizes.\nOne-size carton limit for automatically constructed cartons.\n\nPeak Season: November to December, with over 100,000 packages shipped per day."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Walmart Carton-Mix Optimization Study",
    "text": "Motivation: Walmart Carton-Mix Optimization Study\n\nData was collected to develop a cost model for optimizing carton mix.\nDV: material cost of a carton in dollars per carton.\nIV: volume of the carton measured in cubic inches per carton.\nCost Model Formula:\n\n\\[\ny = -0.11 + 0.0014x\n\\]\n\nExample Calculation:\n\nCarton volume: 2800 cubic inches\nEstimated material cost: \\(y = -0.11 + 0.0014 \\times 2800 = 3.81\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-4",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#motivation-walmart-carton-mix-optimization-study-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Motivation: Walmart Carton-Mix Optimization Study",
    "text": "Motivation: Walmart Carton-Mix Optimization Study\nImplementation and Results\n\nThe regression model was used in an optimization algorithm in Microsoft Excel to provide Walmart managers a recommendation on the optimal mix of carton sizes to carry at the distribution center.\n\nResults:\n\nFirst-year savings: $600,000\nEstimated annual savings across all distribution centers: $2 million"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\n\n\nManagerial decisions often are based on the relationship between two or more variables.\nRegression analysis can be used to develop an equation (as a conjecture) for the relationship between the variables.\n\nThe variable being predicted is called the dependent variable and is denoted by y.\nThe variables being used to predict the value of the dependent variable are called the independent variables and are denoted by x."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\n\n\nSimple linear regression involves one independent variable and one dependent variable.\nThe relationship between the two variables is linear, approximated by a straight line.\n\nAs an initial estimate of the unknown relationship.\nA regression analysis is a trial-and-error exercise.\n\nRegression analysis involving two or more independent variables is called multiple regression."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#regression-objective",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#regression-objective",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Regression Objective",
    "text": "Regression Objective\n\n\nInterpretation: Determine whether variation in the dependent variable can be explained by (the variation of) the independent variable(s) by testing the statistical significance of the independent variable(s):\n\nAs a group (F-test).\nIndividually (t-tests).\n\nPrediction: Study how to predict the dependent variable given the information of the independent variable(s)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#applications",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#applications",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Applications",
    "text": "Applications\n\n\nRevenue vs. Advertising expenditure\nTotal cost vs. production quantity (variable and fixed costs)\nNFL: Annual revenue vs. estimated team value\nTotal points earned vs. hours spent studying\nNumber of days absent vs. distance to work\nNumber of defective parts vs. line speed\nMaintenance cost vs. age of the equipment\nSale price of 2007 Camry vs. mileage\nSales vs. promotion activities and Price\n(Beta risk) Total return of an individual stock vs. total return for the stock market\nOutput vs. input"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-model",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression Model",
    "text": "Simple Linear Regression Model\n\n\nThe equation that describes how y is related to x and an error term is called the regression model.\nThe simple linear regression model for the data is:\n\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\]\nwhere:\n\n\\(\\beta_0\\) and \\(\\beta_1\\) are the unknown parameters of the model,\n\\(\\epsilon\\) is a random variable called the error term (unexplained error), with mean of 0 and unknown error variance \\(\\sigma^2\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-equation",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression Equation",
    "text": "Simple Linear Regression Equation\n\n\nThe Simple Linear Regression Equation is:\n\n\\[\nE(y) = \\beta_0 + \\beta_1 x\n\\]\nGraph of the regression equation is a straight line.\n\n\\(E(y)\\) is the expected value of y for a given x value\n\\(\\beta_0\\) is the y intercept of the regression line (unknown)\n\\(\\beta_1\\) is the slope of the regression line (unknown)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-equation-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#simple-linear-regression-equation-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Simple Linear Regression Equation",
    "text": "Simple Linear Regression Equation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPositive Linear Relationship\n\n\n\n\n\n\n\n\n\n\n\n\n\nNegative Linear Relationship\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo Linear Relationship"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#estimated-simple-linear-regression-equation",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#estimated-simple-linear-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimated Simple Linear Regression Equation",
    "text": "Estimated Simple Linear Regression Equation\n\nThe estimated simple linear regression equation:\n\\[\n\\hat{y} = b_0 + b_1 x\n\\]\nThe graph is called the estimated/predicted regression line.\n\n\\(\\hat{y}\\) is the estimated/predicted value of y for a given x value.\n\\(b_0\\) is the y-intercept of the line, estimating \\(\\beta_0\\)\n\\(b_1\\) is the slope of the line, estimating \\(\\beta_1\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#random-error-epsilon-and-observed-residual-e",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#random-error-epsilon-and-observed-residual-e",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Random Error (\\(\\epsilon\\)) and Observed Residual (\\(e\\))",
    "text": "Random Error (\\(\\epsilon\\)) and Observed Residual (\\(e\\))"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#estimation-process",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#estimation-process",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Estimation Process",
    "text": "Estimation Process"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residualserrors",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residualserrors",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residuals/Errors",
    "text": "Residuals/Errors"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Least Squares Method",
    "text": "Least Squares Method\n\n\\(y_i\\) = observed value of the dependent variable for the i-th observation.\n\\(\\hat{y}_i\\) = estimated value of the dependent variable for the i-th observation.\n\\[\n\\text{Error or Residual} = \\text{Observed} - \\text{Predicted} = y_i - \\hat{y}_i\n\\]\n\nLeast Squares Criterion: To minimize the Sum of Squared Errors (SSE)\n\n\\[\n\\min SSE = \\min \\sum (y_i - \\hat{y}_i)^2 = \\min \\sum (y_i - b_0 - b_1 x_i)^2\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Least Squares Method",
    "text": "Least Squares Method\n\nSlope for the Estimated Regression Equation\n\\[\nb_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2}\n\\]\nwhere:\n\n\\(x_i\\) = value of independent variable for i-th observation\n\\(y_i\\) = value of dependent variable for i-th observation\n\\(\\bar{x}\\) = mean value for independent variable\n\\(\\bar{y}\\) = mean value for dependent variable"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#least-squares-method-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Least Squares Method",
    "text": "Least Squares Method\n\ny-Intercept for the Estimated Regression Equation\n\\[\nb_0 = \\bar{y} - b_1 \\bar{x}\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#regression-modeling-steps",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#regression-modeling-steps",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Regression Modeling Steps",
    "text": "Regression Modeling Steps\n\n\n\nDefine problem and propose model\nMake model assumptions\nCollect data\nDo descriptive data analysis\nObtain the prediction equation and evaluate the model\n\nEstimate the regression coefficients\nCheck adequacy of the overall model\nTest significance of the overall model and the individual independent variables\nResidual Analysis: Validate the model assumptions\n\nSpecial issues (in multiple regression)\n\nMulticollinearity and variables selection\n\nSpecial models and transformations (for model-building)\n(Repeat Steps 1-7 if necessary.)\nPrediction, Implementation, …"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example\n\nExample: Armand’s Pizza Parlor Restaurants\nData was collected from a sample of 10 Armand’s Pizza Parlor Restaurants near college campuses.\nFor the i-th observation or restaurant in the sample:\n\n\\(x_i\\) is the size of the student population\n\\(y_i\\) is the quarterly sales."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example\n\n\n\nRestaurant\nStudent population (1000s)\nQuarterly sales ($1000s)\n\n\n\n\n1\n2\n58\n\n\n2\n6\n105\n\n\n3\n8\n88\n\n\n4\n8\n118\n\n\n5\n12\n117\n\n\n6\n16\n137\n\n\n7\n20\n157\n\n\n8\n20\n169\n\n\n9\n22\n149\n\n\n10\n26\n202"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-excel",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example Excel",
    "text": "Linear Regression: Example Excel\n\nExample: Armand’s Pizza Parlor Restaurants"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example\n\n\n\n\nMetric\nPopulation\nSales\n\n\n\n\nMean\n14\n130\n\n\nStandard Error\n2.512\n13.220\n\n\nMedian\n14\n127.5\n\n\nMode\n8\nN/A\n\n\nStandard Deviation\n7.944\n41.806\n\n\nSample Variance\n63.111\n1747.778\n\n\nKurtosis\n-1.332\n-0.033\n\n\nSkewness\n0\n-0.014\n\n\nRange\n24\n144\n\n\nMinimum\n2\n58\n\n\nMaximum\n26\n202\n\n\nSum\n140\n1300\n\n\nCount\n10\n10\n\n\nConfidence Level (95%)\n5.683\n29.907"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-excel-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-excel-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example Excel",
    "text": "Linear Regression: Example Excel\n\n\n\n\nProducing a Scatter Diagram\n\nStep 1: Select cells B2:C11\nStep 2: Click the Insert tab on the Ribbon\nStep 3: In the Charts group, select Insert Scatter (X,Y) or Bubble Chart\nStep 4: When the list of scatter diagram subtypes appears, select Scatter (chart in upper left corner)\n\n\n\n\n\n\nEditing a Scatter Diagram\n\nStep 1: Click the Chart Title and replace it with Armand’s Pizza Parlors\nStep 2: Click the Chart Elements button\nStep 3: When the list of chart elements appears:\n\nClick Axis Titles (creates placeholders for titles)\nClick Gridlines (to deselect gridlines option)\nClick Trendline\n\nStep 4: Click the horizontal Axis Title and replace it with Student population (1000s)\nStep 5: Click the Vertical (Value) Axis Title and replace it with Quarterly Sales ($1000s)\nStep 6: Select the Format Trendline option\nStep 7: When the Format Trendline dialog box appears:\n\nSelect Display equation on chart\nClick the Fill & Line button\nIn the Dash type box, select Solid\nClose the Format Trendline dialog box"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-4",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ni\n\\(x_i\\)\n\\(y_i\\)\n\\(x_i - \\bar{x}\\)\n\\(y_i - \\bar{y}\\)\n\\((x_i - \\bar{x})(y_i - \\bar{y})\\)\n\\((x_i - \\bar{x})^2\\)\n\\((y_i - \\bar{y})^2\\)\n\n\n\n\n1\n2\n58\n-12\n-72\n864\n144\n5184\n\n\n2\n6\n105\n-8\n-25\n200\n64\n625\n\n\n3\n8\n88\n-6\n-42\n252\n36\n1764\n\n\n4\n8\n118\n-6\n-12\n72\n36\n144\n\n\n5\n12\n117\n-2\n-13\n26\n4\n169\n\n\n6\n16\n137\n2\n7\n14\n4\n49\n\n\n7\n20\n157\n6\n27\n162\n36\n729\n\n\n8\n20\n169\n6\n39\n234\n36\n1521\n\n\n9\n22\n149\n8\n19\n152\n64\n361\n\n\n10\n26\n202\n12\n72\n864\n144\n5184\n\n\nTotal\n140\n1300\n-\n-\n2840\n568\n15730\n\n\n\n\nSample correlation:\n\\[\nr_{xy} = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i - \\bar{x})^2 \\sum(y_i - \\bar{y})^2}} = \\frac{2840}{\\sqrt{568 \\times 15730}} = 0.9501\n\\]\n\n= correl(x-array, y-array)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-5",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#linear-regression-example-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Regression: Example",
    "text": "Linear Regression: Example\n\n\nSlope for the Estimated Regression Equation\n\n\\[\nb_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2} = \\frac{2840}{568} = 5\n\\]\n\ny-Intercept for the Estimated Regression Equation\n\n\\[\nb_0 = \\bar{y} - b_1 \\bar{x} = 130 - 5(14) = 60\n\\]\n\nEstimated Regression Equation\n\n\\[\n\\hat{y} = 60 + 5x\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#remarks",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#remarks",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Remarks",
    "text": "Remarks\n\n\n\\[\nb_1 = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y}) / (n - 1)}{\\sum (x_i - \\bar{x})^2 / (n - 1)} = \\frac{s_{xy}}{s_x^2}\n\\]\n\\[\n= \\frac{s_{xy}}{s_x s_y} \\cdot \\frac{s_y}{s_x} = r_{xy} \\frac{s_y}{s_x}\n\\]\n\\(b_1\\), \\(s_{xy}\\), and \\(r_{xy}\\) have the same signs, reflecting the relationship’s direction between \\(x\\) and \\(y\\).\n\n\n\n\\(b_1\\): Slope of the regression line, indicating the change in \\(y\\) for a unit change in \\(x\\).\n\\(\\sum (x_i - \\bar{x})(y_i - \\bar{y})\\): Numerator for covariance, showing the joint deviation of \\(x\\) and \\(y\\) from their means.\n\\(\\sum (x_i - \\bar{x})^2\\): Denominator representing variance of \\(x\\).\n\\(s_{xy}\\): Sample covariance, indicating how \\(x\\) and \\(y\\) vary together.\n\\(s_x^2\\): Sample variance of \\(x\\), measuring the dispersion of \\(x\\) around its mean.\n\\(s_x\\) and \\(s_y\\): Standard deviations of \\(x\\) and \\(y\\), showing spread around their means.\n\\(r_{xy}\\): Correlation coefficient, measuring strength and direction of the linear relationship between \\(x\\) and \\(y\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Partition of Total Variation",
    "text": "Partition of Total Variation"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Partition of Total Variation",
    "text": "Partition of Total Variation\n\nPrediction equation: \\(\\hat{y} = 60 + 5x\\)\nFor Observation #1 \\((x = 2, y = 58)\\): \\(\\hat{y} = 60 + 5(2) = 70\\)\n\nUnexplained error/residual = \\(y - \\hat{y} = 58 - 70 = -12\\)\n\n\n\n\nNote:\n\n\\[\ny - \\bar{y} = (\\hat{y} - \\bar{y}) + (y - \\hat{y})\n\\]\n\\[\n58 - 130 = (70 - 130) + (58 - 70)\n\\]\n\\[\n\\text{Total} = \\text{Explained} + \\text{Unexplained}\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#partition-of-total-variation-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Partition of Total Variation",
    "text": "Partition of Total Variation\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)\n\\(x_i\\)\nObserved Y\nPredicted Y\nTotal\nExplained\nUnexplained\n\n\n\n\n1\n2\n58\n70\n-72\n-60\n-12\n\n\n2\n6\n105\n90\n-25\n-40\n15\n\n\n3\n8\n88\n100\n-42\n-30\n-12\n\n\n4\n8\n118\n100\n-12\n-30\n18\n\n\n5\n12\n117\n120\n-13\n-10\n-3\n\n\n6\n16\n137\n140\n7\n10\n-3\n\n\n7\n20\n157\n160\n27\n30\n-3\n\n\n8\n20\n169\n160\n39\n30\n9\n\n\n9\n22\n149\n170\n19\n40\n-21\n\n\n10\n26\n202\n190\n72\n60\n12\n\n\n\nMean Y\n130\nSum of square\n15730\n14200\n1530\n\n\n\n\n\n\nSST\nSSR\nSSE"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#derivation-of-the-total-sum-of-squares-sst",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#derivation-of-the-total-sum-of-squares-sst",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Derivation of the Total Sum of Squares (SST)",
    "text": "Derivation of the Total Sum of Squares (SST)\n\nIn the context of simple linear regression, the Total Sum of Squares (SST) is defined as the sum of the squared deviations of the observed \\(y\\) values from their sample mean \\(\\bar{y}\\):\n\\[\nSST = \\sum_{i=1}^{n} (y_i - \\bar{y})^2.\n\\]\nIt is also possible to compute the SST with the following:\n\\[\nSST = (n-1)s^2_y,\n\\]\nDerivation\nRecall that the sample variance of \\(y\\), denoted \\(s^2_y\\), is defined as:\n\\[\ns^2_y = \\frac{1}{n-1}\\sum_{i=1}^{n} (y_i - \\bar{y})^2.\n\\]\nThis definition uses \\(n-1\\) in the denominator to provide an unbiased estimator of the population variance.\nBy multiplying both sides of the sample variance definition by \\(n-1\\), we obtain:\n\\[\n(n-1)s^2_y = \\sum_{i=1}^{n} (y_i - \\bar{y})^2.\n\\]\nRecognizing that the right-hand side is exactly the definition of \\(SST\\), we conclude:\n\\[\nSST = (n-1)s^2_y.\n\\]\nThus, the derivation relies on the definition of sample variance, and the result follows directly from the algebraic manipulation."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\n\nRelationship Among SST, SSR, SSE\n\n\\[\n\\text{SST} = \\text{SSR} + \\text{SSE}\n\\]\n\\[\n\\sum(y_i - \\bar{y})^2 = \\sum(\\hat{y}_i - \\bar{y})^2 + \\sum(y_i - \\hat{y}_i)^2\n\\]\n\\[\n\\text{Degrees of freedom:} \\quad n-1 \\quad\\quad\\quad\\quad\\quad 1 \\quad\\quad\\quad\\quad\\quad n-2 \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\n\\]\nwhere:\n\nSST = total sum of squares (Total variation)\nSSR = sum of squares due to regression (Explained variation)\nSSE = sum of squares due to error (Unexplained variation)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\n\nThe coefficient of determination is:\n\n\\[\nR^2 = \\frac{\\text{Explained variation}}{\\text{Total variation}} = \\frac{\\text{SSR}}{\\text{SST}}\n\\]\nwhere:\n\nSSR = sum of squares due to regression\nSST = total sum of squares"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Coefficient of Determination",
    "text": "Coefficient of Determination\nExample: Armand’s Pizza Parlor Restaurants\n\\[\nR^2 = \\frac{\\text{SSR}}{\\text{SST}} = \\frac{14200}{15730} = 0.9027 = 90.27\\%\n\\]\n\\[\nR^2 = 1 - \\frac{\\text{SSE}}{\\text{SST}} = 1 - \\frac{1530}{15730} = 1 - 0.973 = 90.27\\%\n\\]\n\nThe regression relationship is very strong;\n90.27% of the variability in the sales can be explained by (the variability of) the size of the student population through the proposed linear relationship between them."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-excel",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#coefficient-of-determination-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Coefficient of Determination: Excel",
    "text": "Coefficient of Determination: Excel\n\n\n\n\nAdding \\(R^2\\) Value to Scatter Diagram\n\nStep 1: Right-click on the trendline and select the Format Trendline option\nStep 2: When the Format Trendline dialog box appears:\n\nSelect Display R-squared on chart\nClose the Format Trendline dialog box"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sample-correlation-coefficient",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sample-correlation-coefficient",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Correlation Coefficient",
    "text": "Sample Correlation Coefficient\n\\[\nr_{xy} = (\\text{sign of } b_1) \\sqrt{\\text{Coefficient of Determination}}\n\\]\n\\[\nr_{xy} = (\\text{sign of } b_1) \\sqrt{R^2}\n\\]\nwhere:\n\n\\(b_1\\) = the slope of the estimated regression equation \\(\\hat{y} = b_0 + b_1x\\)\n\nOnly in simple regression."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sample-correlation-coefficient-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sample-correlation-coefficient-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sample Correlation Coefficient",
    "text": "Sample Correlation Coefficient\nExample: Armand’s Pizza Parlor Restaurants\n\\[\nr_{xy} = (\\text{sign of } b_1) \\sqrt{R^2}\n\\]\nThe sign of \\(b_1\\) in the equation \\(\\hat{y} = 10 + 5x\\) is “+”.\n\\[\nr_{xy} = +\\sqrt{0.9027}\n\\]\n\\[\nr_{xy} = +0.9501\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#assumptions-about-the-error-term-epsilon",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#assumptions-about-the-error-term-epsilon",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Assumptions About the Error Term \\(\\epsilon\\)",
    "text": "Assumptions About the Error Term \\(\\epsilon\\)\n\nThe error term \\(\\epsilon\\) is a random variable with a mean or expected value of zero; that is, \\(E(\\epsilon) = 0\\).\n\nImplication: \\(\\beta_0\\) and \\(\\beta_1\\) are constants; therefore \\(E(\\beta_0) = \\beta_0\\) and \\(E(\\beta_1) = \\beta_1\\); thus, for a given value of \\(x\\), the expected value of \\(y\\) is:\n\n\n\n\\[\n   E(y) = \\beta_0 + \\beta_1x\n\\]\n\n\nThe variance of \\(\\epsilon\\), denoted by \\(\\sigma^2\\), is the same for all values of \\(x\\).\n\nImplication: The variance of \\(y\\) about the regression line equals \\(\\sigma^2\\) and is the same for all values of \\(x\\).\n\nThe values of \\(\\epsilon\\) are independent.\n\nImplication: The value of \\(\\epsilon\\) for a particular value of \\(x\\) is not related to the value of \\(\\epsilon\\) for any other value of \\(x\\); thus, the value of \\(y\\) for a particular value of \\(x\\) is not related to the value of \\(y\\) for any other value of \\(x\\).\n\nThe error term \\(\\epsilon\\) is a normally distributed random variable for all values of \\(x\\).\n\nImplication: Because \\(y\\) is a linear function of \\(\\epsilon\\), \\(y\\) is also a normally distributed random variable for all values of \\(x\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#assumptions-about-the-error-term-epsilon-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#assumptions-about-the-error-term-epsilon-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Assumptions About the Error Term \\(\\epsilon\\)",
    "text": "Assumptions About the Error Term \\(\\epsilon\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Significance",
    "text": "Testing for Significance\n\n\nTo test for a significant regression relationship, we must conduct a hypothesis test to determine whether the unknown \\(\\beta_1\\) is zero.\nTwo equivalent Tests are commonly used in simple regression:\n\n\\(t\\) Test\n\n\\(F\\) test\n\nBoth the \\(t\\) test and \\(F\\) test require an estimate of the unknown error variance \\(\\sigma^2\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Significance",
    "text": "Testing for Significance\n\nIdea: Estimating the population error variance (\\(\\sigma^2\\)) by the sample residual variance (denoted by \\(s^2\\) or MSE).\nThe mean square error (MSE), or \\(s^2\\) is:\n\\[\ns^2 = \\text{MSE} = \\frac{\\text{SSE}}{(n-2)}, \\quad \\text{SSE = Sum of Squared Errors (unexplained variation).}\n\\]\nwhere:\n\\[\n\\text{SSE} = \\sum e_i^2 = \\sum (y_i - \\hat{y}_i)^2\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-significance-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Significance",
    "text": "Testing for Significance\n\nAn Estimate of \\(\\sigma\\)\n\nTo estimate \\(\\sigma\\), we take the square root of \\(s^2\\).\nThe resulting \\(s\\) is called the standard error (of the estimate).\n\n\n\\[\ns = \\sqrt{MSE} = \\sqrt{\\frac{SSE}{n - 2}} = \\sqrt{\\frac{\\sum (y_i - \\hat{y}_i)^2}{n - 2}}\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\n\n\nHypotheses\n\\[ H_0 : \\beta_1 = 0 \\quad\\] The proposed linear model is insignificant; No linear relationship; the predictor is insignificant; the predictor explains no variation in the response.\n\\[ H_a : \\beta_1 \\neq 0 \\]\nTest Statistic\n\n\\[\nF = \\frac{SSR / 1}{SSE / (n-2)} = \\frac{MSR}{MSE} \\quad \\text{follows } F(1, n-2), \\text{ if } H_0 \\text{ is true.}\n\\] where\n\nSSR (Sum of Squares for Regression): measures how much of the variation in the dependent variable is explained by the independent variable(s).\nMSR (Mean Square Regression): is the average variation explained by the model per degree of freedom for the regression.In the case above, we have only one independent variable as the degree of freedom for the regression (denominator).\nSSE (Sum of Squares for Error/Residuals): measures the variation in the response variable that is not explained by the model.\nMSE (Mean Square Error): is the average variation that remains unexplained by the model, per degree of freedom for the error. The degrees of freedom for the error is the number of observations (\\(n\\)) in the data set minus the number of parameters being estimated (\\(\\beta_0\\) and \\(\\beta_1\\))."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\n\nDecision Rules (right-tail):\n\nReject \\(H_0\\) if \\(p\\text{-value} \\leq \\alpha\\), or \\(F \\geq F_{\\alpha, 1, n-2}\\)\n\n\n\nwhere:\n\n\\(F_{\\alpha, 1, n-2}\\) is based on an \\(F\\) distribution with 1 degree of freedom in the numerator and \\(n - 2\\) degrees of freedom in the denominator.\n\\(F_{\\alpha, 1, n-2} = F.\\text{INV}(1-\\alpha, 1, n - 2)\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-overall-significance-f-test-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Overall Significance: \\(F\\) Test",
    "text": "Testing for Overall Significance: \\(F\\) Test\n\nCompute the value of the test statistic.\n\n\\[\nF = \\frac{SSR / 1}{SSE / (n-2)} = \\frac{14,200 / 1}{1,530 / (10-2)} = 74.25\n\\]\n\n\nDecision.\n\n\\(F_{\\alpha} = F.\\text{INV}(0.99,1,8) = 11.26\\) and \\(F = 74.25 &gt; 11.26.\\) We reject \\(H_0.\\)\n\\(p\\text{-value} = 1 - F.\\text{DIST}(74.25,1,8, \\text{TRUE}) \\approx 0.000 &lt; 1\\% = \\alpha\\)\n\n\n\n\nThe statistical evidence is sufficient to conclude that a significant relationship exists between the size of the student population and quarterly sales. The significance level is \\(\\alpha = 1\\%\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\n\n\nIn regression, \\(b_1\\) follows a normal distribution with mean \\(\\beta_1\\).\n\n\nHypotheses\n\\(H_0 : \\beta_1 = 0 \\quad (\\text{Independent variable x is insignificant})\\)\n\\(H_a : \\beta_1 \\neq 0\\)\nTest Statistic\n\n\\[\nt = \\frac{b_1 - 0}{s_{b_1}},\n\\] where \\(s_{b_1}\\) is the standard error of the slope estimate \\(b_1\\), i.e., an estimate of the standard deviation of the sampling distribution of \\(b_1\\). It is not the population standard deviation; it is the estimated uncertainty in the slope due to sampling. It follows \\(t(n-2)\\), if \\(H_0\\) is true.\n\\[\ns_{b_1} = \\frac{s}{\\sqrt{\\sum(x_i - \\bar{x})^2}} = \\frac{\\sqrt{\\frac{\\sum (y_i - \\hat{y}_i)^2}{n - 2}}}{\\sqrt{\\sum(x_i - \\bar{x})^2}}= \\sqrt{\\frac{\\sum (Y_i - \\hat{Y}_i)^2}{(n - 2)\\,\\sum (X_i - \\bar{X})^2}}\n\\]\nif we denote \\(\\text{MSE} = \\frac{\\sum (Y_i - \\hat{Y}_i)^2}{n - 2}\\) (the mean squared error), then:\n\\[\ns_{b_1} = \\sqrt{\\frac{\\text{MSE}}{\\sum (X_i - \\bar{X})^2}}.\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\n\n\nDecision Rules (two-tail):\n\nReject \\(H_0\\) if \\(p\\text{-value} \\leq \\alpha\\)\nReject \\(H_0\\) if \\(t \\leq -t_{\\alpha/2,n-2}\\) or \\(t \\geq t_{\\alpha/2,n-2}\\) (i.e., \\(|t| &gt; t_{\\alpha/2,n-2}\\))\n\n\nwhere the critical value, \\(t_{\\alpha/2, n-2}\\), is based on a \\(t\\) distribution with \\(n - 2\\) df."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#testing-for-individual-significance-t-test-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Testing for Individual Significance: \\(t\\) Test",
    "text": "Testing for Individual Significance: \\(t\\) Test\n\n\nCompute the value of the test statistic:\n\n\\[\nt = \\frac{b_1 - 0}{s_{b_1}} = \\frac{5 - 0}{.5803} = 8.62\n\\] \n\nDecision:\n\n\\(t_{0.01/2, 8} = T.\\text{INV}(0.995,8) = 3.355\\) provides an area of 0.005 in the upper tail of a \\(t\\)-distribution with \\(n-2\\) degrees of freedom.\nBecause \\(|t| = 8.62 &gt; 3.355\\), we can reject \\(H_0\\) at \\(\\alpha = 1\\%\\).\n\\(p\\text{-value} = 2*(1-T.\\text{DIST}(8.62,10-2,\\text{TRUE})) \\approx 0.000&lt; 1\\%\\).\n\nWe can reject \\(H_0\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(\\beta_1\\)",
    "text": "Confidence Interval for \\(\\beta_1\\)\n\n\nWe can use a 99% confidence interval for \\(\\beta_1\\) to test the hypotheses just used in the t test.\n\\(H_0\\) is rejected if the hypothesized value of \\(\\beta_1\\) is not included in the corresponding confidence interval for \\(\\beta_1\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(\\beta_1\\)",
    "text": "Confidence Interval for \\(\\beta_1\\)\n\n\nThe form of a confidence interval for \\(\\beta_1\\) is:\n\n\\[\nb_1 \\pm t_{\\alpha/2, n-2} s_{b_1}\n\\]\nwhere:\n\n\\(b_1\\) is the point estimator,\n\\(t_{\\alpha/2, n-2} s_{b_1}\\) is the margin of error (MOE),\n\\(t_{\\alpha/2, n-2}\\) is the t critical value providing an upper-tail area of \\(\\alpha/2\\) in a t distribution with \\(n-2\\) degrees of freedom.\n\\(s_{b_1}\\) is the standard error of the slope estimate \\(b_1\\), i.e., an estimate of the standard deviation of the sampling distribution of \\(b_1\\). It is not the population standard deviation; it is the estimated uncertainty in the slope due to sampling."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-beta_1-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(\\beta_1\\)",
    "text": "Confidence Interval for \\(\\beta_1\\)\n\n\n99% Confidence Interval for \\(\\beta_1\\):\n\n\\[\nb_1 \\pm t_{\\alpha/2} s_{b_1} = 5 \\pm 3.355(.5803) = 5 \\pm 1.95\n\\]\nor 3.05 to 6.95\n\nConclusion: 0 is not included in the 99% confidence interval. Reject \\(H_0\\) at \\(\\alpha\\) = 1%."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#some-cautions-about-the-interpretation-of-significance-tests",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#some-cautions-about-the-interpretation-of-significance-tests",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Some Cautions about the Interpretation of Significance Tests",
    "text": "Some Cautions about the Interpretation of Significance Tests\n\n\nRejecting \\(H_0: \\beta_1 = 0\\) and concluding that the relationship between x and y is significant does not enable us to conclude that a cause-and-effect relationship is present between x and y.\nBecause we are able to reject \\(H_0: \\beta_1 = 0\\) and demonstrate statistical significance does not enable us to conclude that there is a linear relationship between x and y."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#excels-regression-tool-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#excels-regression-tool-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Excel’s Regression Tool",
    "text": "Excel’s Regression Tool\n\n\nExcel also has a comprehensive tool in its Data Analysis package called Regression.\nThe Regression tool can be used to perform a complete regression analysis."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel’s Regression Tool",
    "text": "Using Excel’s Regression Tool\n\nPerforming the Regression Analysis\n\n\n\n\n\nStep 1 Click the DATA tab on the Ribbon\nStep 2 In the Analyze group, click Data Analysis\nStep 3 Choose Regression from the list of Analysis Tools\n\n\n\n\n\n\nStep 4 When the Regression dialog box appears:\n\nEnter C1:C11 in the Input Y Range box\nEnter B1:B11 in the Input X Range box\nSelect the check box for Labels\nSelect the check box for Confidence Level\nEnter 99 in the Confidence Level box\nSelect Output Range\nEnter A13 in the Output Range box\nClick OK"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel’s Regression Tool",
    "text": "Using Excel’s Regression Tool\n\nExample: Armand’s Pizza Parlors: Regression tool dialog box"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel’s Regression Tool",
    "text": "Using Excel’s Regression Tool\n\nExample: Armand’s Pizza Parlors: Regression tool dialog box"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excels-regression-tool-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel’s Regression Tool",
    "text": "Using Excel’s Regression Tool\n\n\n\n\n\nRegression Statistics:\n\nMultiple R: 0.9501. Indicates a strong positive correlation between observed and predicted values.\nR Square (Coefficient of Determination): Approximately 90.27% of the variance in the dependent variable (Sales) is explained by the independent variable (Population).\nAdjusted R Square: 0.8906. Adjusts the R Square for the number of predictors, providing a more accurate measure.\nStandard Error: 13.8293. Measures the typical distance that the observed values fall from the regression line.\n\n\nANOVA\n\nRegression SS: 14200. Variability explained by the model.\n\nResidual SS: 1530. Variability not explained by the model.\nF-Statistic: 74.2484. Indicates the model is statistically significant.\nSignificance F: 2.55E-05. \\(p\\)-value indicating strong evidence against the null hypothesis.\n\n\n\nModel Results\n\nCoefficients:\n\nIntercept: 60 (p-value: 0.0002)\n\nPopulation: 5 (p-value: 2.55E-05)\n\nBoth coefficients are statistically significant.\n\nConfidence Intervals:\n\n95% CI for Intercept: [38.7247, 81.2753]\n95% CI for Population: [3.6619, 6.3381]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-the-estimated-regression-equation-for-estimation-and-prediction-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-the-estimated-regression-equation-for-estimation-and-prediction-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using the Estimated Regression Equation for Estimation and Prediction",
    "text": "Using the Estimated Regression Equation for Estimation and Prediction\n\nA confidence interval is an interval estimate of the mean of all values of \\(y\\) for a given value of \\(x\\).\nA prediction interval is used whenever we want to predict an individual value of \\(y\\) for a new randomly-chosen observation corresponding to a given value of \\(x\\).\nThe given \\(x\\)-value is denoted by \\(x^*\\) , and the corresponding point estimate is obtained from the estimated regression equation:\n\n\\[\n\\hat{y}^* = b_0 + b_1 x^*\n\\]\n\nThe margin of error (MOE) is larger for a prediction interval."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-the-estimated-regression-equation-for-estimation-and-prediction-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-the-estimated-regression-equation-for-estimation-and-prediction-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using the Estimated Regression Equation for Estimation and Prediction",
    "text": "Using the Estimated Regression Equation for Estimation and Prediction\n\nConfidence Interval Estimate of the mean, \\(E(\\hat{y}^*)\\):\n\n\\[\n\\hat{y}^* \\pm t_{\\alpha/2, n-2} s_{\\hat{y}^*}\n\\]\n\nPrediction Interval Estimate of individual \\(\\hat{y}^*\\):\n\n\\[\n\\hat{y}^* \\pm t_{\\alpha/2, n-2} s_{pred}\n\\]\nwhere:\n\nconfidence coefficient is \\(1-\\alpha\\) and \\(t_{\\alpha/2, n-2}\\) is based on a t distribution with \\(n-2\\) degrees of freedom."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#point-estimation",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#point-estimation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Point Estimation",
    "text": "Point Estimation\nExample: Armand’s Pizza Parlors\nTo predict quarterly sales or expected quarterly sales of restaurants near a campus or campuses with 10,000 students (\\(x* = 10\\)),\n\\[\n\\hat{y}^* = 60 + 5(10) = 110\n\\]\nPredicted quarterly sales of $110,000"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sums-of-squares",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#sums-of-squares",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Sums of Squares",
    "text": "Sums of Squares\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(i\\)\n\\(x_i\\)\n\\(y_i\\)\n\\(x_i - \\bar{x}\\)\n\\(y_i - \\bar{y}\\)\n\\((x_i - \\bar{x})(y_i - \\bar{y})\\)\n\\((x_i - \\bar{x})^2\\)\n\\((y_i - \\bar{y})^2\\)\n\n\n\n\n1\n2\n58\n-12\n-72\n864\n144\n5184\n\n\n2\n6\n105\n-8\n-25\n200\n64\n625\n\n\n3\n8\n88\n-6\n-42\n252\n36\n1764\n\n\n4\n8\n118\n-6\n-12\n72\n36\n144\n\n\n5\n12\n117\n-2\n-13\n26\n4\n169\n\n\n6\n16\n137\n2\n7\n14\n4\n49\n\n\n7\n20\n157\n6\n27\n162\n36\n729\n\n\n8\n20\n169\n6\n39\n234\n36\n1521\n\n\n9\n22\n149\n8\n19\n152\n64\n361\n\n\n10\n26\n202\n12\n72\n864\n144\n5184\n\n\nTotal\n140\n1300\n\n\n2840\n568\n15730\n\n\n\n\n\\(\\bar{x} = 14, \\bar{y} = 130\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(E(\\hat{y}^*)\\)",
    "text": "Confidence Interval for \\(E(\\hat{y}^*)\\)\nEstimate of the Standard Deviation of \\(\\hat{y}^*\\):\n\\[\ns_{\\hat{y}^*} = s \\sqrt{\\frac{1}{n} + \\frac{(x^* - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}}\n\\]\n\\[\n= 13.829 \\sqrt{\\frac{1}{10} + \\frac{(10 - 14)^2}{568}}\n\\]\n\\[\n= 13.829 \\sqrt{.1282} = 4.95\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(E(\\hat{y}^*)\\)",
    "text": "Confidence Interval for \\(E(\\hat{y}^*)\\)\n95% confidence interval of the mean quarterly sales for all Armand’s restaurants located near campuses with 10,000 students is\n\\[\n\\hat{y}^* \\pm t_{\\alpha/2} s_{\\hat{y}^*}\n\\]\n\\[\n110 \\pm 2.306(4.95)\n\\]\n\\[\n110 \\pm 11.415, \\text{ or } \\$98,585 \\text{ to } \\$121,415\n\\]\nWe are 95% confident that the mean quarterly sales for all Armand’s restaurants located near campuses with 10,000 students falls between $98,585 and $121,415."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#confidence-interval-for-ehaty-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Confidence Interval for \\(E(\\hat{y}^*)\\)",
    "text": "Confidence Interval for \\(E(\\hat{y}^*)\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Prediction Interval for \\(y^*\\)",
    "text": "Prediction Interval for \\(y^*\\)\nEstimate of the Standard Deviation of an Individual Value of \\(y^*\\)\n\\[\ns_{pred} = s \\sqrt{1 + \\frac{1}{n} + \\frac{(x^* - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}}\n\\]\n\\[\ns_{pred} = 13.829 \\sqrt{1 + \\frac{1}{10} + \\frac{(10 - 14)^2}{568}}\n\\]\n\\[\n= 13.829 \\sqrt{1.282} = 14.69\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Prediction Interval for \\(y^*\\)",
    "text": "Prediction Interval for \\(y^*\\)\n95% prediction interval for quarterly sales for the new Armand’s restaurant located near a campus with 10,000 students is\n\\[\n\\hat{y}^* \\pm t_{\\alpha/2} s_{pred}\n\\]\n\\[\n110 \\pm 2.306(14.69)\n\\]\n\\[\n110 \\pm 33.875, \\text{ or } \\$76,125 \\text{ to } \\$143,875\n\\]\nIf we randomly select one Armand’s restaurant located near a campus with 10,000 students, we are 95% confident that its quarterly sales will be between $76,125 and $143,875."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#prediction-interval-for-y-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Prediction Interval for \\(y^*\\)",
    "text": "Prediction Interval for \\(y^*\\)"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#comments",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#comments",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Comments",
    "text": "Comments\n\n\nPrediction intervals for individuals are wider than the corresponding confidence intervals for means.\nTwo \\(x\\)-values with the same distance to the \\(\\bar{x}\\), their corresponding confidence intervals have the same width (and hence, the same margin of error). True also for the prediction intervals.\nThe confidence interval is wider when the given \\(x\\) is further away from the \\(\\bar{x}\\) – It is more difficult to predict for outlying \\(x\\)’s."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-analysis-validating-model-assumptions-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-analysis-validating-model-assumptions-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Analysis: Validating Model Assumptions",
    "text": "Residual Analysis: Validating Model Assumptions\n\nIf the assumptions about the error term \\(\\epsilon\\) appear questionable, the hypothesis tests about the significance of the regression relationship and the interval estimation results may not be valid.\nThe residuals provide the best information about \\(\\epsilon\\).\nResidual for observation \\(i\\)\n\n\\[\ny_i - \\hat{y}_i\n\\]\n\nMuch of the residual analysis is based on an examination of graphical plots."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#model-assumptions-and-validation-procedures-with-diagnosis-plots",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#model-assumptions-and-validation-procedures-with-diagnosis-plots",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Model Assumptions and Validation Procedures with Diagnosis Plots",
    "text": "Model Assumptions and Validation Procedures with Diagnosis Plots\n\n\\(E(\\epsilon) = 0\\).\n\nValidation procedure: A plot of residuals against the predicted values of the dependent variable \\(y\\).\n\nThe variance of \\(\\epsilon\\), denoted by \\(\\sigma^2\\), is the same for all values of \\(x\\).\n\nValidation procedure: A plot of the residuals against values of the independent variable \\(x\\).\n\nThe values of \\(\\epsilon\\) are independent.\n\nValidation procedure: A standardized residual plot.\n\nThe error term \\(\\epsilon\\) has a normal distribution.\n\nValidation procedure: A normal probability plot."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Plot Against \\(x\\)",
    "text": "Residual Plot Against \\(x\\)\n\nIf the assumption that the variance of \\(\\epsilon\\) is the same (constant) for all values of \\(x\\) is valid, and the assumed regression model is an adequate representation of the relationship between the variables, then the residual plot should give an overall impression of a horizontal band of points.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPanel A\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPanel B\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPanel C"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Plot Against \\(x\\)",
    "text": "Residual Plot Against \\(x\\)\nExample: Armand’s Pizza Parlors\n\n\n\n\n\n\n\n\n\nStudent Population (\\(x_i\\))\nSales (\\(y_i\\))\nPredicted sales \\(y_i = 60 + 5(x_i)\\)\nResiduals (\\(y_i - \\hat{y_i}\\))\n\n\n\n\n2\n58\n70\n-12\n\n\n6\n105\n90\n15\n\n\n8\n88\n100\n-12\n\n\n8\n118\n100\n18\n\n\n12\n117\n120\n-3\n\n\n16\n137\n140\n-3\n\n\n20\n157\n160\n-3\n\n\n20\n169\n160\n9\n\n\n22\n149\n170\n-21\n\n\n26\n202\n190\n12"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Plot Against \\(x\\)",
    "text": "Residual Plot Against \\(x\\)\nExample: Armand’s Pizza Parlors\nPlot of the residuals against the independent variable \\(x\\).\n\n\n\nThe residuals appear to approximate the horizontal pattern in Panel A.\nBased on this subjective evaluation, we conclude that the residual plot does not provide evidence that the assumptions made for Armand’s regression model should be challenged.\nWe can be confident that Armand’s simple regression model is valid."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x---excel",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-x---excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Plot Against \\(x\\) - Excel",
    "text": "Residual Plot Against \\(x\\) - Excel\n\n\n\nUsing Excel to Produce a Residual Plot\n\nThe steps outlined earlier to obtain the regression output are performed with one change.\nWhen the Regression dialog box appears, we must also select the Residual Plot option.\nThe output will include two new items:\n\nA plot of the residuals against the independent variable, and\nA list of predicted values of \\(y\\) and the corresponding residual values."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-haty",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#residual-plot-against-haty",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Residual Plot Against \\(\\hat{y}\\)",
    "text": "Residual Plot Against \\(\\hat{y}\\)\nExample: Armand’s Pizza Parlors\nPlot of the residuals against the independent variable \\(\\hat{y}\\).\n\n\n\nThe pattern of this residual plot is the same as the pattern of the residual plot against the independent variable \\(x\\).\nIt is not a pattern that would lead us to question the model assumptions.\nFor simple linear regression, both the residual plot against \\(x\\) and the residual plot against \\(\\hat{y}\\) provide the same pattern.\nFor multiple regression analysis, the residual plot against \\(\\hat{y}\\) is more widely used because of the presence of more than one independent variable."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residuals",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residuals",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\n\nStandardized Residual for Observation \\(i\\)\n\n\\[\n\\frac{y_i - \\hat{y_i}}{s_{y_i - \\hat{y_i}}}\n\\]\nwhere \\(s_{y_i - \\hat{y_i}}\\) is the standard deviation of residual \\(i\\)\n\\[\ns_{y_i - \\hat{y_i}} = s \\sqrt{1 + h_i}\n\\] where \\(s\\) is the standard error of the estimate\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}\n\\]"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual-plot",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual-plot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residual Plot",
    "text": "Standardized Residual Plot\n\nThe standardized residual plot can provide insight about the assumption that the error term \\(\\epsilon\\) has a normal distribution.\nIf this assumption is satisfied, the distribution of the standardized residuals should appear to come from a standard normal probability distribution.\n\nEmpirical rule applies."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residual",
    "text": "Standardized Residual\nExample: Armand’s Pizza Parlors\n\n\n\n\n\n\n\n\n\nObservation\nPredicted sales \\(y_i = 60 + 5(x_i)\\)\nResiduals (\\(y_i - \\hat{y_i}\\))\nStandardized Residual\n\n\n\n\n1\n70\n-12\n-1.0792\n\n\n2\n90\n15\n1.2224\n\n\n3\n100\n-12\n-.9487\n\n\n4\n100\n18\n1.4230\n\n\n5\n120\n-3\n-.2296\n\n\n6\n140\n-3\n-.2296\n\n\n7\n160\n-3\n-.2372\n\n\n8\n160\n9\n.7115\n\n\n9\n170\n-21\n-1.7114\n\n\n10\n190\n12\n1.0792"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual-plot-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#standardized-residual-plot-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Standardized Residual Plot",
    "text": "Standardized Residual Plot\nExample: Armand’s Pizza Parlors\n\n\nAll of the standardized residuals are between -2 and +2 indicating that there is no reason to question the assumption that ε has a normal distribution."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excel-to-construct-a-standardized-residual-plot",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#using-excel-to-construct-a-standardized-residual-plot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel to construct a Standardized Residual Plot",
    "text": "Using Excel to construct a Standardized Residual Plot\nExample: Armand’s Pizza Parlors"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Plot",
    "text": "Normal Probability Plot\nAnother approach for determining the validity of the assumption that the error term has a normal distribution.\nTo show how a normal probability plot is developed, we introduce the concept of normal scores:\n\nSuppose 10 values are selected randomly from a normal probability distribution with a mean of zero and a standard deviation of one, and that the sampling process is repeated over and over with the values in each sample of 10 ordered from smallest to largest. For now, let us consider only the smallest value in each sample. The random variable representing the smallest value obtained in repeated sampling is called the first-order statistic.\n\n\nFor samples of size 10 from a standard normal probability distribution, the expected value of the first-order statistic is -1.55. This expected value is called a normal score. For the case with a sample of size \\(n = 10\\), there are 10 order statistics and 10 normal scores (next slide). In general, a data set consisting of \\(n\\) observations will have \\(n\\) order statistics and hence \\(n\\) normal scores.\n\nNormal Scores: are expected values of the order statistics from a standard normal distribution."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Plot",
    "text": "Normal Probability Plot\nNormal Scores for \\(n = 10\\)\n\n\n\n\nOrder Statistic\nNormal Score\n\n\n\n\n1\n-1.55\n\n\n2\n-1.00\n\n\n3\n-0.65\n\n\n4\n-0.37\n\n\n5\n-0.12\n\n\n6\n0.12\n\n\n7\n0.37\n\n\n8\n0.65\n\n\n9\n1.00\n\n\n10\n1.55"
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Plot",
    "text": "Normal Probability Plot\n\nTo determine whether the standardized residuals for Armand’s Pizza Parlors appear to come from a standard normal probability distribution.\nWe order the 10 standardized residuals in parallel with the 10 normal scores:\n\n\n\nNormal Scores\nOrdered Standardized Residuals\n\n\n\n\n-1.55\n-1.7114\n\n\n-1.00\n-1.0792\n\n\n-0.65\n-0.9487\n\n\n-0.37\n-0.2372\n\n\n-0.12\n-0.2296\n\n\n0.12\n-0.2296\n\n\n0.37\n0.7115\n\n\n0.65\n1.0792\n\n\n1.00\n1.2224\n\n\n1.55\n1.4230\n\n\n\nInterpreting the Normal Probability Plot: If the normality assumption is satisfied, the smallest standardized residual should be close to the smallest normal score, the next smallest standardized residual should be close to the next smallest normal score, and so on."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-3",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#normal-probability-plot-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Normal Probability Plot",
    "text": "Normal Probability Plot\n\nA plot with the normal scores on the horizontal axis and the corresponding standardized residuals on the vertical axis, the plotted points should cluster closely around a 45-degree line passing through the origin if the standardized residuals are approximately normally distributed.\n\n\n\n\n\n\n\n\n\n\n\nThe points are grouped closely about the line. Therefore, we can conclude that the assumption of the error term having a normal probability distribution is reasonable.\nIn general, the more closely the points are clustered about the 45-degree line, the stronger the evidence supporting the normality assumption. Any substantial curvature in the normal probability plot is evidence that the residuals have not come from a normal distribution."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#outliers",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#outliers",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Outliers",
    "text": "Outliers\nAn outlier is a data point (observation) that does not fit the trend shown by the remaining data. Represent observations that are suspect and warrant careful examination.\n\nErroneous Data\n\nInvestigate the source of the outlier to identify any errors in data collection or entry.\nCorrect the data point if possible, or remove it if the correct value cannot be determined.\n\nViolation of Model Assumptions\n\nUse diagnostic tools to check if the outlier violates the assumptions of simple regression.\nConsider alternative models, such as transformations or robust regression methods, if the assumptions are violated.\n\nLegitimate but Unusual Observations\n\nRecognize that some outliers are natural occurrences and represent rare events.\nRetain these outliers in the analysis to reflect the true variability in the data.\nReport and interpret the presence of these outliers in the context of the study."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Outliers",
    "text": "Detecting Outliers\n\nFor the case of simple linear regression, one can often detect outliers by simply examining the scatter diagram.\n\n\n\n\n\n\n\n\n\n\n\\(R^2 = .4968\\)\n\nGiven the pattern of the rest of the data, we would have expected \\(y_4\\) to be much smaller and hence would consider observation 4 to be an outlier."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers-with-standardized-residuals",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers-with-standardized-residuals",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Outliers with Standardized Residuals",
    "text": "Detecting Outliers with Standardized Residuals\n\nIf an observation deviates greatly from the pattern of the rest of the data, the corresponding standardized residual will be large in absolute value.\nAny observation with a standardized residual of less than -2 or greater than +2 is a potential outlier. With normally distributed errors, standardized residuals should be outside these limits approximately 5% of the time.\n\n\n\n\n\n\n\n\n\nIn the residual output section in the Figure we see that the standard residual value for observation 4 is 2.68."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-outliers-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Outliers",
    "text": "Detecting Outliers\n\nThe identification of the outlier enables us to correct the data error and improve the regression results. This is the result with \\(y_4 = 30\\).\n\n\n\n\n\n\n\n\n\n\nNow, no standard residuals are less than -2 or greater than +2.\nThe value of \\(R^2\\) has increased from 0.4968 to 0.8380\nThe value of \\(b_0\\) has decreased from 64.95 to 59.23.\nThe slope of the line has changed from -7.330 to -6.949."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#influential-observations",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#influential-observations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Influential Observations",
    "text": "Influential Observations\n\n\nAn influential observation is an observation that has a strong influence on the regression results.\nAn influential observation may be an outlier, it may correspond to an \\(x\\) value far from its mean, or it may be caused by a combination of a somewhat off-trend \\(y\\) value and a somewhat extreme \\(x\\) value.\nIf the observation is valid, it can contribute to a better understanding of the appropriate model and can lead to a better estimated regression equation."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Influential Observations",
    "text": "Detecting Influential Observations\n\n\n\n\n\n\n\n\n\n\n\n\nWith observation 7 deleted,\n\nThe value of \\(b_0\\) has increased from 127.4 to 138.1.\nThe slope of the line has changed from -0.425 to -1.090."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Influential Observations",
    "text": "Detecting Influential Observations\nHigh Leverage Points: Observations with extreme values for the independent variable. Observation 7 in the data set shown is a point with high leverage.\nThe leverage of an observation is determined by how far the value of the independent variable is from its mean value.\nFor the single-independent-variable case, the leverage of the \\(i\\)th observation, denoted \\(h_i\\), can be computed using:\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2}\n\\]\nFrom the formula, farther \\(x_i\\) is from its mean \\(\\bar{x}\\), the higher the leverage of observation \\(i\\)."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations-2",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#detecting-influential-observations-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Detecting Influential Observations",
    "text": "Detecting Influential Observations\n\nFor the data shown, the leverage of observation 7 is as follows:\n\\[\nh_i = \\frac{1}{n} + \\frac{(x_i - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} = \\frac{1}{7} + \\frac{(70 - 24.286)^2}{2621.43} = 0.94\n\\]\nFor simple linear regression, we consider observations as having high leverage if \\(h_i &gt; \\frac{6}{n}\\). For the example, \\(\\frac{6}{n} = \\frac{6}{7} = 0.86\\).\nThus, because \\(h_i = 0.94 &gt; 0.86\\), observation 7 would be identified as having high leverage.\n\n\nNotes and Comments:\n\nThe number 6 in the criterion \\(h_i &gt; \\frac{6}{n}\\) is an arbitrary rule of thumb used to identify high leverage points in linear regression. Some statisticians use \\(\\frac{2p}{n}\\), where \\(p\\) is the number of predictors plus one (for the intercept) in the model.\nOnce an observation is identified as potentially influential because of a large residual or high leverage, its impact on the estimated regression equation should be evaluated.\nMore advanced texts discuss diagnostics for doing so. However, if one is not familiar with the more advanced material, a simple procedure is to run the regression analysis with and without the observation. This approach will reveal the influence of the observation on the results."
  },
  {
    "objectID": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#summary-1",
    "href": "lecture_slides/14_chapter_simple_regression/14_chapter_simple_regression.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\nSome key takeaways from this session:\n\nSimple Linear Regression Model: Helps to understand the linear relationship between two variables—predicting the Dependent Variable (\\(Y\\)) based on the Independent Variable (\\(X\\)).\n\nThis method is foundational for exploring how variables are related and how changes in one variable can predict changes in another.\n\nModel Interpretation and Assumptions: It is essential to interpret the regression coefficients and validate model assumptions to ensure that the model is reliable.\n\nAssumptions include linearity, independence, homoscedasticity (constant variance), and normality of residuals.\n\nResidual Analysis: Residual plots and other diagnostic tools are critical for validating the assumptions of the regression model and ensuring its accuracy.\n\nProper validation techniques prevent misinterpretation of data and help maintain the integrity of the analysis."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#overview",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nGeneral Linear Model\nModeling Curvilinear Relationships\nInteraction\nTransformations\nNonlinear Models That Are Intrinsically Linear\n\n\n\nDetermining When to Add or Delete Variables\n\nVariable Selection Procedures\n\nStepwise Method\nForward Method\nBackward Method\nBest Subsets Method"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#general-linear-model-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#general-linear-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "General Linear Model",
    "text": "General Linear Model\n\nModels in which the parameters \\((\\beta_0, \\beta_1, \\ldots, \\beta_p)\\) all have exponents of one are called linear models.\nA general linear model involving \\(p\\) independent variables (\\(z_i\\)’s) is:\n\n\n\\[\ny = \\beta_0 + \\beta_1 z_1 + \\beta_2 z_2 + \\ldots + \\beta_p z_p + \\epsilon\n\\]\nwhere each independent variable \\(z_i\\) is a (linear or nonlinear) function of \\(x_1, x_2, \\ldots, x_k\\) (the variables for which data have been collected).\n\nHere, \\(y\\) can be a function of the original response variable as well."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#general-linear-model-2",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#general-linear-model-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "General Linear Model",
    "text": "General Linear Model\n\nThe simplest case is when we have collected data for just one variable \\(x_1\\) and want to estimate \\(y\\) by using a straight-line relationship. In this case \\(z_1 = x_1\\).\nThis model is called a simple first-order model with one predictor variable.\n\n\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\epsilon\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Modelling Curvilinear Relationships",
    "text": "Modelling Curvilinear Relationships"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-2",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Modelling Curvilinear Relationships",
    "text": "Modelling Curvilinear Relationships\n\nSome non-linear models can be expressed as a general linear model.\nTo account for a curvilinear relationship, we might consider a second-order model with one predictor variable \\((x_1)\\):\n\n\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\epsilon\n\\]\n\nIt is a linear model because we can set: \\(z_1 = x_1\\) and \\(z_2 = x_1^2\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-3",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#modelling-curvilinear-relationships-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Modelling Curvilinear Relationships",
    "text": "Modelling Curvilinear Relationships\n\n\n\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\epsilon\n\\]\n\n\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\epsilon\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#interpretation-of-independent-variable-effect-in-a-second-order-model",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#interpretation-of-independent-variable-effect-in-a-second-order-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interpretation of Independent Variable Effect in a Second-Order Model",
    "text": "Interpretation of Independent Variable Effect in a Second-Order Model\n\n\\(\\beta_1\\): Represents the linear effect of \\(x_1\\) on \\(y\\). It gives the initial (or marginal) change in \\(y\\) for a one-unit increase in \\(x_1\\) when \\(x_1^2\\) is held constant.\n\\(\\beta_2\\): Represents the quadratic effect of \\(x_1\\) on \\(y\\). It determines whether the curve opens upwards \\((\\beta_2 &gt; 0)\\) or downwards \\((\\beta_2 &lt; 0)\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#marginal-effect-of-x_1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#marginal-effect-of-x_1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Marginal Effect of \\(x_1\\)",
    "text": "Marginal Effect of \\(x_1\\)\n\nThe overall effect of \\(x_1\\) on \\(y\\) can be expressed as:\n\n\n\\[\n\\frac{dy}{dx_1} = \\beta_1 + 2\\beta_2 x_1\n\\]\n\nThis shows that the effect of \\(x_1\\) on \\(y\\) changes as \\(x_1\\) increases or decreases due to the presence of the quadratic term \\(x_1^2\\).\nInstead of a constant change (as in linear models), the presence of \\(2\\beta_2 x_1\\) shows a varying slope depending on the value of \\(x_1\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#practical-interpretation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#practical-interpretation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Practical Interpretation",
    "text": "Practical Interpretation\n\nIf \\(\\beta_2 &gt; 0\\), \\(y\\) increases at an increasing rate as \\(x_1\\) increases, resulting in a U-shaped curve.\nIf \\(\\beta_2 &lt; 0\\), \\(y\\) increases at a decreasing rate and then decreases, resulting in an inverted U-shaped curve.\nThe effect of \\(x_1\\) should always be considered in light of both \\(\\beta_1\\) and \\(\\beta_2\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#interaction-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#interaction-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Interaction",
    "text": "Interaction\n\nIf the original data set consists of observations for \\(y\\) and two independent variables, \\(x_1\\) and \\(x_2\\), we might develop a second-order model with two predictor variables \\((x_1\\) and \\(x_2)\\) with interaction:\n\n\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 + \\epsilon\n\\]\n\nThe variable \\(x_1 x_2\\) is added to account for the potential effects of the two variables acting together.\n\\(\\beta_3\\) measures the interaction effect."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interaction",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interaction",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Interaction",
    "text": "Example: Interaction\nLets check the regression study conducted by Tyler Personal Care for one of its new shampoo products. Two factors believed to have the most influence on sales are:\n\nUnit selling price\nAdvertising expenditure\n\nTo investigate the effects of these two variables on sales, prices of $2.00, $2.50, and $3.00 were paired with advertising expenditures of $50,000 and $100,000 in 24 test markets."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-difference-in-mean-sales",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-difference-in-mean-sales",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Difference in Mean Sales",
    "text": "Example: Difference in Mean Sales\n\n\nMean Sales (1000s) for the Tyler Personal Care Example\n\n\n\nAdvertising Expenditure\n$2.00\n$2.50\n$3.00\n\n\n\n\n$50,000\n461\n364\n332\n\n\n$100,000\n808\n646\n375\n\n\n\n\n\n\nWith a price of $2.00, the difference in mean sales between advertising expenditures of $50,000 and $100,000 is:\n\\[\n808,000 - 461,000 = 347,000 \\, units\n\\]\nWhen the price is $2.50, the difference is:\n\\[\n646,000 - 364,000 = 282,000 \\, units\n\\]\nWhen the price is $3.00, the difference is:\n\\[\n375,000 - 332,000 = 43,000 \\, units\n\\]\n\n\nClearly, the difference in mean sales between advertising expenditures depends on the price of the product. The effect of increased advertising expenditure diminishes at higher selling prices, providing evidence of interaction between the price and advertising expenditure variables."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-regression-model-with-interaction",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-regression-model-with-interaction",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Regression Model with Interaction",
    "text": "Example: Regression Model with Interaction\n\nTo account for the effect of interaction, we use the following regression model:\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 + \\epsilon\n\\]\nWhere:\n\n\\(y\\) = unit sales (1000s)\n\\(x_1\\) = price ($)\n\\(x_2\\) = advertising expenditure ($1000s)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-estimated-regression-equation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-estimated-regression-equation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Estimated Regression Equation",
    "text": "Example: Estimated Regression Equation\nUsing the estimated regression equation:\n\\[\n\\text{Sales} = -275.8333 + 175 \\, \\text{Price} + 19.68 \\, \\text{AdvExp} - 6.08 \\, \\text{PriceAdv}\n\\]\nWhere:\n\nSales = unit sales (1000s)\nPrice = price of the product ($)\nAdvExp = advertising expenditure ($1000s)\nPriceAdv = interaction term (Price times AdvExp)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-significance-of-interaction",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-significance-of-interaction",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Significance of Interaction",
    "text": "Example: Significance of Interaction\n\n\nThe \\(p\\)-value corresponding to the \\(t\\)-test for PriceAdv is 0.0000, which indicates significant interaction between the price of the product and the advertising expenditure."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interpretation-of-coefficients",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interpretation-of-coefficients",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Interpretation of Coefficients",
    "text": "Example: Interpretation of Coefficients\n\n\n\\(\\beta_0\\): Intercept. Represents the expected value of \\(y\\) when \\(x_1\\) and \\(x_2\\) are zero.\n\\(\\beta_1\\): Effect of \\(x_1\\) on \\(y\\) when \\(x_2 = 0\\).\n\\(\\beta_2\\): Effect of \\(x_2\\) on \\(y\\) when \\(x_1 = 0\\).\n\\(\\beta_3\\): Interaction effect between \\(x_1\\) and \\(x_2\\). Indicates how the relationship between \\(x_1\\) and \\(y\\) changes with different values of \\(x_2\\), and vice-versa."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-marginal-effects",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-marginal-effects",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Marginal Effects",
    "text": "Example: Marginal Effects\n\nEffect of \\(x_1\\):\n\n\n\\[\n\\frac{\\partial y}{\\partial x_1} = \\beta_1 + \\beta_3 x_2\n\\]\n\nEffect of \\(x_2\\):\n\n\n\n\\[\n\\frac{\\partial y}{\\partial x_2} = \\beta_2 + \\beta_3 x_1\n\\]\n\n\nThe effect of \\(x_1\\) on \\(y\\) depends on \\(x_2\\), and the effect of \\(x_2\\) on \\(y\\) depends on \\(x_1\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interpretation-of-interaction-effect",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-interpretation-of-interaction-effect",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Interpretation of Interaction Effect",
    "text": "Example: Interpretation of Interaction Effect\n\n\nIf \\(\\beta_3 &gt; 0\\), a positive (or negative) effect of \\(x_1\\) on \\(y\\) increases as \\(x_2\\) increases.\nIf \\(\\beta_3 &lt; 0\\), a positive (or negative) effect of \\(x_1\\) on \\(y\\) decreases as \\(x_2\\) increases."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-coefficient-interpretation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-coefficient-interpretation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Coefficient Interpretation",
    "text": "Example: Coefficient Interpretation\n\n\nPrice: \\(175\\) - When AdvExp is zero, a one-unit increase in Price leads to an expected increase of 175 units in \\(y\\).\nAdvExp: \\(19.68\\) - When Price is zero, a one-unit increase in AdvExp results in an expected increase of 19.68 units in \\(y\\).\nPriceAdv: \\(-6.08\\)- Interaction effect: A one-unit increase in AdvExp decreases the effect of Price on \\(y\\) by 6.08 units (and vice versa).\n\n\nInterpretation of Interaction Effect\n\n\nThe interaction term \\(\\beta_3\\) (PriceAdv) is negative.\n\nAs AdvExp increases, the positive effect of Price on \\(y\\) decreases.\nSuggests diminishing returns on Price when AdvExp is already high (or vice versa).\n\nAn increase in Advertising Expenditures may lead to higher sales, but this effect diminishes as more the Price increases.\nThe interaction effect is negative and significant, showing that the combined effect of Price and AdvExp on \\(y\\) is not purely additive.\nTakeaway: Adjustments to Price or AdvExp should consider their interaction, as increasing both may not yield linear increases in \\(y.\\)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#original-data",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#original-data",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Original Data",
    "text": "Original Data"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#log-transformation-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#log-transformation-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Log Transformation",
    "text": "Log Transformation"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#possibile-logarithmic-transformations",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#possibile-logarithmic-transformations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Possibile Logarithmic Transformations",
    "text": "Possibile Logarithmic Transformations\n\n\n\n\n\n\n\n\n\n\nX\nlogX\n\n\n\n\nY\nlinear\\(\\hat{Y}_i = \\alpha + \\beta X_i\\)\nlinear-log\\(\\hat{Y}_i = \\alpha + \\beta \\log X_i\\)\n\n\nlogY\nlog-linear\\(\\log \\hat{Y}_i = \\alpha + \\beta X_i\\)\nlog-log\\(\\log \\hat{Y}_i = \\alpha + \\beta \\log X_i\\)\n\n\n\n\n\n\nSource: Linear Regression Models with Logarithmic Transformations"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#what-changes-after-the-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#what-changes-after-the-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "What Changes After the Transformation",
    "text": "What Changes After the Transformation\n\n\nYou should be cautious when interpreting and reporting the findings of the model.\nThe interpretation varies based on the variable that was transformed (dependent variable, independent variable, or both).\nAs a general rule, you should always keep in mind the logic:\n\n\n\n“What does a one-unit change in this transformed variable mean in terms of the original variable?”\n\n\nThe Effect Book"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#log-transformation-summary",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#log-transformation-summary",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Log Transformation Summary",
    "text": "Log Transformation Summary\n\n\n\n\n\n\n\n\n\n\n\nModel\nModel Equation\nInterpretation of \\(\\beta_1\\)\nInterpretation\n\n\n\n\nLevel-level\n\\(y = \\beta_0 + \\beta_1 x + \\epsilon\\)\n\\(\\Delta y = \\beta_1 \\Delta x\\)\nA one-unit change in \\(x\\) results in a \\(\\beta_1\\) unit change in \\(y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLevel-log\n\\(y = \\beta_0 + \\beta_1 \\log(x) + \\epsilon\\)\n\\(\\Delta y = (\\beta_1 / 100) \\% \\Delta x\\)\nA 1% change in \\(x\\) results in a \\(\\beta_1/100\\) unit change in \\(y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog-level\n\\(\\log(y) = \\beta_0 + \\beta_1 x + \\epsilon\\)\n\\(\\%\\Delta y = (100\\beta_1) \\Delta x\\)\nA one-unit change in \\(x\\) results in a \\(\\beta_1\\%\\) change in \\(y\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog-log\n\\(\\log(y) = \\beta_0 + \\beta_1 \\log(x) + \\epsilon\\)\n\\(\\%\\Delta y = \\beta_1 \\% \\Delta x\\)\nA 1% change in \\(x\\) results in a \\(\\beta_1\\%\\) change in \\(y\\)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-log-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-log-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Log Transformation",
    "text": "Example: Log Transformation\n\nPredict Miles-Per-Gallon (MPG) according to the automobile Weight (in pounds):\n\n\n\n\\[\n\\text{MPG} = 56.0957 - 0.0116 \\times \\text{Weight}\n\\]\n\n\n\n\n\n\n\n\n\n\nThe pattern does not look like the the horizontal band we should expect to find if the assumptions about the error term are valid.\nVariability in the residuals appears to increase as the value of \\(\\hat{y}\\) increases.\n\n\n\n\n\\[\n\\text{LnMPG} = 4.5242 - 0.0005 \\times \\text{Weight}\n\\]\n\n\n\n\n\n\n\n\n\n\nThe wedge-shaped pattern disappeared.\nThe model with the logarithm of miles per gallon as the dependent variable provides an excellent fit to the oberved data."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#nonlinear-models-that-are-intrinsically-linear-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#nonlinear-models-that-are-intrinsically-linear-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Nonlinear Models That Are Intrinsically Linear",
    "text": "Nonlinear Models That Are Intrinsically Linear\n\nModels in which the parameters \\(\\beta_0, \\beta_1, \\ldots, \\beta_p\\) have exponents other than one are called nonlinear models.\nFor the case of the exponential model, we can perform a transformation of variables that will enable us to perform regression analysis using the general linear model.\nThe exponential model involves the following regression equation:\n\\[\nE(y) = \\beta_0 \\beta_1^x\n\\]\nThis model is appropriate when the dependent variable \\(y\\) increases or decreases by a constant percentage, instead of by a fixed amount, as \\(x\\) increases."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-of-exponential-model",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#example-of-exponential-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example of Exponential Model",
    "text": "Example of Exponential Model\nSuppose sales for a product \\(y\\) are related to advertising expenditure \\(x\\) (in $1000s) according to the following regression equation:\n\\[\nE(y) = 500(1.2)^x\n\\] Thus,\n\nfor \\(x = 1\\), \\(E(y) = 500(1.2)^1 = 600\\)\nfor \\(x = 2\\), \\(E(y) = 500(1.2)^2 = 720\\)\nfor \\(x = 3\\), \\(E(y) = 500(1.2)^3 = 864\\)\n\nNote that \\(E(y)\\) is not increasing by a constant amount in this case, but by a constant percentage. The percentage increase is 20%."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#logarithmic-transformation-of-the-model",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#logarithmic-transformation-of-the-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Logarithmic Transformation of the Model",
    "text": "Logarithmic Transformation of the Model\n\nWe can transform this nonlinear model to a linear model by taking the natural logarithm of both sides of the equation:\n\\[\n\\ln E(y) = \\ln \\beta_0 + x \\ln \\beta_1\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#linearized-model",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#linearized-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linearized Model",
    "text": "Linearized Model\n\nNow, if we let \\(y' = \\ln E(y)\\), \\(\\beta'_0 = \\ln \\beta_0\\), and \\(\\beta'_1 = \\ln \\beta_1\\), we can rewrite the equation as:\n\\[\ny' = \\beta'_0 + \\beta'_1 x\n\\]\nThe formulas for simple linear regression can now be used to develop estimates of \\(\\beta'_0\\) and \\(\\beta'_1\\). Denoting the estimates as \\(b'_0\\) and \\(b'_1\\), leads to the following estimated regression equation:\n\\[\n\\hat{y'} = b'_0 + b'_1 x\n\\]\nTo obtain predictions of the original dependent variable \\(y\\) given a value of \\(x\\), we would first substitute the value of \\(x\\) into the equation above to compute \\(\\hat{y'}\\), and then raise \\(e\\) to the power of \\(\\hat{y'}\\) to obtain the prediction of \\(y\\), or the expected value of \\(y\\), in its original units."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#linearized-model---example-prediction",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#linearized-model---example-prediction",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linearized Model - Example Prediction",
    "text": "Linearized Model - Example Prediction\nGiven the estimates:\n\n\\(b'_0 = 3.5\\)\n\\(b'_1 = 0.2\\)\n\nLet’s predict \\(y\\) when the advertising expenditure \\(x = 5\\) (in $1000s).\nUsing the linearized equation we calculate \\(y'\\):\n\\[\ny' = b'_0 + b'_1 \\cdot x = 3.5 + 0.2 \\cdot 5 = 4.5\n\\]\nNow, exponentiate \\(y'\\) to get the predicted \\(y\\):\n\\[\ny = e^{4.5} \\approx 90.02\n\\]\nThus, the predicted sales \\(y\\) when the advertising expenditure is 5 (in $1000s) is approximately 90 units (in $1000s)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#other-transformations-to-consider-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#other-transformations-to-consider-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Other Transformations to Consider",
    "text": "Other Transformations to Consider\n\n\nSquare-root: \\(\\sqrt{x}\\)\n\nLogarithmic: \\(\\log_{10}(x), \\log_{10}(y), \\ln(x)\\), etc.\n\nReciprocal: \\(1/y, 1/x\\)\n\nExponential: \\(e^x, e^y\\)\n\nSquare: \\(x^2, y^2\\)\n\nPower: \\(x^k, y^k\\)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#square-root-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#square-root-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Square-Root Transformation",
    "text": "Square-Root Transformation\n\nAdd or use \\(\\sqrt{x}\\) term or \\((x^{0.5})\\)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#logarithmic-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#logarithmic-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Logarithmic Transformation",
    "text": "Logarithmic Transformation\n\nAdd or use \\(\\ln(x) \\text{ or } \\log(x)\\) term."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#reciprocal-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#reciprocal-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Reciprocal Transformation",
    "text": "Reciprocal Transformation\n\nAdd or use \\(1/x\\) term."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#exponential-transformation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#exponential-transformation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Transformation",
    "text": "Exponential Transformation\n\nChange \\(y\\) to \\(\\ln(y)\\) as the new response variable."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#power-transformations",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#power-transformations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Power Transformations",
    "text": "Power Transformations\n\nAdd \\(x^2\\) or \\(x^k\\) term."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#overview-of-predictor-evaluation",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#overview-of-predictor-evaluation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview of Predictor Evaluation",
    "text": "Overview of Predictor Evaluation\n\nStatistical Significance: Indicates whether the relationship between a predictor and the dependent variable is unlikely to have occurred by chance.\nEffectiveness: Reflects the practical impact or importance of the predictor on the dependent variable.\n\nAssessed by observing changes in adjusted R-squared when the predictor is included.\nStatistical significance is evaluated using the p-value."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#four-scenarios-for-predictors",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#four-scenarios-for-predictors",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Four Scenarios for Predictors",
    "text": "Four Scenarios for Predictors\n\n\n\n\n\n\n\n\n\n\nStatistically Significant(e.g. p-value &lt; 0.05)\nNot Statistically Significant(e.g. p-value ≥ 0.05)\n\n\n\n\nEffective (Adjusted R-squared increases significantly)\nScenario 1Predictor is both statistically significant and effective.\nScenario 3Effective but not statistically significant.\n\n\nNot Effective (Adjusted R-squared does not increase significantly)\nScenario 2Statistically significant but not effective.\nScenario 4Not statistically significant nor effective.\n\n\n\n\nDefinition: A predictor is an ineffective predictor if its \\(|T-Value| = \\left| \\frac{b - 0}{se(b)} \\right| &lt; 1\\). If that is the case, the coefficient estimate \\(b\\) is within one standard deviation from 0, i.e., too close to 0, or its two-sided \\(p-value &gt; 0.32\\) (Empirical rule).\n\nAdding an effective predictor will decrease the estimated error variance \\(S^2\\) and hence increase Adj \\(R^2\\). The opposite is true when adding an ineffective predictor.\nRemoving an effective predictor will increase the estimated error variance \\(S^2\\) and hence decrease Adj \\(R^2\\). The opposite is true when removing an ineffective predictor."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-1-statistically-significant-and-effective",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-1-statistically-significant-and-effective",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scenario 1: Statistically Significant and Effective",
    "text": "Scenario 1: Statistically Significant and Effective\nCharacteristics\n\np-value below chosen significance level (e.g., \\(p &lt; 0.05\\))\nAdjusted R-squared increases meaningfully when the predictor is included\n\n\nInterpretation\n\nPredictor reliably contributes to the dependent variable’s variance.\nBoth statistically and practically meaningful.\n\n\n\nExample\n\nHealthcare: Adding “age” as a predictor in a model for blood pressure yields a p-value of \\(p &lt; 0.001\\) and increases the adjusted R-squared from 0.30 to 0.45.\nAge is both a statistically significant and effective predictor of blood pressure."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-2-statistically-significant-but-not-effective",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-2-statistically-significant-but-not-effective",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scenario 2: Statistically Significant but Not Effective",
    "text": "Scenario 2: Statistically Significant but Not Effective\nCharacteristics\n\np-value below the significance threshold\nMinimal change in adjusted R-squared: negligible improvement in the model’s explanatory power\n\n\nInterpretation\n\nStatistically reliable but lacks practical impact.\nCommon in large samples where even small effects become significant.\n\n\n\nExample\n\nEconomics: Adding “hair color” as a predictor of income yields p = 0.02, but increases adjusted R-squared from 0.25 to 0.251.\nHair color is statistically significant but not practically effective."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-3-not-statistically-significant-but-effective",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-3-not-statistically-significant-but-effective",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scenario 3: Not Statistically Significant but Effective",
    "text": "Scenario 3: Not Statistically Significant but Effective\nCharacteristics\n\np-value exceeds the significance level (e.g., \\(p &gt; 0.05\\))\nSubstantial increase in adjusted R-squared\n\n\nInterpretation\n\nMeaningful effect, but lacks statistical support.\nMay need a larger sample size or further refinement.\n\n\n\nExample\n\nEducation: Adding “hours of sleep” as a predictor of student performance increases adjusted R-squared from 0.40 to 0.50 but yields p = 0.08.\n“Hours of sleep” has a practical impact but isn’t statistically significant."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-4-not-statistically-significant-and-not-effective",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#scenario-4-not-statistically-significant-and-not-effective",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Scenario 4: Not Statistically Significant and Not Effective",
    "text": "Scenario 4: Not Statistically Significant and Not Effective\nCharacteristics\n\np-value above the significance threshold\nNo increase in adjusted R-squared\n\n\nInterpretation\n\nPredictor lacks both statistical and practical value.\nLikely safe to exclude from the model.\n\n\n\nExample\n\nMarketing: Adding “shoe size” to predict customer satisfaction yields p = 0.60 and decreases adjusted R-squared from 0.35 to 0.34."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#strategies-for-adding-or-removing-variables-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#strategies-for-adding-or-removing-variables-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Strategies for Adding or Removing Variables",
    "text": "Strategies for Adding or Removing Variables\n\n\n\n\n#\nStrategy\nDescription\nAdd Variables\nRemove Variables\n\n\n\n\n1\nP-Value\nBased on statistical significance\nIf p-value &lt; 0.05\nIf p-value &gt; 0.05\n\n\n2\nAdjusted R-Squared\nChecks if model fit improves\nIf adjusted \\(R^2\\) increases\nIf adjusted \\(R^2\\) decreases\n\n\n3\nF-Test\nCompares models with and without added variables\nIf F-test indicates significant improvement\nIf F-test shows no significant improvement\n\n\n4\nAIC or BIC\nBalances model fit and complexity\nIf AIC/BIC decreases\nIf AIC/BIC increases\n\n\n5\nStepwise Regression\nAutomated selection procedure based on statistical contribution\nAdd variables with high statistical contribution\nRemove variables with low contribution\n\n\n6\nMulticollinearity (VIF)\nThe Variance Inflation Factor detects multicollinearity between independent variables\nUse the full model\nIf VIF &gt; 10\n\n\n7\nBest Subset Selection\nCompares all possible combinations of predictors to identify the best model\nAdds the combination of predictors with the best performance based on chosen criteria (e.g., adjusted \\(R^2\\))\nN/A; evaluates models by selecting the best subset\n\n\n8\nCross-Validation\nAssesses model performance across different data subsets\nIf cross-validation performance improves\nIf cross-validation performance worsens\n\n\n9\nGood vs Bad Controls\nFor causal inference purposes\nAdd good controls that help block non-causal paths\nRemove bad controls that open new spurious paths\n\n\n10\nTheoretical Justification\nAdds or removes variables based on theory, domain knowledge, or experience\nAdd based on theory or domain knowledge\nRemove variables that are irrelevant, regardless of statistical significance"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-or-removing-variables",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-or-removing-variables",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding or Removing Variables",
    "text": "Adding or Removing Variables\nWe will focus on the following:\n\nStepwise regression\nForward selection\nBackward elimination\nBest-subsets regression.\n\nThe first three procedures are iterative; at each step, a single independent variable is added or deleted, and the new model is evaluated. The process continues until a stopping criterion indicates that the procedure cannot find a better model.\nThe best-subsets procedure is not a one-variable-at-a-time procedure; it evaluates regression models involving different subsets of the independent variables."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nWe can use an F-test to determine whether it is advantageous to add one or more independent variables to a multiple regression model.\nThis is based on determining the reduction in the error sum of squares (SSE) resulting from adding variables.\nThe null and alternative hypotheses are defined as:\n\\[\nH_0: \\beta_{q+1} = \\beta_{q+2} = \\cdots = \\beta_p = 0\n\\]\n\\[\nH_a: \\text{One or more of the parameters is not equal to zero}\n\\]\nwhere \\(q\\) is the number of independent variables in the first model."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nLet’s illustrate this using the Butler Trucking example.\nThe regression equation with miles traveled \\(x_1\\) as the only independent variable is:\n\\[\n\\hat{y} = 1.2739 + 0.0678x_1\n\\]\nThe error sum of squares for this model is:\n\\[\nSSE(x_1) = 8.0287\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-2",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nWhen the number of deliveries \\(x_2\\) is added, the regression equation becomes:\n\\[\n\\hat{y} = -0.8687 + 0.0611x_1 + 0.9234x_2\n\\]\nThe error sum of squares for this model is:\n\\[\nSSE(x_1, x_2) = 2.2994\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-3",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nThe reduction in SSE from adding \\(x_2\\) to the model is:\n\\[\nSSE(x_1) - SSE(x_1, x_2) = 8.0287 - 2.2994 = 5.7293\n\\]\nWe can conduct a F-test to determine if this reduction is significant:\n\\[\nF = \\frac{\\frac{SSE(x_1) - SSE(x_1, x_2)}{1}}{\\frac{SSE(x_1, x_2)}{n - p - 1}}\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-4",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\n\nSubstituting the values:\n\\[\nF = \\frac{5.7293}{1} \\Big/ \\frac{2.2994}{7} = 17.44\n\\] Where,\n\n\\(n = 10\\)\n\\(p = 2\\)\n\nConclusion from F-Test\nUsing Excel, we obtain a \\(p\\)-value of \\(0.0042\\) for the calculated F-statistic. Since the \\(p\\)-value is less than the significance level \\(\\alpha = 0.05,\\) we reject the null hypothesis. Thus, adding \\(x_2\\) results in a significant reduction in SSE.\nThe t-test and F-test are equivalent when only one independent variable is being added, and we can use either to assess significance."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-5",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nIn the stepwise regression, forward selection, and backward elimination procedures, the criterion for selecting an independent variable to add or delete from the model at each step is based on the F-statistic.\nSuppose we are considering adding \\(x_2\\) to a model involving \\(x_1\\) or deleting \\(x_2\\) from a model involving \\(x_1\\) and \\(x_2\\). To test whether the addition or deletion of \\(x_2\\) is statistically significant, the null and alternative hypotheses can be stated as follows:\n\\[\nH_0: \\beta_2 = 0\n\\]\n\\[\nH_a: \\beta_2 \\neq 0\n\\]"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-6",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-f-test-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: F-test",
    "text": "Adding Variables in Regression Models: F-test\nWe saw that:\n\\[\nF = \\frac{{SSE(x_1) - SSE(x_1, x_2)}}{1} \\div \\frac{{SSE(x_1, x_2)}}{n - p - 1}\n\\]\ncan be used as a criterion for determining whether the presence of \\(x_2\\) in the model causes a significant reduction in the error sum of squares.\nThe p-value corresponding to this F-statistic is used to determine whether an independent variable should be added or deleted from the regression model. The usual rejection rule applies: Reject \\(H_0\\) if p-value \\(\\leq \\alpha\\)."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-overview",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression: Overview",
    "text": "Stepwise Regression: Overview\n\nStepwise regression is a semi-automated procedure for selecting independent variables in a multiple regression model.\nAt each step, the method evaluates whether any variable should be removed from or added to the model based on predefined significance levels.\nBecause it does not exhaustively examine all possible combinations of predictors, stepwise regression does not guarantee finding the best subset of predictors in terms of overall fit or predictive accuracy."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-how-it-works",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-how-it-works",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression: How It Works",
    "text": "Stepwise Regression: How It Works\n\nInitial Removal Check\n\nBegin with an initial model (which can start with no variables, a single variable, or a chosen subset).\nCompute F-statistics and p-values for each predictor already included.\nIf any predictor’s p-value exceeds the “p-value to leave” threshold (often denoted \\(\\alpha_{\\text{remove}}\\)), the predictor with the largest p-value is removed.\nAfter a variable is removed, a new step commences.\n\nNext Possible Addition\n\nIf no variable meets the criterion for removal, then the procedure checks any variables not in the model.\nCompute F-statistics and p-values for each candidate predictor not in the model.\nIf the smallest p-value among these is below the “p-value to enter” threshold (often denoted \\(\\alpha_{\\text{enter}}\\)), the corresponding predictor is added.\nSteps alternate between removal and addition until no variable can be removed or added based on these criteria."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#considerations-and-limitations",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#considerations-and-limitations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Considerations and Limitations",
    "text": "Considerations and Limitations\n\nNon-exhaustive approach: Because stepwise regression evaluates one variable at a time (in or out), it does not consider all possible subsets of predictors. Therefore, it might overlook a model that would yield a higher \\(R^2\\) or better predictive performance.\nVariability of inclusion: A predictor can enter at one step, be removed at a later step, and potentially re-enter if the residual relationships change after adding or removing other variables.\nOveremphasis on p-values: Stepwise regression heavily depends on p-values, which can be sensitive to sample size and collinearity. It can also lead to an overly complex model or, conversely, a model that excludes potentially relevant predictors.\nData-driven model building: Automated selection methods (including stepwise) may produce results that do not generalize well outside the sample. Cross-validation or penalized methods (e.g., LASSO, ridge regression) are often recommended as more robust alternatives."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression Example",
    "text": "Stepwise Regression Example\nSuppose we have a dataset with:\n\nIncome (in thousands of dollars)\nAge (age of household head)\nEducation (years of education)\nSpending (annual spending on goods, our dependent variable)"
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-starting-point",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-starting-point",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression Example: Starting Point",
    "text": "Stepwise Regression Example: Starting Point\n\nInitial Model\n\nBegin with one predictor (for instance, Income) or a subset deemed important by domain knowledge.\nFit the model:\n\\[\n\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\epsilon.\n\\]\nSuppose Income is significant at \\(\\alpha=0.05\\). Keep Income in the model.\n\nEvaluating Other Predictors\n\nNext, consider adding Age or Education.\nFit two separate models, each adding one candidate variable:\n\n\\(\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_2 \\cdot \\text{Education} + \\epsilon.\\)\n\\(\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_3 \\cdot \\text{Age} + \\epsilon.\\)\n\nCalculate p-values for \\(\\hat{\\beta}_2\\) and \\(\\hat{\\beta}_3\\). If Education has the lower p-value (below the “p-value to enter,” say 0.05), add Education to the model."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-checking-for-removal",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-checking-for-removal",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression Example: Checking for Removal",
    "text": "Stepwise Regression Example: Checking for Removal\nOnce you have a model with Income and Education, stepwise regression checks if Income or Education should be removed:\n\nRe-estimate:\n\\[\n\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_2 \\cdot \\text{Education} + \\epsilon.\n\\]\nIf either predictor’s p-value exceeds “p-value to leave” (say 0.10), remove that predictor. Otherwise, both stay."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-considering-remaining-predictors",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-considering-remaining-predictors",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression Example: Considering Remaining Predictors",
    "text": "Stepwise Regression Example: Considering Remaining Predictors\nIf Age is still not in the model, you check whether it can enter:\n\nFit:\n\\[\n\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_2 \\cdot \\text{Education} + \\beta_3 \\cdot \\text{Age} + \\epsilon.\n\\]\nIf Age’s p-value is below the threshold, it is added; otherwise, it is excluded.\n\nContinue this process until no more additions or removals are justified."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-final-model",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#stepwise-regression-example-final-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Stepwise Regression Example: Final Model",
    "text": "Stepwise Regression Example: Final Model\nEventually, the procedure converges on a model, for example:\n\\[\n\\text{Spending} = \\beta_0 + \\beta_1 \\cdot \\text{Income} + \\beta_2 \\cdot \\text{Education} + \\epsilon.\n\\]\nThis indicates Income and Education meet the significance criteria for inclusion, while Age does not."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#summary-of-the-stepwise-procedure",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#summary-of-the-stepwise-procedure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary of the Stepwise Procedure",
    "text": "Summary of the Stepwise Procedure\n\nStart\n\nChoose an initial model (empty, single variable, or chosen subset).\n\nRemove\n\nCheck if any included variables can be removed based on “p-value to leave.” If so, remove the worst offender and repeat.\n\nAdd\n\nIf no variable is removed in a step, check whether any excluded variable meets the “p-value to enter.” If so, add the variable with the smallest p-value.\n\nStop\n\nTerminate when no variable can be removed or added according to the thresholds."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-overview",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forward Selection: Overview",
    "text": "Forward Selection: Overview\n\nForward selection is a sequential variable selection procedure that begins with an empty model (i.e., no predictors) and incrementally adds variables based on significance criteria.\nUnlike the stepwise procedure, forward selection never removes any variable once it has been included."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-procedure",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-procedure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forward Selection: Procedure",
    "text": "Forward Selection: Procedure\n\n\nStart with No Variables\n\nThe initial model includes no predictors: \\[\ny = \\beta_0 + \\epsilon.\n\\]\n\nEvaluate All Predictors for Entry\n\nFor each potential predictor not yet in the model, calculate the F-statistic (or equivalently, t-statistic for the coefficient) and its corresponding p-value.\np-Value to Enter: Each predictor is tested against a specified significance level (e.g., \\(\\alpha_{\\text{enter}}\\)). If the smallest p-value among all candidate predictors falls below \\(\\alpha_{\\text{enter}}\\), add that corresponding predictor to the model.\n\nRecalculate and Repeat\n\nAfter adding a predictor, recalculate the model parameters and evaluate the remaining predictors for entry. Continue this process of adding one variable at a time.\n\nTermination\n\nThe procedure stops when no remaining predictors meet the threshold for entry, meaning all p-values for excluded variables exceed \\(\\alpha_{\\text{enter}}\\).\n\n\n\n\nKey Difference from Stepwise: In forward selection, once a variable is included, it cannot be removed—even if adding subsequent variables renders it less significant."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-limitations",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#forward-selection-limitations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forward Selection Limitations",
    "text": "Forward Selection Limitations\n\n\nNo Removal of Variables: Because there is no mechanism to remove predictors, variables that become unnecessary later might remain in the final model. This can lead to inflated model complexity and reduced interpretability.\nPotential Multicollinearity Issues: Forward selection does not explicitly account for multicollinearity. High correlations among predictors may lead to unstable coefficient estimates and p-values, producing misleading or less robust results.\nGreedy Algorithm: The procedure is myopically focused on adding one predictor at a time based on immediate improvements in model fit. It may miss a combination of predictors that could perform better when considered together.\nRisk of Overfitting: When many potential predictors exist, forward selection can overfit the sample data, reducing the model’s generalizability. The model might appear strong in-sample but perform poorly on new data.\nNeglect of Interactions and Nonlinearities: Because forward selection evaluates predictors in isolation, it does not automatically consider interaction terms or nonlinear transformations. Thus, it can overlook influential higher-order relationships."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-overview",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Backward Elimination: Overview",
    "text": "Backward Elimination: Overview\nBackward elimination is a sequential variable selection method that starts with the full model—i.e., one that includes all potential predictors—and iteratively removes the least significant predictor at each step. It stops when no remaining predictors have a p-value above the designated “p-value to leave” threshold (\\(\\alpha_{\\text{remove}}\\)). Unlike stepwise methods, once a variable is removed, it is not allowed to reenter the model."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-procedure",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-procedure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Backward Elimination: Procedure",
    "text": "Backward Elimination: Procedure\n\n\nBegin with All Predictors\n\nThe initial model is: \\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_k x_k + \\epsilon.\n\\]\n\nCompute p-values\n\nEstimate the coefficients and compute p-values (or equivalent F-statistics) for each predictor.\n\nRemove the Least Significant Variable\n\nIdentify the predictor with the largest p-value.\nIf that p-value exceeds the “p-value to leave” threshold, remove the corresponding variable from the model.\n\nRe-estimate and Repeat\n\nAfter removing a variable, re-fit the model and compute p-values again for the reduced set of predictors.\n\nContinue removing variables one at a time until no remaining predictors have p-values larger than \\(\\alpha_{\\text{remove}}\\).\n\nStop Criterion\n\nOnce no variable meets the removal criterion, the procedure ends. The final set of variables constitutes the chosen model.\n\n\n\n\nKey Restriction: Any predictor removed at an earlier step cannot be reconsidered for reentry in later steps."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-limitations",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#backward-elimination-limitations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Backward Elimination Limitations",
    "text": "Backward Elimination Limitations\n\nNo Reentry of Variables: Once a predictor is removed, it stays out—even if, after further eliminations, it would have become significant again. This may lead to omitting variables that could have value under a different model specification.\nMulticollinearity Concerns: Backward elimination does not explicitly address multicollinearity. Highly correlated predictors may cause instability in coefficient estimates, rendering p-values less reliable.\nRisk of Overfitting: Because the procedure begins with all variables, it may produce an overly complex initial model. While backward elimination might remove some predictors, it can still result in a model that is closely tailored to the sample data but performs poorly in out-of-sample scenarios.\nDependence on Initial Model: The entire process depends heavily on the initial choice of predictors. If irrelevant variables are included or if critical interaction terms are missing, the final model may be suboptimal.\nPotentially Different Final Models: Different paths of elimination might yield different final models, depending on the order in which variables are removed. This is particularly true if multiple predictors have similar statistical significance or if interactions are not explored."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#best-subsets-regression-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#best-subsets-regression-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Best-Subsets Regression",
    "text": "Best-Subsets Regression\nMany statistical software packages have a procedure called best-subsets regression that enables the user to find, given a specified number of independent variables, the best regression equation.\nTypical output from such packages will enable the user to identify:\n\nThe two best one-variable estimated regression equations,\nThe two best two-variable regression equations,\nThe two best three-variable regression equations, and so on.\n\n\nThe criterion used in determining which estimated regression equations are best for any number of predictors is usually the value of the adjusted coefficient of determination."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-notes-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#adding-variables-in-regression-models-notes-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Adding Variables in Regression Models: Notes",
    "text": "Adding Variables in Regression Models: Notes\n\nLimitations of Procedures: None of the procedures that add or delete variables one at a time can be guaranteed to identify the best regression model.\n\nHowever, they are excellent approaches to finding good models—especially when multicollinearity is present.\n\nSoftware Implementation: The stepwise, forward selection, backward elimination, and best-subsets approaches to building a regression model can be implemented in Excel.\n\nHowever, this would be very inefficient as each approach would potentially require several steps in which various models based on what was learned in the previous step would have to be estimated.\nMost statistical software (including R) are capable of implementing each of these algorithms automatically."
  },
  {
    "objectID": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#summary-1",
    "href": "lecture_slides/16_chapter_model_building/16_chapter_model_building.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nGeneral Linear Model: Models parameters with exponents of 1. Example:\n\\[y = \\beta_0 + \\beta_1 z_1 + \\beta_2 z_2 + \\ldots + \\beta_p z_p + \\epsilon\\]\nCurvilinear Relationships: Use quadratic terms to model curvature:\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2 + \\epsilon\\]\nInteraction Effects: Captures how two variables together influence \\(y\\).Here is a great paper about the topic.\n\\[y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 + \\epsilon\\]\nLog Transformations: Useful for handling non-linearity and heteroscedasticity.\nStepwise Regression: Iterative process of adding/removing variables based on statistical significance, but risks overfitting.\nForward Selection: Adds variables one-by-one but doesn’t allow removal after inclusion.\nBackward Elimination: Starts with all variables and eliminates non-significant ones.\nBest-Subsets Regression: Evaluates all possible subsets of variables to find the best model."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#overview",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nTime Series and Time Series Patterns\nForecast Accuracy – Definitions\nNaïve Forecasting Method\nMoving Averages\nExponential Smoothing\n\n\n\nLag Variables\nTrend Projection\nSeasonality without Trend\nSeasonality and Trend"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series",
    "text": "Time Series\n\nTime series are especially important in business applications since they are involved in forecasting (revenues, expenses, stock prices, inventory levels, etc.).\nA time series is a sequence of measurements (of a variable) taken every hour, day, week, month, quarter, year, or any other regular time interval.\nThe pattern of the data is crucial for understanding how the time series has behaved over time.\nIf such behavior can be expected to continue in the future, we can use it to select an appropriate forecasting method."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods",
    "text": "Forecasting Methods"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-qualitative",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-qualitative",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Qualitative",
    "text": "Forecasting Methods: Qualitative\n\n\nForecasting methods can be classified as qualitative or quantitative.\nQualitative methods generally involve expert judgment to develop forecasts.\n\nSuch methods are appropriate when historical data are not applicable or unavailable.\n\nWe will focus on quantitative forecasting methods."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Quantitative",
    "text": "Forecasting Methods: Quantitative\n\nQuantitative forecasting methods can be used when:\n\nPast information about the variable being forecast is available,\nThe information can be quantified,\nIt is reasonable to assume that the pattern of the past will continue.\n\nIn such cases, a forecast can be developed using a time series or a causal method."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Quantitative",
    "text": "Forecasting Methods: Quantitative\n\nQuantitative methods are based on an analysis of historical data concerning one or more time series.\nA time series is a set of observations measured at successive points in time.\nTime Series Method: Restricts data to past values of the series.\nCausal Method: Uses other time series believed to be related to the time series to be forecasted."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Quantitative",
    "text": "Forecasting Methods: Quantitative\n\nTime Series Analysis\n\nThe objective is to discover a pattern in historical data and extrapolate it into the future.\nThe forecast is based solely on past values of the variable or past forecast errors."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Quantitative",
    "text": "Forecasting Methods: Quantitative\n\nCausal Methods\n\nAssumes the variable being forecasted has a cause-effect relationship with other variables.\nRegression analysis can be used to forecast the time series value as the dependent variable.\nIdentifying related independent variables can help in developing a regression equation for forecasting."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecasting-methods-quantitative-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecasting Methods: Quantitative",
    "text": "Forecasting Methods: Quantitative\n\n\nRegression Analysis: Time is treated as the independent variable, and the time series as the dependent variable.\nTime-Series Regression: The sole independent variable is time.\nCross-Sectional Regression: The independent variables are something other than time."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Plot",
    "text": "Time Series Plot\n\nThe first step in selecting an appropriate forecasting method is to construct a time series plot to identify patterns.\nA time series plot is a graphical presentation of the relationship between time and the time series variable.\nIt is a scatterplot where time is on the horizontal axis, and the time series values are on the vertical axis."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Plot: Example",
    "text": "Time Series Plot: Example\nGasoline sale time series\nThe number of gallons of gasoline sold by a gasoline distributor over a period of 12 weeks is given in the table below. The distributor would like to identify the underlying pattern in the data to guide it in selecting an appropriate forecasting method.\n\n\n\n\nWeek\nSales\n\n\n\n\n1\n17\n\n\n2\n21\n\n\n3\n19\n\n\n4\n23\n\n\n5\n18\n\n\n6\n16\n\n\n7\n20\n\n\n8\n18\n\n\n9\n22\n\n\n10\n20\n\n\n11\n15\n\n\n12\n22"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-example-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-plot-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Plot: Example",
    "text": "Time Series Plot: Example\nGasoline sales time series"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns",
    "text": "Time Series Patterns\nThe common types of data patterns that can be identified when examining a time series plot include:\n\nHorizontal\nTrend\nSeasonal\nTrend and Seasonal\nCyclical"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-horizontal-pattern",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-horizontal-pattern",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Horizontal Pattern",
    "text": "Time Series Patterns: Horizontal Pattern\n\nA horizontal pattern exists when the data fluctuate around a constant mean.\nChanges in business conditions can often result in a time series that shifts to a new level.\nIt is more difficult to choose an appropriate forecasting method to identify a change in the level of the time series. (The Change-time problem.)"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-horizontal-pattern-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-horizontal-pattern-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Horizontal Pattern",
    "text": "Time Series Patterns: Horizontal Pattern\nStationary Time Series\nThe term stationary time series is used to denote a time series whose statistical properties are independent of time. In particular, this means that:\n\nThe process generating the data has a constant mean.\nThe variability of the time series is constant over time.\n\n\nA time series plot for a stationary time series will always exhibit a horizontal pattern. But simply observing a horizontal pattern is not sufficient evidence to conclude that the time series is stationary.\nMore advanced texts on forecasting discuss procedures for determining if a time series is stationary and provide methods for transforming a time series that is not stationary into a stationary series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-trend-pattern",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-trend-pattern",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Trend Pattern",
    "text": "Time Series Patterns: Trend Pattern\n\nA time series may show gradual drifts or movements to relatively higher or lower values over a longer period of time.\nTrend is usually the result of long-term factors such as changes in the population, demographics, technology, or consumer preferences.\nA trend pattern can be identified by analyzing multiperiod movements in historical data."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-seasonal-pattern",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-seasonal-pattern",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Seasonal Pattern",
    "text": "Time Series Patterns: Seasonal Pattern\n\nSeasonal patterns are recognized by seeing the same repeating pattern of highs and lows over successive periods of time (within a “short” period of time).\nA seasonal pattern might occur within a day, week, month, quarter, or year.\nA seasonal pattern does not necessarily refer to the four seasons of the year."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-trend-and-seasonal-pattern",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-trend-and-seasonal-pattern",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Trend and Seasonal Pattern",
    "text": "Time Series Patterns: Trend and Seasonal Pattern\n\nSome time series include a combination of a trend and seasonal pattern.\nTime series decomposition can be used to separate or decompose a time series into trend and seasonal components."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-cyclical-pattern",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-patterns-cyclical-pattern",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Patterns: Cyclical Pattern",
    "text": "Time Series Patterns: Cyclical Pattern\n\nA cyclical pattern exists if the time series plot shows an alternating sequence of points below and above the trend line lasting more than one year.\nOften, the cyclical component of a time series is due to multiyear business cycles.\nBusiness cycles are difficult, if not impossible, to forecast."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#using-excels-chart-tools-to-construct-a-time-series-plot",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#using-excels-chart-tools-to-construct-a-time-series-plot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Using Excel’s Chart Tools to Construct a Time Series Plot",
    "text": "Using Excel’s Chart Tools to Construct a Time Series Plot\n\n\n\n\nA time series plot is simply a scatter diagram with lines connecting the points.\nSteps\n\nSelect cells A2:B13 in the Gasoline.xlsx file.\nClick the Insert tab on the Ribbon\nIn the Charts group, click the Insert Scatter (X, Y) or Bubble Chart button\nWhen the list of scatter diagram subtypes appears:\n\nClick the Scatter with Straight Lines and Markers button\n\n\nThe time series plot produced by Excel will appear in the same worksheet."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#selecting-a-forecasting-method-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#selecting-a-forecasting-method-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting a Forecasting Method",
    "text": "Selecting a Forecasting Method\n\n\nThe underlying pattern in the time series is an important factor in selecting a forecasting method.\nA time series plot should be one of the first tools developed to determine what forecasting method to use.\nIf we see a horizontal pattern, then we need to select a method appropriate for this type of pattern.\nIf we observe a trend in the data, then we need to use a method that can handle the trend effectively."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy",
    "text": "Forecast Accuracy\n\n\nMeasures of forecast accuracy are used to determine how well a particular forecasting method can reproduce the time series data that we already have.\nForecast accuracy measures are important factors in comparing different forecasting methods.\nBy selecting the method that has the best accuracy, we will obtain better forecasts for future time periods."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy",
    "text": "Forecast Accuracy\n\nThe key concept associated with measuring forecast accuracy is forecast error:\n\n\\[\n\\text{Forecast Error} = \\text{Actual Observed Value} - \\text{Forecast}\n\\]\n\\[\n\\text{Residual} = \\text{Observed} - \\text{Predicted}\n\\]\n\nA positive forecast error indicates the forecasting method underestimated the actual value.\nA negative forecast error indicates the forecasting method overestimated the actual value.\nA forecast error is basically a residual."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy",
    "text": "Forecast Accuracy\n\nMean Error (ME): ME is the mean or average of the forecast errors. Because positive and negative forecast errors tend to offset one another, the mean error is likely to be small. Thus, the mean error is not a very useful measure.\nMean Absolute Error (MAE): MAE avoids the problem of positive and negative errors offsetting one another. It is the mean of the absolute values of the forecast errors."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy",
    "text": "Forecast Accuracy\n\nMean Squared Error (MSE): MSE also avoids the problem of positive and negative errors offsetting one another. It is the average of the squared forecast errors.\nMean Absolute Percentage Error (MAPE): The size of MAE and MSE depend upon the scale of the data, so it is difficult to make comparisons for different time periods. To make such comparisons, we need to work with relative or percentage error measures. Percentage Error is the error divided by the observed value of the time series. The MAPE is the average of the absolute percentage errors of the forecasts."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Naïve Forecast",
    "text": "Forecast Accuracy: Example Naïve Forecast\n\n\nTo demonstrate the computation of these measures of forecast accuracy, let’s introduce the simplest of forecasting methods: the naïve forecasting method\nThe naïve forecasting method uses only the most recent observation in the time series as the forecast for the next time period.\n\n\\[\nF_{t+1} = Y_t, \\text{ the actual observed value in period } t\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Naïve Forecast",
    "text": "Forecast Accuracy: Example Naïve Forecast\n\nGasoline sale time series\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nObserved Time series\nNaïve Forecast\nForecast error\nAbsolute value of forecast error\nSquared forecast error\nPercentage error\nAbsolute value of percentage error\n\n\n\n\n1\n17\n\n\n\n\n\n\n\n\n2\n21\n17\n4\n4\n16\n19.05 = \\(\\frac{4}{21}\\)\n19.05\n\n\n3\n19\n21\n-2\n2\n4\n-10.53\n10.53\n\n\n4\n23\n19\n4\n4\n16\n17.39\n17.39\n\n\n5\n18\n23\n-5\n5\n25\n-27.78\n27.78\n\n\n6\n16\n18\n-2\n2\n4\n-12.5\n12.5\n\n\n7\n20\n16\n4\n4\n16\n20.00\n20.00\n\n\n8\n18\n20\n-2\n2\n4\n-11.11\n11.11\n\n\n9\n22\n18\n4\n4\n16\n18.18\n18.18\n\n\n10\n20\n22\n-2\n2\n4\n-10.00\n10.00\n\n\n11\n15\n20\n-5\n5\n25\n-33.33\n33.33\n\n\n12\n22\n15\n7\n7\n49\n31.82\n31.82\n\n\nTotals\n\n\n5\n41\n179\n1.19\n211.69\n\n\n\n\nWeek 2: the postive forecast error indicates that the forecasting method underestimated the actual value of sales.\nWeek 3: the negative forecast error indicates that the forecasting method overestimated the actual value of sales."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-naïve-forecast-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Naïve Forecast",
    "text": "Forecast Accuracy: Example Naïve Forecast\n\nGasoline sale time series: Naive Forecast Accuracy\n\nMean Absolute Error (MAE): It is the mean of the absolute values of the forecast errors.\n\n\n\\[\n\\text{MAE} = \\frac{41}{11} = 3.73\n\\]\n\nMean Squared Error (MSE): It is the average of the squared forecast errors.\n\n\n\n\\[\n\\text{MSE} = \\frac{179}{11} = 16.27\n\\]\n\n\n\nThe size of MAE and MSE depends upon the scale of the data. So, it is not recommended to make comparisons for different time intervals (e.g. months vs weeks).\nTo make comparisons like these we need relative or percentage error measues like MAPE.\nMean Absolute Percentage Error (MAPE): It is the average of the absolute percentage errors of the forecasts.\n\n\n\n\\[\n\\text{MAPE} = \\frac{211.69}{11} = 19.24\\%\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Historical Data Average",
    "text": "Forecast Accuracy: Example Historical Data Average\nLet’s use the average of all the historical data available as the forecast for the next period.\n\nWe begin by developing a forecast for Week 2. Since there is only one historical value available prior to Week 2, the forecast for Week 2 is just the time series value in Week 1. Thus, the forecast for Week 2 is 17 thousand gallons of gasoline.\n\n\nTo compute the forecast for Week 3, we take the average of the sales values in Weeks 1 and 2:\n\\[\n\\text{Forecast for week 3} = \\frac{17 + 21}{2} = 19\n\\]\n\n\nSimilarly, the forecast for Week 4 is:\n\\[\n\\text{Forecast for week 4} = \\frac{17 + 21 + 19}{3} = 19\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Historical Data Average",
    "text": "Forecast Accuracy: Example Historical Data Average\n\nThe forecasts obtained using this method for the gasoline time series are:\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nTime Series Value\nForecast\nForecast Error\nAbsolute Value of Forecast Error\nSquared Forecast Error\nPercentage Error\nAbsolute Value of Percentage Error\n\n\n\n\n1\n17\n\n\n\n\n\n\n\n\n2\n21\n17.00\n4.00\n4.00\n16.00\n19.05\n19.05\n\n\n3\n19\n19.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n4\n23\n19.00\n4.00\n4.00\n16.00\n17.39\n17.39\n\n\n5\n18\n20.00\n-2.00\n2.00\n4.00\n-11.11\n11.11\n\n\n6\n16\n19.60\n-3.60\n3.60\n12.96\n-22.50\n22.50\n\n\n7\n20\n19.00\n1.00\n1.00\n1.00\n5.00\n5.00\n\n\n8\n18\n19.14\n-1.14\n1.14\n1.31\n-6.35\n6.35\n\n\n9\n22\n19.00\n3.00\n3.00\n9.00\n13.64\n13.64\n\n\n10\n20\n19.33\n0.67\n0.67\n0.44\n3.33\n3.33\n\n\n11\n15\n19.40\n-4.40\n4.40\n19.36\n-29.33\n29.33\n\n\n12\n22\n19.00\n3.00\n3.00\n9.00\n13.64\n13.64\n\n\n\n\nTotals\n4.53\n26.81\n89.07\n2.76\n141.34"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-example-historical-data-average-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Example Historical Data Average",
    "text": "Forecast Accuracy: Example Historical Data Average\nUsing the results shown, we obtained the following values of MAE, MSE, and MAPE:\n\\[\n\\text{MAE} = \\frac{26.81}{11} = 2.44\n\\]\n\\[\n\\text{MSE} = \\frac{89.07}{11} = 8.10\n\\]\n\\[\n\\text{MAPE} = \\frac{141.34}{11} = 12.85\\%\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-comparison-of-forecasting-methods",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-accuracy-comparison-of-forecasting-methods",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast Accuracy: Comparison of Forecasting Methods",
    "text": "Forecast Accuracy: Comparison of Forecasting Methods\nWe can now compare the accuracy of the two forecasting methods we have considered by comparing the values of MAE, MSE, and MAPE for each method.\n\n\n\n\nNaive Method\nAverage of Past Values\n\n\n\n\nMAE\n3.73\n2.44\n\n\nMSE\n16.27\n8.10\n\n\nMAPE\n19.24%\n12.85%\n\n\n\nFor every measure, the average of past values provides more accurate forecasts than using the most recent observation as the forecast for the next period.\n\nIf the underlying time series is stationary, the average of all the historical data will generally provide the best results.\nIf the time series is not stationary, adjustments are needed.\n\n\nIn cases where the time series shifts to a new level (e.g., due to contract changes), the naive method might adapt faster than the averaging method."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#importance-of-forecast-accuracy-and-adaptability",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#importance-of-forecast-accuracy-and-adaptability",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Importance of Forecast Accuracy and Adaptability",
    "text": "Importance of Forecast Accuracy and Adaptability\nMeasures of forecast accuracy are crucial but should not be the sole basis for choosing a forecasting method.\n\nConsider the business context and the likelihood of changes in the time series level.\nHistorical forecast accuracy should be weighed alongside the ability of the method to adapt to shifts."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-and-exponential-smoothing-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-and-exponential-smoothing-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages and Exponential Smoothing",
    "text": "Moving Averages and Exponential Smoothing\n\nThree forecasting methods that are appropriate for a time series with a horizontal pattern:\n\n\nMoving Averages (MAs)\nWeighted Moving Averages\nExponentially Weighted Moving Averages (EWMAs)\n\n\nThey are called smoothing methods because their objective is to smooth out the random fluctuations (due to random errors or noises) in the time series.\nThey are most appropriate for short-range forecasts."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages",
    "text": "Moving Averages\nThe moving averages method uses the average of the most recent k data values in the time series as the forecast for the next period. Mathematically, a moving average forecast of order k is as follows:\n\n\n\n\n\n\n\nMoving Average Forecast of Order \\(k\\)\n\n\n\\[\nF_{t+1} = \\frac{\\sum (\\text{most recent } k \\text{ data values})}{k} = \\frac{Y_t + Y_{t-1} + \\cdots + Y_{t-k+1}}{k}\n\\]\nwhere:\n\n\\(F_{t+1}\\) = forecast of the time series for period \\(t + 1\\)\n\\(Y_t\\) = actual value of the time series in period \\(t\\)\n\n\n\n\n\n\nEach observation in the moving average calculation receives the same weight \\((1/k)\\).\nThe term moving is used because every time a new observation becomes available for the time series, it replaces the oldest observation in the equation.\nAs a result, the average will change, or move, as new observations become available."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages",
    "text": "Moving Averages\n\n\nTo use moving averages to forecast, we must first select the span (the order), which is the number of observed time series values to be included in the moving average.\n\nA smaller value of k will track shifts in a time series more quickly than a larger value of k.\nA larger value of k, the smoother the MA. Less sensitive to changes in the given time series.\nIf more past observations are considered relevant, then a larger value of k is better."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages",
    "text": "Moving Averages\n\nExample: Gasoline sale time series: three-week moving average (\\(k = 3\\))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nTime series value\nForecast\nForecast error\nAbsolute value of forecast error\nSquared forecast error\nPercentage error\nAbsolute value of percentage error\n\n\n\n\n1\n17\n\n\n\n\n\n\n\n\n2\n21\n\n\n\n\n\n\n\n\n3\n19\n\n\n\n\n\n\n\n\n4\n23\n\\(\\frac{(17 + 21 + 19)}{3} = 19\\)\n4\n4\n16\n17.39\n17.39\n\n\n5\n18\n\\(\\frac{21 + 19 + 23}{3} = 21\\)\n-3\n3\n9\n-16.67\n16.67\n\n\n6\n16\n20\n-4\n4\n16\n-25.00\n25.00\n\n\n7\n20\n19\n1\n1\n1\n5.00\n5.00\n\n\n8\n18\n18\n0\n0\n0\n0.00\n0.00\n\n\n9\n22\n18\n4\n4\n16\n18.18\n18.18\n\n\n10\n20\n20\n0\n0\n0\n0.00\n0.00\n\n\n11\n15\n20\n-5\n5\n25\n-33.33\n33.33\n\n\n12\n22\n19\n3\n3\n9\n13.64\n13.64\n\n\n\n\nTotals\n0\n24\n92\n-20.79\n129.21"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages",
    "text": "Moving Averages\nExample: Gasoline sale time series: three-week moving average\n\\[\n\\text{MAE} = \\frac{24}{9} = 2.67\n\\]\n\\[\n\\text{MSE} = \\frac{92}{9} = 10.22\n\\]\n\\[\n\\text{MAPE} = \\frac{129.21}{9} = 14.36\\%\n\\]\n\nThe three-week moving average approach provided more accurate forecasts than the naïve approach (19.24%)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-plot",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-plot",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages Plot",
    "text": "Moving Averages Plot\n\nExample: Gasoline sales time series: three-week moving average\n\n\n\nThe Figure shows the original time series plot and the three-week moving average forecasts.\nNote how the graph of the moving average forecasts has tended to smooth out the random fluctuations in the time series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-excel",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#moving-averages-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Moving Averages: Excel",
    "text": "Moving Averages: Excel\nEnter/Access Data: Open the file Gasoline. The data are in cells A2:B13 and labels are in cells A1:B1.\n\nStep 1: Click the Data tab on the Ribbon\nStep 2: In the Analyze group, click Data Analysis\nStep 3: Choose Moving Average from the list of Analysis Tools and click OK\nStep 4: When the Moving Average dialog box appears:\n\nEnter B2:B13 in the Input Range box\nEnter 3 in the Interval box\nEnter C3 in the Output Range box\nSelect the check box for Chart Output\nClick OK\n\n\nThe three-week moving average forecasts appear in column C of the worksheet; a chart showing the actual values of the time series and the forecasted values also appears. Forecasts for periods of other lengths can be computed easily by entering a different value in the interval box."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#weighted-moving-averages-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#weighted-moving-averages-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Weighted Moving Averages",
    "text": "Weighted Moving Averages\n\nIn the moving averages method, each observation in the moving average calculation receives the same weight.\nWeighted Moving Averages: we can select a different weight for each data value (e.g. the most recent observations) and then compute a weighted average of the most recent \\(k\\) values as the forecast.\n\nThe more recent observations are typically given more weight than older observations.\nFor convenience, the weights should sum to 1."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#weighted-moving-averages-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#weighted-moving-averages-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Weighted Moving Averages",
    "text": "Weighted Moving Averages\nFor the Gasoline data, a three-period weighted moving average (3WMA) for Week 4 is:\n\\[\nWMA_3 = \\frac{1}{6}(17) + \\frac{2}{6}(21) + \\frac{3}{6}(19) = 19.33\n\\]\n\nif the weights are \\(\\frac{1}{6}, \\frac{2}{6}, \\frac{3}{6}\\), which sum to 1.\n19 is the most recent of the three observations and receives the largest weight.\nTo determine whether one particular combination of number of data values and weights provides a more accurate forecast than another combination, it is recommended to use MSE as the measure of the forecast accuracy.\n\nIf we assume that the combination that is best for the past will also be best for the future, we would use the one that minimizes MSE for the historical time series to forecast the next value in the time series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast",
    "text": "Exponential Smoothing Forecast\n\n\nThe exponential smoothing forecast is a special case of the weighted moving averages.\nIt is the weighted average of all the time series data up to the current period.\nWe select only the weight between 0 and 1 for the most recent observation. This weight is called the smoothing constant and is denoted by \\(\\alpha\\).\n\n\\(1 - \\alpha\\) is called the damping factor.\n\n\n\n\n\n\n\n\n\n\n\nSingle Exponential Smoothing Forecast\n\n\n\\[\nF_{t+1} = \\alpha Y_t + (1 - \\alpha) F_t\n\\]\nwhere\n\n\\(F_{t+1}\\) = forecast of the time series for period \\(t + 1\\)\n\\(Y_t\\) = actual value of the time series in period \\(t\\)\n\\(F_t\\) = forecast of the time series for period \\(t\\)\n\\(\\alpha\\) = smoothing constant \\((0 \\leq \\alpha \\leq 1)\\)\n\n\n\n\n\n\n\n\nThere are a number of exponential smoothing procedures.\nThe term exponential smoothing comes from the exponential nature of the weighting scheme for the historical values.\n\nThe weights assigned to the time series values decrease exponentially as the “age” of the data values increases.\n\nThe statistic computed in each period is called the Exponentially Weighted Moving Average (EWMA)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast",
    "text": "Exponential Smoothing Forecast\nLet’s illustrate by working with a time series involving only three periods of data: \\(Y_1\\), \\(Y_2\\), and \\(Y_3\\).\n\nTo initiate, let \\(F_1\\) equal the actual value of the time series in period 1; that is, \\(F_1 = Y_1\\). Hence, the forecast for period 2 is\n\\[\n\\begin{aligned}\nF_2 &= \\alpha Y_1 + (1 - \\alpha) F_1 \\\\\n    &= \\alpha Y_1 + (1 - \\alpha) Y_1 \\\\\n    &= Y_1\n\\end{aligned}\n\\]\nThus, the exponential smoothing forecast for period 2 is equal to the actual value of the time series in period 1."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast",
    "text": "Exponential Smoothing Forecast\nThe forecast for period 3 is\n\\[\nF_3 = \\alpha Y_2 + (1 - \\alpha) F_2 = \\alpha Y_2 + (1 - \\alpha) Y_1\n\\]\nFinally, substituting this expression for \\(F_3\\) in the expression for \\(F_4\\), we obtain\n\\[\n\\begin{aligned}\nF_4 &= \\alpha Y_3 + (1 - \\alpha) F_3 \\\\\n&= \\alpha Y_3 + (1 - \\alpha)[\\alpha Y_2 + (1 - \\alpha) Y_1] \\\\\n&= \\alpha Y_3 + \\alpha (1 - \\alpha) Y_2 + (1 - \\alpha)^2 Y_1\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast",
    "text": "Exponential Smoothing Forecast\n\nThe term exponential smoothing comes from the exponential nature of the weighting scheme for the historical values.\nWe now see that \\(F_4\\) is a weighted average of the first three time series values. The sum of the coefficients, or weights, for \\(Y_1\\), \\(Y_2\\), and \\(Y_3\\) equals 1. A similar argument can be made to show that, in general, any forecast \\(F_{t+1}\\) is a weighted average of all the previous time series values.\nDespite the fact that exponential smoothing provides a forecast that is a weighted average of all past observations, all past data do not need to be saved to compute the forecast for the next period. In fact, only two pieces of information are needed: \\(Y_t\\) and \\(F_t\\)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Example",
    "text": "Exponential Smoothing Forecast: Example\nGasoline sale time series\nThe number of gallons of gasoline sold by a distributor over a period of 12 weeks is given below. The distributor uses exponential smoothing to forecast sales. Which value for the smoothing constant \\(\\alpha\\), 0.2 or 0.3, gives better forecasts?\n\n\n\n\nWeek\nSales\n\n\n\n\n1\n17\n\n\n2\n21\n\n\n3\n19\n\n\n4\n23\n\n\n5\n18\n\n\n6\n16\n\n\n7\n20\n\n\n8\n18\n\n\n9\n22\n\n\n10\n20\n\n\n11\n15\n\n\n12\n22"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Example",
    "text": "Exponential Smoothing Forecast: Example\n\nGasoline sale time series with smoothing constant \\(\\alpha = 0.2\\)\n\n\n\n\n\n\n\n\n\n\nWeek\nTime series value\nForecast\nForecast error\nSquared forecast error\n\n\n\n\n1\n17\n\n\n\n\n\n2\n21\n17\n4.00\n16.00\n\n\n3\n19\n\\(0.2(21) + 0.8(17)=17.80\\)\n1.20\n1.44\n\n\n4\n23\n\\(0.2(19) + 0.8(17.80)=18.04\\)\n4.96\n24.60\n\n\n5\n18\n19.03\n-1.03\n1.06\n\n\n6\n16\n18.83\n-2.83\n8.01\n\n\n7\n20\n18.26\n1.74\n3.03\n\n\n8\n18\n18.61\n-0.61\n0.37\n\n\n9\n22\n18.49\n3.51\n12.32\n\n\n10\n20\n19.19\n0.81\n0.66\n\n\n11\n15\n19.35\n-4.35\n18.92\n\n\n12\n22\n18.48\n3.52\n12.39\n\n\n\n\nTotals\n10.92\n98.80"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Example",
    "text": "Exponential Smoothing Forecast: Example\nGasoline sale time series with smoothing constant \\(\\alpha = 0.2\\)\n\\[\n\\text{MSE} = \\frac{98.80}{11} = 8.98\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Example",
    "text": "Exponential Smoothing Forecast: Example\n\nGasoline sale time series with smoothing constant \\(\\alpha = 0.3\\)\n\n\n\n\n\n\n\n\n\n\nWeek\nTime series value\nForecast\nForecast error\nSquared forecast error\n\n\n\n\n1\n17\n\n\n\n\n\n2\n21\n17\n4\n16\n\n\n3\n19\n18.20\n0.80\n0.64\n\n\n4\n23\n18.44\n4.56\n20.79\n\n\n5\n18\n19.81\n-1.81\n3.28\n\n\n6\n16\n19.27\n-3.27\n10.69\n\n\n7\n20\n18.29\n1.71\n2.92\n\n\n8\n18\n18.80\n-0.80\n0.64\n\n\n9\n22\n18.56\n3.44\n11.83\n\n\n10\n20\n19.59\n0.41\n0.17\n\n\n11\n15\n19.71\n-4.71\n22.18\n\n\n12\n22\n18.30\n3.70\n13.69\n\n\n\n\nTotals\n8.03\n102.83"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-example-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Example",
    "text": "Exponential Smoothing Forecast: Example\nGasoline sale time series with smoothing constant \\(\\alpha = 0.3\\)\n\\[\n\\text{MSE} = \\frac{102.83}{11} = 9.35\n\\]\n\nExponential smoothing (with \\(\\alpha = 0.2\\)) provided more accurate forecasts (8.98) than exponential smoothing with \\(\\alpha = 0.3\\) in this example."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-excel",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Excel",
    "text": "Exponential Smoothing Forecast: Excel\n\nStep 1: Click Data tab on the Ribbon\nIn the Analyze group, click Data Analysis\nChoose Exponential smoothing from the list of Analysis Tools and click OK\nWhen the Exponential smoothing dialog box appears:\n\nEnter B2:B13 in the Input Range box\nEnter 0.8 in the Damping factor box\nEnter C2 in the Output Range box\nSelect Chart Output\n\nClick OK"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-excel-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#exponential-smoothing-forecast-excel-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Exponential Smoothing Forecast: Excel",
    "text": "Exponential Smoothing Forecast: Excel\n\nGasoline sale time series with smoothing constant \\(\\alpha = 0.2\\)"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables",
    "text": "Forecast with Lag Variables\n\nLag variables are often used in time series analysis to capture the correlation (effect) of past time series values with (on) the present or future time series values.\n\nFor example, this quarter’s sales depend on (are correlated with) sales of the last three quarters.\nAt time any \\(t\\), variable \\(v_t\\) may depend on \\(y_{t-1}, y_{t-2}, y_{t-3}, \\dots\\), which are denoted by Lag 1, Lag 2, Lag 3, respectively.\nThese lag variables are considered predictors of \\(v_t\\).\n\nThis type of correlation is called autocorrelation.\nThe choice of lag order (how many periods back to look) and the selection of an appropriate forecasting model are critical for forecasting lag variables effectively."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-global-apple-iphone-quarterly-sales",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-global-apple-iphone-quarterly-sales",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables: Global Apple iPhone Quarterly Sales",
    "text": "Forecast with Lag Variables: Global Apple iPhone Quarterly Sales\n\n\n\n\nQuarter\n\\(t\\)\nSales ($Mil.)\n\n\n\n\nQ210\n1\n8.75\n\n\nQ310\n2\n8.40\n\n\nQ410\n3\n14.10\n\n\nQ111\n4\n16.24\n\n\nQ211\n5\n18.65\n\n\nQ311\n6\n20.34\n\n\nQ411\n7\n17.07\n\n\nQ112\n8\n37.04\n\n\nQ212\n9\n35.06\n\n\nQ312\n10\n26.03\n\n\nQ412\n11\n26.91\n\n\nQ113\n12\n47.79\n\n\n…\n…\n…\n\n\n\n\n\\(n = 32\\)"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables",
    "text": "Forecast with Lag Variables\nAssume lag order is 4.\n\n\n\nQuarter\n\\(t\\)\nSales ($Mil.)\nLag 1\nLag 2\nLag 3\nLag 4\n\n\n\n\nQ210\n1\n8.75\n\n\n\n\n\n\nQ310\n2\n8.40\n8.75\n\n\n\n\n\nQ410\n3\n14.10\n8.40\n8.75\n\n\n\n\nQ111\n4\n16.24\n14.10\n8.40\n8.75\n\n\n\nQ211\n5\n18.65\n16.24\n14.10\n8.40\n8.75\n\n\nQ311\n6\n20.34\n18.65\n16.24\n14.10\n8.40\n\n\n…\n…\n…\n…\n…\n…\n…"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-correlations",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-correlations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables: Correlations",
    "text": "Forecast with Lag Variables: Correlations\n\n\n\n\nSales ($Mil.)\nLag 1\nLag 2\nLag 3\n\n\n\n\nLag 1\n0.642\n\n\n\n\n\nLag 2\n0.418\n0.660\n\n\n\n\nLag 3\n0.603\n0.440\n0.660\n\n\n\nLag 4\n0.914\n0.605\n0.437\n0.664"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-full-model",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-full-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables: Full Model",
    "text": "Forecast with Lag Variables: Full Model\n\nSummary Output:\n\n\n\nRegression Statistics\n\n\n\n\n\nMultiple R\n0.9226\n\n\nR Square\n0.8511\n\n\nAdjusted R Square\n0.8252\n\n\nStandard Error\n7.0864\n\n\nObservations\n28\n\n\n\nANOVA\n\n\n\n\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n\nRegression\n4\n6602.696\n1650.674\n32.871\n0.000\n\n\nResidual\n23\n1154.980\n50.217\n\n\n\n\nTotal\n27\n7757.676\n\n\n\n\n\n\nCoefficients:\n\n\n\nVariables\nCoefficients\nStandard Error\nt Stat\nP-value\n\n\n\n\nIntercept\n16.438\n4.179\n3.933\n0.001\n\n\nLag 1\n0.011\n0.122\n0.091\n0.928\n\n\nLag 2\n-0.141\n0.119\n-1.188\n0.247\n\n\nLag 3\n0.007\n0.121\n0.057\n0.955\n\n\nLag 4\n0.858\n0.115\n7.467\n0.000"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-reduced-model",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-reduced-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables: Reduced Model",
    "text": "Forecast with Lag Variables: Reduced Model\n\nSummary Output:\n\n\n\nRegression Statistics\n\n\n\n\n\nMultiple R\n0.9144\n\n\nR Square\n0.8361\n\n\nAdjusted R Square\n0.8298\n\n\nStandard Error\n6.9933\n\n\nObservations\n28\n\n\n\nANOVA\n\n\n\n\ndf\nSS\nMS\nF\nSignificance F\n\n\n\n\nRegression\n1\n6486.115\n6486.115\n132.624\n0.000\n\n\nResidual\n26\n1271.561\n48.906\n\n\n\n\nTotal\n27\n7757.676\n\n\n\n\n\n\nCoefficients:\n\n\n\nVariables\nCoefficients\nStandard Error\nt Stat\nP-value\n\n\n\n\nIntercept\n13.161\n3.002\n4.384\n0.000\n\n\nLag 4\n0.813\n0.071\n11.516\n0.000\n\n\n\n\\[\n\\widehat{Sales_t} = 13.161 + (0.813) \\widehat{Sales_{t-4}}\n\\]\nwhere the predictor is the Lag 4 variable."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-excel",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#forecast-with-lag-variables-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Forecast with Lag Variables: Excel",
    "text": "Forecast with Lag Variables: Excel\n\n\nImportant!Do not include empty cells or fill empty cells with zeros in Step 2.\n\n\n\n\n\nStep 1: Set Up Your Data in Excel\n\n\nOrganize Your Data\n\nPlace your main variable (e.g., \\(Y\\)) in one column (e.g., A) with the header “Y”.\nCreate two new columns for the lagged versions of \\(Y\\):\n\n“Y_lag1” for the first lag, containing values of \\(Y\\) shifted down by one row.\n“Y_lag2” for the second lag, containing values of \\(Y\\) shifted down by two rows.\n\n\nCreate the Lagged Variables\n\nIn B3 (under “Y_lag1”), enter the formula =A2 to reference the previous row’s value of \\(Y\\).\nIn C4 (under “Y_lag2”), enter the formula =A2 to reference the value of \\(Y\\) two rows above.\n\nCopy these formulas down the columns to match the length of the \\(Y\\) column.\nLeave the first two rows empty in the lagged variable columns, as there are no lagged values for the initial observations.\n\n\nPrepare Data for Regression\n\nRemoving the first two rows from your analysis since they lack lagged values in an option, but it is not recommended. Start analysis from row 4 onward.\n\n\n\n\n\n\nStep 2: Run the Regression\n\n\n\nOpen the Data Analysis Tool\n\nGo to the Data tab &gt; Data Analysis.\nIf Data Analysis isn’t visible, enable it via File &gt; Options &gt; Add-Ins &gt; Excel Add-ins &gt; Analysis ToolPak.\n\nSelect Regression: Choose Regression in the Data Analysis dialog and click OK.\nSpecify the Input Range\n\nInput Y Range: Select the range of \\(Y\\) values, excluding the first two rows (e.g., A4:A20). Do not fill empty cells with zeros.\nInput X Range: Select both lagged variable ranges (e.g., B4:C20). Do not fill empty cells with zeros.\n\nSet Up Additional Options\n\nCheck Labels if headers were included in your input ranges.\nChoose the output location for the regression results.\n\nRun the Regression: Click OK to run. Excel will generate the regression output."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#trend-projection-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#trend-projection-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Trend Projection",
    "text": "Trend Projection\n\nIf a time series plot exhibits a linear trend, the method of least squares regression may be used to determine a trend line (projection) for future forecasts.\nLeast squares regression determines the unique trend line forecast, which minimizes the sum of squared (forecast) errors, SSE, between the trend line forecasts (predicted values) and the actual (observed) values for the time series.\nThe independent variable is the time period and the dependent variable is the actual observed value in the time series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression",
    "text": "Linear Trend Regression\n\n\n\n\nBicycle Yearly Sales Time Series\n\n\n\n\nTime (Year)\nSales (1000s)\n\n\n\n\n1\n21.6\n\n\n2\n22.9\n\n\n3\n25.5\n\n\n4\n21.9\n\n\n5\n23.9\n\n\n6\n27.5\n\n\n7\n31.5\n\n\n8\n29.7\n\n\n9\n28.6\n\n\n10\n31.4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlthough it shows some up and down movement over the past 10 years, we can identify a linear trend line.\nThe trend line provides a reasonable approximation o the. long-run movement in the series.\nWe can use the simple linear regression method to develop such a linear trend line."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression",
    "text": "Linear Trend Regression\n\n\n\n\n\n\n\n\nLinear Trend Equation\n\n\n\\[\n\\hat{Y_t} = b_0 + b_1 t, \\quad t = 1, 2, \\ldots\n\\]\nwhere:\n\n\\(\\hat{Y_t}\\) = linear trend forecast of mean response for period t\n\\(b_0\\) = estimated intercept of the linear trend line\n\\(b_1\\) = estimated slope of the linear trend line\n\\(t\\) = time period"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression",
    "text": "Linear Trend Regression\n\n\n\n\n\n\n\nComputing the Slope and Intercept for a Linear Trend\n\n\n\\[\nb_1 = \\frac{\\sum_{t=1}^{n} (t - \\bar{t})(Y_t - \\bar{Y})}{\\sum_{t=1}^{n} (t - \\bar{t})^2}, \\quad \\text{or} \\quad b_1 = \\frac{\\sum_{t=1}^{n} t Y_t - \\left( \\frac{\\sum_{t=1}^{n} t \\sum_{t=1}^{n} Y_t}{n} \\right)}{\\sum_{t=1}^{n} t^2 - \\left( \\frac{\\left(\\sum_{t=1}^{n} t\\right)^2}{n} \\right)}\n\\]\n\\[\nb_0 = \\bar{Y} - b_1 \\bar{t}\n\\]\nWhere:\n\n\\(Y_t\\) = value of the time series in period \\(t\\)\n\\(n\\) = number of time periods (number of observations)\n\\(\\bar{Y}\\) = average value of the time series\n\\(\\bar{t}\\) = average value of \\(t\\)"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression: Example",
    "text": "Linear Trend Regression: Example\n\nTo compute the linear trend equation for the bicycle sales time series, we begin the calculations by computing \\(\\bar{t}\\) and \\(\\bar{Y}\\).\n\\[\n\\bar{t} = \\frac{\\sum_{t=1}^{n} t}{n} = \\frac{55}{10} = 5.5\n\\]\n\\[\n\\bar{Y} = \\frac{\\sum_{t=1}^{n} Y_t}{n} = \\frac{264.5}{10} = 26.45\n\\]\n\nUsing these values, and the data, we can compute: the slope and intercept.\n\\[\nb_1 = \\frac{\\sum_{t=1}^{n} (t - \\bar{t})(Y_t - \\bar{Y})}{\\sum_{t=1}^{n} (t - \\bar{t})^2} = \\frac{90.75}{82.5} = 1.1\n\\]\n\\[\nb_0 = \\bar{Y} - b_1 \\bar{t} = 26.45 - 1.1(5.5) = 20.4\n\\]\n\n\nTherefore, the linear trend equation is:\n\\[\n\\hat{Y}_t = 20.4 + 1.1t\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression: Example",
    "text": "Linear Trend Regression: Example\n\nBicycle Sales Time Series\n\n\n\n\n\n\n\n\n\n\n\n\\(t\\)\n\\(Y_1\\)\n\\(t - \\bar{t}\\)\n\\(Y_1 - \\bar{Y}\\)\n\\((t - \\bar{t})(Y_1 - \\bar{Y})\\)\n\\((t - \\bar{t})^2\\)\n\n\n\n\n1\n21.6\n-4.5\n-4.85\n21.825\n20.25\n\n\n2\n22.9\n-3.5\n-3.55\n12.425\n12.25\n\n\n3\n25.5\n-2.5\n-0.95\n2.375\n6.25\n\n\n4\n21.9\n-1.5\n-4.55\n6.825\n2.25\n\n\n5\n23.9\n-0.5\n-2.55\n1.275\n0.25\n\n\n6\n27.5\n0.5\n1.05\n0.525\n0.25\n\n\n7\n31.5\n1.5\n5.05\n7.575\n2.25\n\n\n8\n29.7\n2.5\n3.25\n8.125\n6.25\n\n\n9\n28.6\n3.5\n2.15\n7.525\n12.25\n\n\n10\n31.4\n4.5\n4.95\n22.275\n20.25\n\n\nTotals\n264.5\n\n\n90.750\n82.5"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression: Example",
    "text": "Linear Trend Regression: Example\nLinear Trend Equation for the Bicycle Sales Time Series:\n\\[\n\\hat{Y}_t = 20.4 + 1.1t\n\\]\nThe slope 1.1 indicates that over the past 10 years the firm experienced an average growth in sales of about 1100 units per year.\n\nIf we assume that the past 10-year trend in sales is a good indicator of the future, this trend equation can be used to develop forecasts for future time periods. Substituting \\(t = 11\\) into the equation yields next year’s trend projection or forecast, \\(\\hat{Y}_{11}\\).\n\\[\n\\hat{Y}_t = 20.4 + 1.1 \\times 11 = 32.5\n\\]\nThus, using trend projection, we would forecast sales of 32,500 bicycles next year."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#linear-trend-regression-example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Linear Trend Regression: Example",
    "text": "Linear Trend Regression: Example\n\nBicycle Sales Time Series\n\n\n\nYear\nSales\nForecast\nForecast error\nSquared Forecast Error\n\n\n\n\n1\n21.6\n21.5\n0.1\n0.01\n\n\n2\n22.9\n22.6\n0.3\n0.09\n\n\n3\n25.5\n23.7\n1.8\n3.24\n\n\n4\n21.9\n24.8\n-2.9\n8.41\n\n\n5\n23.9\n25.9\n-2.0\n4.00\n\n\n6\n27.5\n27.8\n0.5\n0.25\n\n\n7\n31.5\n28.1\n3.4\n11.56\n\n\n8\n29.7\n29.2\n0.5\n0.25\n\n\n9\n28.6\n30.3\n-1.7\n2.89\n\n\n10\n31.4\n31.4\n0.0\n0.00\n\n\nTotal\n264.5\n\n\n30.7\n\n\n\n\\[\n\\text{MSE} = \\frac{\\sum_{t=1}^{n} (Y_t - F_t)^2}{n} = \\frac{30.7}{10} = 3.07\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#regression-output-example-excel",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#regression-output-example-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Regression Output: Example Excel",
    "text": "Regression Output: Example Excel\n\n\n\n\nEnter/Access Data: Open the file Bicycle. The data are in cells A2:B11 and labels are in cells A1:B1.\n\n\nStep 1: Click the Data tab on the Ribbon\nStep 2: In the Analyze group, click Data Analysis\nStep 3: Choose Regression from the list of Analysis Tools\nStep 4: When the Regression dialog box appears:\n\nEnter B1:B11 in the Input Y Range box\nEnter A1:A11 in the Input X Range box\nSelect the check box for Labels\nSelect the check box for Confidence Level\nOutput Range:\n\nEnter A13 in the Output Range box (to identify the upper left corner of the section of the worksheet where the output will appear)\n\nClick OK"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Nonlinear Trend Regression",
    "text": "Nonlinear Trend Regression\n\nSometimes time series have a curvilinear or nonlinear trend.\nA variety of nonlinear functions can be used to develop an estimate of the trend in a time series.\nOne example is this quadratic trend equation:\n\n\\[\n\\hat{Y_t} = b_0 + b_1t + b_2t^2\n\\]\n\nAnother example is this exponential trend equation:\n\n\\[\n\\hat{Y_t} = b_0(b_1)^t\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Nonlinear Trend Regression: Example",
    "text": "Nonlinear Trend Regression: Example\n\nCholesterol Revenue Time Series\nThe data regarding cholesterol sales over a period of 10 years is tabulated below. A curvilinear function appears to be needed to model the long-term trend.\n\n\n\n\n\n\nYear\nRevenue ($ millions)\n\n\n\n\n1\n23.1\n\n\n2\n21.3\n\n\n3\n27.4\n\n\n4\n34.6\n\n\n5\n33.8\n\n\n6\n43.2\n\n\n7\n59.5\n\n\n8\n64.4\n\n\n9\n74.2\n\n\n10\n99.3"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example-excel",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example-excel",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Nonlinear Trend Regression: Example Excel",
    "text": "Nonlinear Trend Regression: Example Excel\n\n\n\n\nEnter/Access Data: Open the file Cholesterol.\n\n\nStep 1: Click the Data tab on the Ribbon\nStep 2: In the Analyze group, click Data Analysis\nStep 3: Choose Regression from the list of Analysis Tools\nStep 4: When the Regression dialog box appears:\n\nEnter C1:C11 in the Input Y Range box\nEnter A1:B11 in the Input X Range box\nSelect the check box for Labels\nSelect the check box for Confidence Level\nOutput Range:\n\nEnter A13 in the Output Range box (to identify the upper left corner of the section of the worksheet where the output will appear)\n\nClick OK\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe estimated regression equation is:\n\\[\n\\hat{Y}_t = 24.1817 - 2.1060t + 0.9216t^2\n\\]\nThe forecast of sales revenue for year 11 is:\n\\[\n\\hat{Y}_t = 24.1817 - 2.1060(11) + 0.9216(11)^2 = 112.53, \\quad \\text{or} \\quad \\approx \\text{\\$112.5 million}.\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example-excel-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#nonlinear-trend-regression-example-excel-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Nonlinear Trend Regression: Example Excel",
    "text": "Nonlinear Trend Regression: Example Excel\n\n\n\nSteps for Creating a Scatter Plot with Trendline\n\nEnter/Access Data: Open the file Cholesterol\n\n\nStep 1: Select cells B2:B11\nStep 2: Click the Insert tab on the Ribbon\nStep 3: In the Charts group, click the Insert Scatter (X, Y) or Bubble Chart button\nStep 4: When the list of scatter diagram subtypes appears, click the Scatter button (the chart in the upper left corner)\nStep 5: Click OK; the scatter diagram will appear in the current worksheet\nStep 6: Position the mouse pointer over any data point in the scatter diagram, right-click, and choose Add Trendline\nStep 7: In the Format Trendline dialog box:\n\nChoose Polynomial from the Trend/Regression Type list\nEnter 2 in the Order box\nChoose Display Equation on chart"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend",
    "text": "Seasonality Without Trend\n\nWhen seasonality exists, we need to incorporate it into our forecasting models to ensure accurate forecasts.\nWe will first look at the case of a seasonal time series with no trend and then discuss how to model seasonality with trend.\nSeasonal patterns are recognized by seeing the same repeating pattern of highs and lows over successive and short periods of time (within a “short” period of time).\n\nA seasonal pattern might occur within a day, week, month, quarter, year, or some other interval no greater than a year.\nA seasonal pattern does not necessarily refer to the four seasons of the year (spring, summer, fall, and winter)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\n\n\n\n\nUmbrella Quarterly Sales Time Series\n\n\n\n\nYear\nQuarter\nSales\n\n\n\n\n1\n1\n125\n\n\n1\n2\n153\n\n\n1\n3\n106\n\n\n1\n4\n88\n\n\n2\n1\n118\n\n\n2\n2\n161\n\n\n2\n3\n133\n\n\n2\n4\n102\n\n\n3\n1\n138\n\n\n3\n2\n144\n\n\n3\n3\n113\n\n\n3\n4\n80\n\n\n4\n1\n109\n\n\n4\n2\n137\n\n\n4\n3\n125\n\n\n4\n4\n109\n\n\n5\n1\n130\n\n\n5\n2\n165\n\n\n5\n3\n128\n\n\n5\n4\n96"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\n\n\n\nUmbrella Quarterly Sales Time Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe time series plot does not clearly indicate any long-term trend in sales.\nHowever, close inspection of the plot does reveal a seasonal pattern.\n\nThe first and third quarters have moderate sales,\nthe second quarter has the highest sales, and\nthe fourth quarter tends to be the lowest quarter in terms of sales."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\n\nRecall that dummy variables can be used to deal with categorical independent variables in a multiple regression model.\nWe will treat the season as a categorical variable.\nRecall that when a categorical variable has \\(k\\) levels, \\(k - 1\\) dummy variables are required.\nIf there are four seasons, we have the following dummy variables with \\(Qtr4\\) being the reference level:\n\n\n\n\\[\n\\text{Qtr1} =\n\\begin{cases}\n1 & \\text{if Quarter 1} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n\\text{Qtr2} =\n\\begin{cases}\n1 & \\text{if Quarter 2} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\quad\n\\text{Qtr3} =\n\\begin{cases}\n1 & \\text{if Quarter 3} \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\n\n\n\n\n\n\nYear\nQuarter\nQtr1\nQtr2\nQtr3\nSales\n\n\n\n\n1\n1\n1\n0\n0\n125\n\n\n1\n2\n0\n1\n0\n153\n\n\n1\n3\n0\n0\n1\n106\n\n\n1\n4\n0\n0\n0\n88\n\n\n2\n1\n1\n0\n0\n118\n\n\n2\n2\n0\n1\n0\n161\n\n\n2\n3\n0\n0\n1\n133\n\n\n2\n4\n0\n0\n0\n102\n\n\n3\n1\n1\n0\n0\n138\n\n\n3\n2\n0\n1\n0\n144\n\n\n3\n3\n0\n0\n1\n113\n\n\n3\n4\n0\n0\n0\n80\n\n\n4\n1\n1\n0\n0\n109\n\n\n4\n2\n0\n1\n0\n137\n\n\n4\n3\n0\n0\n1\n125\n\n\n4\n4\n0\n0\n0\n109\n\n\n5\n1\n1\n0\n0\n130\n\n\n5\n2\n0\n1\n0\n165\n\n\n5\n3\n0\n0\n1\n128\n\n\n5\n4\n0\n0\n0\n96"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\n\nGeneral Form of Estimated Regression Equation\n\n\\[\n\\hat{Y} = b_0 + b_1(Qtr1) + b_2(Qtr2) + b_3(Qtr3)\n\\]\n\n\nEstimated Regression Equation\n\n\\[\n\\text{Forecasted Sales} = 95.0 + 29.0(Qtr1) + 57.0(Qtr2) + 26.0(Qtr3)\n\\]\n\n\n\nForecast of Mean Quarterly Sales in Year 6\n\nQuarter 1: Sales = 95 + 29(1) + 57(0) + 26(0) = 124\nQuarter 2: Sales = 95 + 29(0) + 57(1) + 26(0) = 152\nQuarter 3: Sales = 95 + 29(0) + 57(0) + 26(1) = 121\nQuarter 4: Sales = 95 + 29(0) + 57(0) + 26(0) = 95"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-5",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-without-trend-example-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality Without Trend: Example",
    "text": "Seasonality Without Trend: Example\nNote that we could have obtained the quarterly forecasts for next year simply by computing the average number of umbrellas sold in each quarter:\n\n\n\nYear\nQuarter 1\nQuarter 2\nQuarter 3\nQuarter 4\n\n\n\n\n1\n125\n153\n106\n88\n\n\n2\n118\n161\n133\n102\n\n\n3\n138\n144\n113\n80\n\n\n4\n109\n137\n125\n109\n\n\n5\n130\n165\n128\n96\n\n\nAverage\n124\n152\n121\n95\n\n\n\nNonetheless, the regression output provides additional information that can be used to assess the accuracy of the forecast and determine the significance of the results."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality and Trend: Example",
    "text": "Seasonality and Trend: Example\n\n\n\nSmartphone Quarterly Sales Data (in Thousands)\n\n\n\nYear\nQuarter\nSales (1000s)\n\n\n\n\n1\n1\n4.8\n\n\n\n2\n4.1\n\n\n\n3\n6.0\n\n\n\n4\n6.5\n\n\n2\n1\n5.8\n\n\n\n2\n5.2\n\n\n\n3\n6.8\n\n\n\n4\n7.4\n\n\n3\n1\n6.0\n\n\n\n2\n5.6\n\n\n\n3\n7.5\n\n\n\n4\n7.8\n\n\n4\n1\n6.3\n\n\n\n2\n5.9\n\n\n\n3\n8.0\n\n\n\n4\n8.4"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality and Trend: Example",
    "text": "Seasonality and Trend: Example\nMultiple Regression Equation for Seasonal Effects and Trend\nThe general form of the estimated multiple regression equation for modeling both the quarterly seasonal effects and the linear trend in the smartphone time series is as follows:\n\\[\n\\hat{Y}_t = b_0 + b_1 \\text{Qtr1} + b_2 \\text{Qtr2} + b_3 \\text{Qtr3} + b_4 t\n\\]\nwhere\n\n\\(\\hat{Y}_t\\) = estimate or forecast of sales in period \\(t\\)\nQtr1 = 1 if time period \\(t\\) corresponds to the first quarter of the year; 0 otherwise\nQtr2 = 1 if time period \\(t\\) corresponds to the second quarter of the year; 0 otherwise\nQtr3 = 1 if time period \\(t\\) corresponds to the third quarter of the year; 0 otherwise\n\\(t\\) = time period"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality and Trend: Example",
    "text": "Seasonality and Trend: Example\n\n\n\nQuarterly Sales Data with Indicators and Period\n\n\n\nYear\nQuarter\nQtr1\nQtr2\nQtr3\nPeriod\nSales (1000s)\n\n\n\n\n1\n1\n1\n0\n0\n1\n4.8\n\n\n\n2\n0\n1\n0\n2\n4.1\n\n\n\n3\n0\n0\n1\n3\n6.0\n\n\n\n4\n0\n0\n0\n4\n6.5\n\n\n2\n1\n1\n0\n0\n5\n5.8\n\n\n\n2\n0\n1\n0\n6\n5.2\n\n\n\n3\n0\n0\n1\n7\n6.8\n\n\n\n4\n0\n0\n0\n8\n7.4\n\n\n3\n1\n1\n0\n0\n9\n6.0\n\n\n\n2\n0\n1\n0\n10\n5.6\n\n\n\n3\n0\n0\n1\n11\n7.5\n\n\n\n4\n0\n0\n0\n12\n7.8\n\n\n4\n1\n1\n0\n0\n13\n6.3\n\n\n\n2\n0\n1\n0\n14\n5.9\n\n\n\n3\n0\n0\n1\n15\n8.0\n\n\n\n4\n0\n0\n0\n16\n8.4"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality and Trend: Example",
    "text": "Seasonality and Trend: Example\n\nGeneral Form of Estimated Regression Equation\n\\[\n\\hat{Y} = b_0 + b_1 Qtr1 + b_2 \\cdot Qtr2 + b_3 \\cdot Qtr3 + b_4 \\cdot t\n\\]\nWhere \\(t\\) is the time period \\(t = 1, 2, \\ldots\\)\n\n\nEstimated Regression Equation\n\nForecast for Time Period 17 (Quarter 1 in Year 5)\n\\[\n\\text{Sales} = 6.07 - 1.36(1) - 2.03(0) - .304(0) + .146(17) = 7.19\n\\]\n\n\nForecast for Time Period 18 (Quarter 2 in Year 5)\n\\[\n\\text{Sales} = 6.07 - 1.36(0) - 2.03(1) - .304(0) + .146(18) = 6.67\n\\]\n\n\nForecast for Time Period 19 (Quarter 3 in Year 5)\n\\[\n\\text{Sales} = 6.07 - 1.36(0) - 2.03(0) - .304(1) + .146(19) = 8.54\n\\]\n\n\nForecast for Time Period 20 (Quarter 4 in Year 5)\n\\[\n\\text{Sales} = 6.07 - 1.36(0) - 2.03(0) - .304(0) + .146(20) = 8.99\n\\]\n\n\nThus, accounting for the seasonal effects and the linear trend in smartphone sales, the estimates of quarterly sales in year 5 are 7190, 6670, 8540, and 8990."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonality-and-trend-example-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonality and Trend: Example",
    "text": "Seasonality and Trend: Example\n\nThe dummy variables in the estimated multiple regression equation provide four estimated multiple regression equations, one for each quarter.\n\\[\n\\text{Quarter 1: Sales} = 6.07 - 1.36(1) - 2.03(0) - .304(0) + .146t = 4.71 + .146t\n\\]\nSimilarly, if time period \\(t\\) corresponds to quarters 2, 3, and 4, the estimates of quarterly sales are:\n\\[\n\\begin{align*}\n\\text{Quarter 2: Sales} & = 6.07 - 1.36(0) - 2.03(1) - .304(0) + .146t = 4.04 + .146t \\\\\n\\text{Quarter 3: Sales} & = 6.07 - 1.36(0) - 2.03(0) - .304(1) + .146t = 5.77 + .146t \\\\\n\\text{Quarter 4: Sales} & = 6.07 - 1.36(0) - 2.03(0) - .304(0) + .146t = 6.07 + .146t\n\\end{align*}\n\\]\n\nInterpretation of the Regression Coefficients\nThe slope of the trend line for each quarterly forecast equation is .146, indicating a growth in sales of about 146 smartphones per quarter.\nThe only difference in the four equations is that they have different intercepts.\nFor instance, the intercept for the quarter 1 equation is 4.71 and the intercept for the quarter 4 equation is 6.07. Thus, sales in quarter 1 are\n\\[\n4.71 - 6.07 = -1.36\n\\]\nor 1360 smartphones less than in quarter 4.\nIn other words, the estimated regression coefficient for Qtr1 provides an estimate of the difference in sales between quarter 1 and quarter 4."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-decomposition-motivation",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-decomposition-motivation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Decomposition: Motivation",
    "text": "Time Series Decomposition: Motivation\n\n\nUnderstanding what is really going on with a time series often depends upon the use of deseasonalized data.\nFor example, we might be interested in learning whether electrical power consumption is increasing in our area.\nSuppose we learn that electric power consumption in September is down 3% from the previous month. Is it correct to conclude that the electric power consumption is decreasing?\nWe must be careful with such information, because whenever a seasonal influence is present, such comparisons may be misleading if the data have not been deseasonalized.\nThe fact that electric power consumption is down 3% from August to September might be only the seasonal effect associated with a decrease in the use of air conditioning and not because of a long-term decline in the use of electric power.\nIndeed, after adjusting for the seasonal effect, we might even find that the use of electric power increased.\nMany other time series, such as unemployment statistics, home sales, and retail sales, are subject to strong seasonal influences. It is important to deseasonalize such data before making a judgment about any long-term trend."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-decomposition-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#time-series-decomposition-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Time Series Decomposition",
    "text": "Time Series Decomposition\nTime series decomposition can be used to separate or decompose a time series. It assumes that \\(Y_t\\), the actual time series value at period \\(t\\), is a function of three components:\n\nA trend component\nA seasonal component\nAn irregular or error component\n\n\nHow these three components are combined to generate the observed values of the time series depends upon whether we assume the relationship is best described by an additive or a multiplicative model."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#choosing-between-additive-and-multiplicative-models",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#choosing-between-additive-and-multiplicative-models",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Choosing Between Additive and Multiplicative Models",
    "text": "Choosing Between Additive and Multiplicative Models\n\nIf the seasonal fluctuations change over time, growing larger as the sales volume increases because of a long-term linear trend, then a multiplicative model should be used.\nMany business and economic time series follow this pattern."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#additive-decomposition-model",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#additive-decomposition-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Additive Decomposition Model",
    "text": "Additive Decomposition Model\n\nAn additive model is appropriate in situations where the seasonal fluctuations do not depend upon the level of the time series.\nIf the sizes of the seasonal fluctuations in earlier time periods are about the same as the sizes of the seasonal fluctuations in later time periods, an additive model is appropriate."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#additive-decomposition-model-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#additive-decomposition-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Additive Decomposition Model",
    "text": "Additive Decomposition Model\nAn additive decomposition model takes the following form:\n\\[\nY_t = Trend_t + Seasonal_t + Irregular_t\n\\]\nwhere\n\n\\(Trend_t\\) = trend value at time period \\(t\\)\n\\(Seasonal_t\\) = seasonal value at time period \\(t\\)\n\\(Irregular_t\\) = irregular value at time period \\(t\\)\nIn an additive model, the values for the three components are simply added together to obtain the actual time series value \\(Y_t\\).\nThe irregular or error component accounts for the variability in the time series that cannot be explained by the trend and seasonal components."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model",
    "text": "Multiplicative Decomposition Model\nA multiplicative decomposition model takes the following form:\n\\[\nY_t = Trend_t \\times Seasonal_t \\times Irregular_t\n\\]\nwhere\n\n\\(Trend_t\\) = trend value at time period \\(t\\)\n\\(Seasonal_t\\) = seasonal index at time period \\(t\\)\n\\(Irregular_t\\) = irregular index at time period \\(t\\)\nThe Census Bureau uses a multiplicative model in conjunction with its methodology for deseasonalizing time series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model",
    "text": "Multiplicative Decomposition Model\nIn this model, the trend, seasonal, and irregular components are multiplied to give the value of the time series.\n\nTrend is measured in units of the item being forecast.\nThe seasonal and irregular components are measured in relative terms:\n\nValues above 1.00 indicate effects above the trend.\nValues below 1.00 indicate effects below the trend."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example",
    "text": "Multiplicative Decomposition Model: Example\n\n\nSales are lowest in the second quarter of each year and increase in quarters 3 and 4.\nWe conclude that a seasonal pattern exists for the smartphone sales time series."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#procedures-overview",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#procedures-overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Procedures: Overview",
    "text": "Procedures: Overview\n\nThe computational procedure to identify each quarter’s seasonal influence begins by computing a moving average to remove the combined seasonal and irregular effects from the data, leaving us with a time series that contains only trend and any remaining random variation not removed by the moving average calculations.\n\nSteps 1-2: Calculate centered moving averages (Initial deseasonalized data).\nStep 3: Determine the seasonal and irregular factors for each time series value. (Individual factors due to seasonality and irregularity).\nStep 4: Determine Seasonal Index (SI) for each season (Updating the factors).\nStep 5: Determine the deseasonalized data (Update the deseasonalized data using SI).\nStep 6: Determine the Trend Component of the deseasonalized data (Model trend).\nStep 7: Determine the deseasonalized predictions (based on the Trend Component). (Forecast trend).\nStep 8: Add the seasonality to the predictions."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 1)",
    "text": "Multiplicative Decomposition Model: Example (Step 1)\nMoving Average Calculation\n\nBecause we are working with a quarterly series, we will use four data values in each moving average.\nThe moving average calculation for the first four quarters of the smartphone sales data is:\n\n\\[\n\\text{First moving average} = \\frac{4.8 + 4.1 + 6.0 + 6.5}{4} = \\frac{21.4}{4} = 5.35\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 1)",
    "text": "Multiplicative Decomposition Model: Example (Step 1)\nMoving Average Calculation\n\nNote that the moving average calculation for the first four quarters yields the average quarterly sales over year 1 of the time series.\nContinuing the moving average calculations, we next add the 5.8 value for the first quarter of year 2 and drop the 4.8 for the first quarter of year 1.\n\nThus, the second moving average is:\n\\[\n\\text{Second moving average} = \\frac{4.1 + 6.0 + 6.5 + 5.8}{4} = \\frac{22.4}{4} = 5.60\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 1)",
    "text": "Multiplicative Decomposition Model: Example (Step 1)\nMoving Average Calculation\nSimilarly, the third moving average calculation is:\n\\[\n(6.0 + 6.5 + 5.8 + 5.2) / 4 = 5.875\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-1-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 1)",
    "text": "Multiplicative Decomposition Model: Example (Step 1)\nBefore we proceed with the moving average calculations for the entire time series, let us return to the first moving average calculation, which resulted in a value of 5.35.\n\nThe 5.35 value is the average quarterly sales volume for year 1.\nAs we look back at the calculation of the 5.35 value, associating 5.35 with the “middle” of the moving average group makes sense."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 2)",
    "text": "Multiplicative Decomposition Model: Example (Step 2)\nPeriod Alignment with Moving Averages\nNote that with four quarters in the moving average, there is no middle period.\n\nThe 5.35 value really corresponds to period 2.5, the last half of quarter 2 and the first half of quarter 3.\nSimilarly, if we go to the next moving average value of 5.60, the middle period corresponds to period 3.5, the last half of quarter 3 and the first half of quarter 4."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 2)",
    "text": "Multiplicative Decomposition Model: Example (Step 2)\nCentering Moving Averages\nThe two moving average values we computed do not correspond directly to the original quarters of the time series.\n\nWe can resolve this by computing the average of the two moving averages.\nThe center of the first moving average is period 2.5, and the center of the second moving average is period 3.5.\nBy averaging these, we center the moving average at quarter 3, exactly where it should be."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 2)",
    "text": "Multiplicative Decomposition Model: Example (Step 2)\nCentered Moving Average Calculation\nThis moving average is referred to as a centered moving average.\n\nThus, the centered moving average for period 3 is:\n\n\\[\n\\frac{5.35 + 5.60}{2} = 5.475\n\\]\n\nSimilarly, the centered moving average value for period 4 is:\n\n\n\\[\n\\frac{5.60 + 5.875}{2} = 5.738\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-2-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 2)",
    "text": "Multiplicative Decomposition Model: Example (Step 2)\n\nCentered Moving Average Calculations\nSummary of the moving average and centered moving average calculations for the smartphone sales data.\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nQuarter\nSales (1000s)\nFour-Quarter Moving Average\nCentered Moving Average\n\n\n\n\n1\n1\n4.8\n\n\n\n\n1\n2\n4.1\n\n\n\n\n\n\n\n5.350\n\n\n\n1\n3\n6.0\n\n5.475\n\n\n\n\n\n5.600\n\n\n\n1\n4\n6.5\n\n5.738\n\n\n\n\n\n5.875\n\n\n\n2\n1\n5.8\n\n5.975\n\n\n\n\n\n6.075\n\n\n\n2\n2\n5.2\n\n6.188\n\n\n\n\n\n6.300\n\n\n\n2\n3\n6.8\n\n6.325\n\n\n\n\n\n6.350\n\n\n\n2\n4\n7.4\n\n6.400\n\n\n\n\n\n6.450\n\n\n\n3\n1\n6.0\n\n6.538\n\n\n\n\n\n6.625\n\n\n\n3\n2\n5.6\n\n6.675\n\n\n\n\n\n6.725\n\n\n\n3\n3\n7.5\n\n6.763\n\n\n\n\n\n6.800\n\n\n\n3\n4\n7.8\n\n6.838\n\n\n\n\n\n6.875\n\n\n\n4\n1\n6.3\n\n6.938\n\n\n\n\n\n7.000\n\n\n\n4\n2\n5.9\n\n7.075\n\n\n\n\n\n7.150\n\n\n\n4\n3\n8.0\n\n\n\n\n4\n4\n8.4"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 3)",
    "text": "Multiplicative Decomposition Model: Example (Step 3)\nWhat do the centered moving averages tell us about this time series?\n\n\n\nThe Figure shows a time series plot of the actual time series values and the centered moving average values.\nNote particularly how the centered moving average values tend to “smooth out” both the seasonal and irregular fluctuations in the time series.\nThe centered moving averages represent the trend in the data and any random variation that was not removed by using moving averages to smooth the data."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nThe multiplicative decomposition model is:\n\\[\nY_t = Trend_t \\times Seasonal_t \\times Irregular_t\n\\]\nBy dividing each side of this equation by the trend component \\(T_t\\), we can identify the combined seasonal-irregular effect in the time series.\n\\[\n\\frac{Y_t}{Trend_t} = \\frac{Trend_t \\times Seasonal_t \\times Irregular_t}{Trend_t} = Seasonal_t \\times Irregular_t\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nFor example, the third quarter of year 1 shows a trend value of 5.475 (the centered moving average).\nSo:\n\\[\n\\frac{6.0}{5.475} = 1.096\n\\]\nThis is the combined seasonal-irregular value."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\n\nSeasonal-irregular values for the entire time series.\n\n\n\n\n\n\n\n\n\n\nYear\nQuarter\nSales (1000s)\nCentered Moving Average\nSeasonal-Irregular Value\n\n\n\n\n1\n1\n4.8\n\n\n\n\n1\n2\n4.1\n\n\n\n\n1\n3\n6.0\n5.475\n1.096\n\n\n1\n4\n6.5\n5.738\n1.133\n\n\n2\n1\n5.8\n5.975\n0.971\n\n\n2\n2\n5.2\n6.188\n0.840\n\n\n2\n3\n6.8\n6.325\n1.075\n\n\n2\n4\n7.4\n6.400\n1.156\n\n\n3\n1\n6.0\n6.538\n0.918\n\n\n3\n2\n5.6\n6.675\n0.839\n\n\n3\n3\n7.5\n6.763\n1.109\n\n\n3\n4\n7.8\n6.838\n1.141\n\n\n4\n1\n6.3\n6.938\n0.908\n\n\n4\n2\n5.9\n7.075\n0.834\n\n\n4\n3\n8.0\n\n\n\n\n4\n4\n8.4"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-3",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-3",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nSeasonal-Irregular Values for Third Quarter\nConsider the seasonal-irregular values for the third quarter: 1.096, 1.075, and 1.109.\n\nSeasonal-irregular values greater than 1.00 indicate effects above the trend estimate, while values below 1.00 indicate effects below the trend estimate.\nThe three seasonal-irregular values for quarter 3 show an above-average effect in the third quarter."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-4",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-4",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nAveraging to Estimate Seasonal Influence\nSince the year-to-year fluctuations in the seasonal-irregular values are primarily due to random error, we can average the computed values to eliminate the irregular influence and obtain an estimate of the third-quarter seasonal influence.\n\\[\n\\text{Seasonal effect of quarter 3} = \\frac{1.096 + 1.075 + 1.109}{3} = 1.09\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-5",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nSeasonal-Irregular Values and Seasonal Indexes\n\n\n\nQuarter\nSeasonal-Irregular Values\nSeasonal Index\n\n\n\n\n1\n0.971, 0.918, 0.908\n0.93\n\n\n2\n0.840, 0.839, 0.834\n0.84\n\n\n3\n1.096, 1.075, 1.109\n1.09\n\n\n4\n1.133, 1.156, 1.141\n1.14\n\n\n\n\nThe seasonal indexes for the four quarters are 0.93, 0.84, 1.09, and 1.14.\nThe best sales quarter is the fourth quarter, with sales averaging 14% above the trend estimate.\nThe worst, or slowest, sales quarter is the second quarter; its seasonal index of 0.84 shows that the sales average is 16% below the trend estimate.\nThe seasonal component corresponds clearly to the intuitive expectation that smartphone sales increase when a new school year begins (quarter 3) and for the holiday season (quarter 4)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-6",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nOne final adjustment is sometimes necessary in obtaining the seasonal indexes.\n\nThe multiplicative model requires that the average seasonal index equal 1.00, so the sum of the four seasonal indexes must equal 4.00.\nIn other words, the seasonal effects must even out over the year.\nThe average of the seasonal indexes in our example is equal to 1.00, so this type of adjustment is not necessary."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-7",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#multiplicative-decomposition-model-example-step-4-7",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Multiplicative Decomposition Model: Example (Step 4)",
    "text": "Multiplicative Decomposition Model: Example (Step 4)\nMaking Adjustments (If Required)\nIn cases where adjustment is necessary:\n\nMultiply each seasonal index by the number of seasons divided by the sum of the unadjusted seasonal indexes.\n\nFor quarterly data, this means:\n\\[\n\\text{Adjusted Seasonal Index} = \\frac{4}{\\text{sum of the unadjusted seasonal indexes}}\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-step-5",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-step-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series (Step 5)",
    "text": "Deseasonalizing the Time Series (Step 5)\nA time series that has had the seasonal effects removed is referred to as a deseasonalized time series, and the process of using the seasonal indexes to remove the seasonal effects from a time series is referred to as deseasonalizing the time series.\n\nUsing a multiplicative decomposition model, we deseasonalize a time series by dividing each observation by its corresponding seasonal index.\nThe multiplicative decomposition model is:\n\n\\[\nY_t = Trend_t \\times Seasonal_t \\times Irregular_t\n\\]\nWhen we divide each time series observation \\(Y_t\\) by its corresponding seasonal index, the resulting data show only trend and random variability (the irregular component)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalized-sales-data-table-step-5",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalized-sales-data-table-step-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalized Sales Data Table (Step 5)",
    "text": "Deseasonalized Sales Data Table (Step 5)\n\n\n\n\n\n\n\n\n\n\n\n\nYear\nQuarter\nTime Period\nSales (1000s)\nSeasonal Index\nDeseasonalized Sales\n\n\n\n\n1\n1\n1\n4.8\n0.93\n5.16\n\n\n1\n2\n2\n4.1\n0.84\n4.88\n\n\n1\n3\n3\n6.0\n1.09\n5.50\n\n\n1\n4\n4\n6.5\n1.14\n5.70\n\n\n2\n1\n5\n5.8\n0.93\n6.24\n\n\n2\n2\n6\n5.2\n0.84\n6.19\n\n\n2\n3\n7\n6.8\n1.09\n6.24\n\n\n2\n4\n8\n7.4\n1.14\n6.49\n\n\n3\n1\n9\n6.0\n0.93\n6.45\n\n\n3\n2\n10\n5.6\n0.84\n6.67\n\n\n3\n3\n11\n7.5\n1.09\n6.88\n\n\n3\n4\n12\n7.8\n1.14\n6.84\n\n\n4\n1\n13\n6.3\n0.93\n6.77\n\n\n4\n2\n14\n5.9\n0.84\n7.02\n\n\n4\n3\n15\n8.0\n1.09\n7.34\n\n\n4\n4\n16\n8.4\n1.14\n7.37"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalized-sales-plot-step-5",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalized-sales-plot-step-5",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalized Sales Plot (Step 5)",
    "text": "Deseasonalized Sales Plot (Step 5)"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-step-5-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-step-5-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series (Step 5)",
    "text": "Deseasonalizing the Time Series (Step 5)\nIdentifying Trend in Deseasonalized Data\nThe graph of the deseasonalized smartphone sales time series shown in the Figure appears to have an upward linear trend.\n\nTo identify this trend, we will fit a linear trend equation to the deseasonalized time series.\nThe only difference is that we will be fitting a trend line to the deseasonalized data instead of the original data."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-linear-trend-equation-step-6",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-linear-trend-equation-step-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series: Linear Trend Equation (Step 6)",
    "text": "Deseasonalizing the Time Series: Linear Trend Equation (Step 6)\nRecall that for a linear trend, the estimated regression equation can be written as:\n\\[\nT_t = b_0 + b_1 t\n\\]\nwhere\n\n\\(T_t\\): linear trend forecast in period \\(t\\)\n\\(b_0\\): intercept of the linear trend line\n\\(b_1\\): slope of the trend line\n\\(t\\): time period"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-fitting-a-linear-trend-line-step-6",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-fitting-a-linear-trend-line-step-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series: Fitting a Linear Trend Line (Step 6)",
    "text": "Deseasonalizing the Time Series: Fitting a Linear Trend Line (Step 6)\nTo fit a linear trend line to the deseasonalized data, the only change is that the deseasonalized time series values are used instead of the observed values \\(Y_t\\) in computing \\(b_0\\) and \\(b_1\\).\nUsing Excel’s Regression tool, the estimated linear trend equation is:\n\\[\n\\text{Deseasonalized Sales} = 5.10 + 0.148t\n\\]"
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-interpretation-of-the-slope-step-6",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-interpretation-of-the-slope-step-6",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series: Interpretation of the Slope (Step 6)",
    "text": "Deseasonalizing the Time Series: Interpretation of the Slope (Step 6)\n\nThe slope of 0.148 indicates that over the past 16 quarters, the firm averaged a deseasonalized growth in sales of about 148 smartphones per quarter.\nIf we assume that the past 16-quarter trend in sales data is a reasonably good indicator of the future, this equation can be used to develop a trend projection for future quarters."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-example-projection-step-7",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#deseasonalizing-the-time-series-example-projection-step-7",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Deseasonalizing the Time Series: Example Projection (Step 7)",
    "text": "Deseasonalizing the Time Series: Example Projection (Step 7)\nSubstituting \\(t = 17\\) into the equation yields next quarter’s deseasonalized trend projection, \\(T_{17}\\):\n\\[\nT_{17} = 5.10 + 0.148(17) = 7.616\n\\]\nThus, using the deseasonalized data, the linear trend forecast for next quarter (period 17) is 7616 smartphones.\nSimilarly, the deseasonalized trend forecasts for the next three quarters (periods 18, 19, and 20) are 7764, 7912, and 8060 smartphones, respectively."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonal-adjustments-step-8",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonal-adjustments-step-8",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonal Adjustments (Step 8)",
    "text": "Seasonal Adjustments (Step 8)\nThe final step in developing the forecast when both trend and seasonal components are present is to use the seasonal indexes to adjust the deseasonalized trend projections.\n\nFor the smartphone sales example, we have a deseasonalized trend projection for the next four quarters.\nNow, we must adjust the forecast for the seasonal effect.\n\nThe seasonal index for the first quarter of year 5 (\\(t = 17\\)) is 0.93, so we obtain the quarterly forecast by multiplying the deseasonalized forecast based on trend \\((T_{17} = 7616)\\) by the seasonal index (0.93). Thus, the forecast for the next quarter is \\(7616 \\times 0.93 = 7083\\)."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonal-adjustments-quarterly-forecasts-table-step-8",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#seasonal-adjustments-quarterly-forecasts-table-step-8",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Seasonal Adjustments: Quarterly Forecasts Table (Step 8)",
    "text": "Seasonal Adjustments: Quarterly Forecasts Table (Step 8)\n\n\n\n\n\n\n\n\n\n\nYear\nQuarter\nDeseasonalized Trend Forecast\nSeasonal Index\nQuarterly Forecast\n\n\n\n\n5\n1\n7616\n0.93\n\\(7616 \\times 0.93 = 7083\\)\n\n\n5\n2\n7764\n0.84\n\\(7764 \\times 0.84 = 6522\\)\n\n\n5\n3\n7912\n1.09\n\\(7912 \\times 1.09 = 8624\\)\n\n\n5\n4\n8060\n1.14\n\\(8060 \\times 1.14 = 9188\\)\n\n\n\n\nThe high-volume fourth quarter has a 9188-unit forecast, and the low-volume second quarter has a 6522-unit forecast."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#cyclical-component",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#cyclical-component",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Cyclical Component",
    "text": "Cyclical Component\nMathematically, the multiplicative model can be expanded to include a cyclical component.\n\\[\nY_t = Trend_t \\times Cyclical_t \\times Seasonal_t \\times Irregular_t\n\\]\n\nThe cyclical component, like the seasonal component, is expressed as a percentage of trend.\nThis component is attributable to multiyear cycles in the time series.\n\nIt is analogous to the seasonal component but over a longer period. However, due to the length of time involved, obtaining enough relevant data to estimate the cyclical component is often difficult."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#cyclical-component-challenges",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#cyclical-component-challenges",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Cyclical Component: Challenges",
    "text": "Cyclical Component: Challenges\n\nCycles usually vary in length, making it difficult to identify or separate cyclical effects from long-term trend effects.\nIn practice, these effects are often combined and referred to as a combined trend-cycle component."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#summary-1",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nTime Series Analysis: Understand patterns (trend, seasonality, cycles) to forecast future values.\nForecast Accuracy: Key measures include MAE, MSE, and MAPE for assessing model performance.\nSmoothing Techniques: Moving averages and exponential smoothing help in handling horizontal patterns.\nTrend and Seasonality: Apply decomposition and regression for more complex time series with trends and seasonal variations."
  },
  {
    "objectID": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#summary-2",
    "href": "lecture_slides/17_chapter_time_series/17_chapter_time_series.html#summary-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nImportant: The following table is not exhaustive; it merely illustrates the examples discussed in the lecture. Remember that within the General Linear Model framework, these methods can be combined and adapted based on the specific objectives of the analysis.\n\n\n\n\n\n\n\n\n\n\n\n\nForecasting Method / Pattern\nHorizontal\nLinear Trend\nNon-linear Trend\nSeasonal\nSeasonal + Trend\n\n\n\n\n1. Naive Forecast\nX\n\n\n\n\n\n\n2. Hist. Data Average Method\nX\n\n\n\n\n\n\n3. Moving Average (\\(k\\) and \\(1/k\\))\nX\n\n\n\n\n\n\n4. Weighted Moving Average (\\(k\\), weights should sum to 1)\nX\n\n\n\n\n\n\n5. Exponential Smoothing (\\(\\alpha\\))\nX\n\n\n\n\n\n\n6. Regression Model: Lag Variable\n\nX\nX\nX\nX\n\n\n7. Regression Model: Time as Independent Variable\n\nX\n\n\n\n\n\n8. Regression Model: Time as Independent Variable with Transformation\n\n\nX\n\n\n\n\n9. Regression Model: Season as Independent Variable\n\n\n\nX\n\n\n\n10. Regression Model: Time and Season as Independent Variables\n\n\n\n\nX"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#overview",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#overview",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Overview",
    "text": "Overview\n\n\n\nProblem formulation.\nChance Events and States of Nature.\nPayoff tables.\nDecision trees.\n\n\n\nDecision Making with Probabilities.\n\nExpected Value Approach\nExpected Value of Perfect Information (EVPI)\nExpected Value with Sample Information (EVSI)\n\nBayes’ theorem to compute branch probabilities for decision trees."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#problem-formulation",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#problem-formulation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Problem Formulation",
    "text": "Problem Formulation\n\nThe first step in the decision analysis process is problem formulation.\n\nIt can be a verbal statement of the problem. Then, we identify the decision alternatives, the uncertain future events, referred to as chance events, and the consequences associated with each decision alternative and each chance event outcome."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-pittsburgh-development-corporation-pdc",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-pittsburgh-development-corporation-pdc",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Pittsburgh Development Corporation (PDC)",
    "text": "Example: Pittsburgh Development Corporation (PDC)\n\nPittsburgh Development Corporation (PDC) has purchased land to develop a luxury condominium complex with individual units priced between $300,000 and $1,400,000.\n\nDecision Problem: PDC’s primary decision challenge is to determine the optimal size of the condominium project that will maximize profits, considering the uncertainty of future demand for these units.\nProject Options: PDC has commissioned architectural plans for three potential project sizes:\n\nSmall Complex: 30 condominiums\nMedium Complex: 60 condominiums\nLarge Complex: 90 condominiums\n\nKey Considerations: The financial viability and success of the project depend on:\n\nThe selected project size (small, medium, or large)\nFuture demand for the condominiums, an uncertain factor influencing profitability\n\n\n\nPDC must analyze both the scale of the project and demand uncertainty to make an informed, profitable decision."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-pdcs-decision-alternatives",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-pdcs-decision-alternatives",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: PDC’s Decision Alternatives",
    "text": "Example: PDC’s Decision Alternatives\nIt is clear that the decision is to select the best size for the condominium complex.\n\nPDC has the following three decision alternatives:\n\\[\nd_1 = \\text{a small complex with 30 condominiums}\n\\]\n\\[\nd_2 = \\text{a medium complex with 60 condominiums}\n\\]\n\\[\nd_3 = \\text{a large complex with 90 condominiums}\n\\]"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#chance-events-and-states-of-nature-in-decision-analysis",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#chance-events-and-states-of-nature-in-decision-analysis",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Chance Events and States of Nature in Decision Analysis",
    "text": "Chance Events and States of Nature in Decision Analysis\nIn decision analysis, uncertain future events like demand levels are known as chance events.\nThe possible outcomes of these events are called states of nature, with only one state ultimately occurring."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-states-of-nature-for-the-pdc-project",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-states-of-nature-for-the-pdc-project",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: States of Nature for the PDC Project",
    "text": "Example: States of Nature for the PDC Project\n\nA key factor in PDC’s decision-making process is the uncertainty surrounding demand for the condominiums.\n\nFor PDC’s condominium project, the two relevant states of nature regarding demand are:\n\\[\ns_1 = \\text{Strong demand for the condominiums}\n\\]\n\\[\ns_2 = \\text{Weak demand for the condominiums}\n\\]\nBy defining these states of nature, PDC can structure its decision-making process to account for demand uncertainty and evaluate the impact of each demand scenario on project profitability."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-sequence-of-decisions-and-consequences",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-sequence-of-decisions-and-consequences",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Sequence of Decisions and Consequences",
    "text": "Example: Sequence of Decisions and Consequences\nThe decision analysis process follows a structured sequence to ensure optimal decision-making:\n\nSelect a Decision Alternative: Management begins by choosing a project size (complex size) from the available options (small, medium, or large complex).\nState of Nature Occurs: After the decision, an uncertain demand scenario—known as the state of nature—will materialize. In this case, it could be: Strong Demand or Weak Demand.\nObserve the Consequence: Based on the chosen project size and the actual demand, a consequence will occur. For PDC, the consequence is represented as profit or loss from the project.\n\n\nBy following this sequence, PDC can better understand potential outcomes and make informed decisions to maximize profitability."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#payoff-tables-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#payoff-tables-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Payoff Tables",
    "text": "Payoff Tables\nTo determine the optimal complex size, PDC must evaluate the consequence of each decision alternative under different demand scenarios. For the purpose of choosing the best Payoff, we use Payoff Tables.\n\nKey Concepts\nPayoff: The result (profit or loss) from a specific combination of a decision alternative (complex size) and a state of nature (demand).\nPayoff Table: A table that organizes payoffs for all possible combinations of decision alternatives and states of nature, providing a structured view of potential outcomes.\n\n\nBy analyzing the payoff table, PDC can make an informed decision that aligns with their profitability goals.\n\n\nGiven the three decision alternatives and the two states of nature, which complex size should PDC choose?"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-payoff-table",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-payoff-table",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Payoff Table",
    "text": "Example: Payoff Table\n\nThe payoff table will show projected profits (in millions of dollars) for each combination of decision alternative (complex size) and state of nature (demand).\n\n\n\n\n\n\n\n\nDecision Alternative / State of Nature\nStrong Demand(\\(s_1\\))\nWeak Demand(\\(s_2\\))\n\n\nSmall complex (\\(d_1\\))\n8\n7\n\n\nMedium complex (\\(d_2\\))\n14\n5\n\n\nLarge complex (\\(d_3\\))\n20\n-9"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-interpreting-payoffs",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-interpreting-payoffs",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Interpreting Payoffs",
    "text": "Example: Interpreting Payoffs\nSince PDC’s goal is to maximize profit, profit is used as the payoff measure in this case.\n\nNotation: We use \\(V_{ij}\\) to denote the payoff for decision alternative \\(i\\) under state of nature \\(j\\).\n\n\nFrom the Payoff Table:\n\n\\(V_{31} = 20\\): A payoff of $20 million occurs if PDC builds a large complex (\\(d_3\\)) and demand is strong (\\(s_1\\)).\n\\(V_{32} = -9\\): A loss of $9 million occurs if PDC builds a large complex (\\(d_3\\)) and demand is weak (\\(s_2\\)).\n\n\n\nThese payoff values help PDC evaluate the potential financial outcomes of each decision under different demand scenarios, guiding them toward the most profitable choice."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-trees-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-trees-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Trees",
    "text": "Decision Trees\n\n\n\nA decision tree graphically shows the sequential nature of the decision-making process.\n\nThe Figure presents a decision tree for the PDC problem, demonstrating the natural or logical progression that will occur over time.\n\nFirst, PDC must make a decision regarding the size of the condominium complex (\\(d_1\\), \\(d_2\\), or \\(d_3\\)).\nThen, after the decision is implemented, either state of nature \\(s_1\\) or \\(s_2\\) will occur.\n\n\n\nThe number at each end point of the tree indicates the payoff associated with a particular sequence. For example:\n\nThe topmost payoff of 8 indicates an $8 million profit if PDC constructs a small condominium complex (\\(d_1\\)) and demand is strong (\\(s_1\\)).\nThe next payoff of 7 indicates an anticipated profit of $7 million if PDC constructs a small condominium complex (\\(d_1\\)) and demand is weak (\\(s_2\\)).\n\n\n\nThus, the decision tree shows the sequences of decision alternatives and states of nature, providing the six possible payoffs."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#explanation-of-the-decision-tree",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#explanation-of-the-decision-tree",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Explanation of the Decision Tree",
    "text": "Explanation of the Decision Tree\n\n\n\nThe decision tree has four nodes, numbered 1–4, representing decisions and chance events:\n\nDecision nodes (squares): Represent points where a decision must be made. Node 1 is the decision node.\nChance nodes (circles): Represent points where the outcome depends on chance. Nodes 2, 3, and 4 are chance nodes.\nBranches: Branches leaving the decision node correspond to decision alternatives (small, medium, or large complex).\nBranches: Branches leaving each chance node correspond to the states of nature (strong or weak demand).\nPayoffs: are shown at the end of each branch.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can the decision maker use the information in the payoff table or the decision tree to select the best decision alternative?"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-making-with-probabilities-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-making-with-probabilities-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Making with Probabilities",
    "text": "Decision Making with Probabilities\n\nWith the decision alternatives and the states of nature established, our next step is to determine the probabilities for each state of nature.\nThere are several methods to assign probabilities:\n\nClassical method: Based on logical analysis, typically used when outcomes are equally likely.\nRelative frequency method: Uses historical or empirical data to estimate probabilities.\nSubjective method: Relies on expert judgment or intuition when data is scarce or unavailable.\n\n\nWith these probabilities in hand, we apply the expected value approach to calculate the expected payoff for each decision alternative by weighting possible outcomes according to their probabilities.\n\n\nThe decision alternative with the highest expected value is then identified as the best or recommended choice for the problem."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-approach",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-approach",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value Approach",
    "text": "Expected Value Approach\n\nThe probabilities for the states of nature must satisfy the basic requirements for assigning probabilities.\nWe begin by defining the expected value of a decision alternative. Let:\n\n\\(N\\) = the number of states of nature\n\\(P(s_j)\\) = the probability of state of nature \\(s_j\\)\n\n\nBecause one and only one of the \\(N\\) states of nature can occur, the probabilities must satisfy two conditions:\n\nNon-negativity: \\[\nP(s_j) \\geq 0 \\quad \\text{for all states of nature}\n\\]\nTotal probability: \\[\n\\sum_{j=1}^{N} P(s_j) = P(s_1) + P(s_2) + \\cdots + P(s_N) = 1\n\\]"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-calculation",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-calculation",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value Calculation",
    "text": "Expected Value Calculation\nThe expected value (EV) of decision alternative \\(d_i\\) is as follows:\n\\[\n\\text{EV}(d_i) = \\sum_{j=1}^{N} P(s_j) V_{ij}\n\\]\nwhere:\n\n\\(V_{ij}\\) = the value of the payoff for decision alternative \\(d_i\\) and state of nature \\(s_j\\).\n\n\nIn words, the expected value of a decision alternative is the sum of weighted payoffs for the decision alternative. The weight for a payoff is the probability of the associated state of nature and therefore the probability that the payoff will occur."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-calculation-of-expected-value",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-calculation-of-expected-value",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Calculation of Expected Value",
    "text": "Example: Calculation of Expected Value\n\nPDC is optimistic about the potential demand for its luxury high-rise condominium complex. Based on this optimism, PDC assigns subjective probabilities to represent the likelihood of each demand scenario:\n\nProbability of strong demand (\\(s_1\\)): \\(P(s_1) = 0.8\\)\nProbability of weak demand (\\(s_2\\)): \\(P(s_2) = 0.2\\)\n\n\nUsing these probabilities and the associated payoffs, we calculate the expected value (EV) for each decision alternative:\n\nSmall complex (\\(d_1\\)): \\[\n\\text{EV}(d_1) = 0.8(8) + 0.2(7) = 7.8\n\\]\nMedium complex (\\(d_2\\)): \\[\n\\text{EV}(d_2) = 0.8(14) + 0.2(5) = 12.2\n\\]\nLarge complex (\\(d_3\\)): \\[\n\\text{EV}(d_3) = 0.8(20) + 0.2(-9) = 14.2\n\\]\n\n\n\nBy comparing the expected values, we find that the large complex (\\(d_3\\)) yields the highest expected value of $14.2 million. Therefore, according to the expected value approach, the large complex is the recommended decision."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#applying-the-expected-value-approach-using-decision-trees",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#applying-the-expected-value-approach-using-decision-trees",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Applying the Expected Value Approach Using Decision Trees",
    "text": "Applying the Expected Value Approach Using Decision Trees\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe calculations required to identify the decision alternative with the best expected value can be conveniently carried out on a decision tree.\nWorking backward through the decision tree, we first compute the expected value at each chance node; that is, at each chance node, we weight each possible payoff by its probability of occurrence. By doing so, we obtain the expected values for nodes 2, 3, and 4."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-of-expected-value-approach-using-decision-trees",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-of-expected-value-approach-using-decision-trees",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary of Expected Value Approach Using Decision Trees",
    "text": "Summary of Expected Value Approach Using Decision Trees\n\nThe decision maker controls the choice at each decision node aiming to maximize the expected profit. At decision node 1, the expected value approach identifies the best decision alternative as:\n\nDecision \\(d_3\\): Constructing the large condominium complex, which yields an expected value of $14.2 million.\n\n\nThis recommendation of \\(d_3\\) is consistent with both the decision tree analysis and the expected value calculations derived from the payoff table.\nUsing the expected value approach in conjunction with the decision tree provides a clear and structured framework for selecting the optimal decision based on projected profits."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-perfect-information-evpi-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-perfect-information-evpi-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value of Perfect Information (EVPI)",
    "text": "Expected Value of Perfect Information (EVPI)\n\n\nWhat if PDC has the opportunity to conduct a market research study to gauge buyer interest in the condominium project?\n\n\nThis study could provide valuable information to refine the probability assessments for the different states of nature (e.g., strong or weak demand).\n\n\nTo understand the potential value of this information, we assume the study could yield perfect information — meaning PDC would know, with certainty, which state of nature will occur before making a decision.\n\n\nGiven this perfect information, we can develop an optimal decision strategy.\n\n\nWe can quantify how much PDC should be willing to pay for this perfect information by calculating the Expected Value of Perfect Information (EVPI)."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#payoff-table-for-the-pdc-condominium-project-millions",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#payoff-table-for-the-pdc-condominium-project-millions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Payoff Table for the PDC Condominium Project ($ Millions)",
    "text": "Payoff Table for the PDC Condominium Project ($ Millions)\n\n\n\n\nDecision Alternative\nStrong Demand \\(s_1\\)\nWeak Demand \\(s_2\\)\n\n\n\n\nSmall complex, \\(d_1\\)\n8\n7\n\n\nMedium complex, \\(d_2\\)\n14\n5\n\n\nLarge complex, \\(d_3\\)\n20\n-9"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy-with-perfect-information",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy-with-perfect-information",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Strategy with Perfect Information",
    "text": "Decision Strategy with Perfect Information\n\nWith perfect information about the states of nature, PDC can tailor its decision strategy to maximize profits based on certainty about demand:\n\nIf PDC knows with certainty that strong demand (\\(s_1\\)) will occur:\n\n\nThe optimal decision is to select the large complex (\\(d_3\\)), resulting in a payoff of $20 million.\n\n\nIf PDC knows with certainty that weak demand (\\(s_2\\)) will occur:\n\n\nThe optimal decision is to select the small complex (\\(d_1\\)), resulting in a payoff of $7 million.\n\n\nThis decision strategy demonstrates the value of perfect information by showing how it would enable PDC to make the most profitable choice in each scenario.\n\n\n\nWhat is the expected value for this decision strategy?"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-this-decision-strategy",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-this-decision-strategy",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value of this Decision Strategy",
    "text": "Expected Value of this Decision Strategy\n\nWhat is the expected value for this decision strategy?\n\n\nTo compute the expected value with perfect information, we return to the original probabilities for the states of nature:\n\n\\(P(s_1) = 0.8\\)\n\\(P(s_2) = 0.2\\)\n\n\n\nSo, the expected value of the decision strategy based on perfect information is:\n\\[\n0.8(20) + 0.2(7) = 17.4\n\\]\nWe refer to the expected value of $17.4 million as the expected value with perfect information (EVwPI)."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-perfect-information-evpi-2",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-perfect-information-evpi-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value of Perfect Information (EVPI)",
    "text": "Expected Value of Perfect Information (EVPI)\nIn general, the expected value of perfect information (EVPI) is computed as follows:\n\\[\n\\text{EVPI} = | \\text{EVwPI} - \\text{EVwoPI} |\n\\]\nwhere:\n\nEVPI = expected value of perfect information\nEVwPI = expected value with perfect information about the states of nature\nEVwoPI = expected value without perfect information about the states of nature\n\n\n\nNote the role of the absolute value. For minimization problems, information helps reduce or lower cost; thus, the expected value with perfect information is less than or equal to the expected value without perfect information. In this case, EVPI is the magnitude of the difference between EVwPI and EVwoPI."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-expected-value-of-perfect-information-evpi",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-expected-value-of-perfect-information-evpi",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Expected Value of Perfect Information (EVPI)",
    "text": "Example: Expected Value of Perfect Information (EVPI)\nThe expected value with perfect information is $17.4 million, and the expected value without perfect information (EVwoPI) is $14.2 million. Therefore, the expected value of perfect information (EVPI) is:\n\\[\n\\text{EVPI} = 17.4 - 14.2 = 3.2\n\\]\n\nIn other words, $3.2 million represents the additional expected value that can be obtained if perfect information were available about the states of nature.\n\n\nGiven the EVPI of $3.2 million, PDC might seriously consider a market survey as a way to obtain more information about the states of nature."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-analysis-with-sample-information-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-analysis-with-sample-information-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Analysis with Sample Information",
    "text": "Decision Analysis with Sample Information\nAdditional information is often obtained through sample information, which provides insights into the likely states of nature. Common sources of sample information include:\n\nRaw material sampling\nProduct testing\nMarket research studies\n\n\nUsing sample information, decision makers can update their prior probability estimates. These revised probabilities, adjusted based on new data, are referred to as posterior probabilities."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#market-research-study-for-pdc",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#market-research-study-for-pdc",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Market Research Study for PDC",
    "text": "Market Research Study for PDC\nLet’s assume that PDC manager is considering a six-month market research study designed to learn more about potential market acceptance of the PDC condominium project.\nShe anticipates that the market research study will provide one of the following two results:\n\nFavorable report: A significant number of the individuals contacted express interest in purchasing a PDC condominium.\nUnfavorable report: Very few of the individuals contacted express interest in purchasing a PDC condominium."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-tree-with-market-research-study",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-tree-with-market-research-study",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Tree with Market Research Study",
    "text": "Decision Tree with Market Research Study\n\n\nThe decision tree for the PDC problem with sample information shows the logical sequence for the decisions and the chance events.\n\nPDC’s management must decide whether the market research should be conducted.\nIf it is conducted, PDC’s management must be prepared to make a decision about the size of the condominium project if:\n\nthe market research report is favorable or\nthe market research report is unfavorable."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#analysis-of-decision-tree-structure",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#analysis-of-decision-tree-structure",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Analysis of Decision Tree Structure",
    "text": "Analysis of Decision Tree Structure\n\n\n\nIn the decision tree diagram:\n\nSquares represent decision nodes, where PDC actively makes a choice.\nCircles represent chance nodes, where the outcome is determined by probability rather than a decision.\n\n\nKey Nodes in the Decision Tree\n\nDecision Node 1:\n\nPDC must decide whether to conduct a market research study.\n\nChance Node 2:\n\nIf the study is conducted, the outcome—favorable or unfavorable report—is determined by chance, as PDC has no control over this result.\n\nDecision Node 3:\n\nIf the report is favorable, PDC must choose the size of the complex (small, medium, or large) based on this information.\n\nDecision Node 4:\n\nIf the report is unfavorable, PDC again chooses the size of the complex (small, medium, or large), this time with the knowledge of an unfavorable market assessment.\n\nChance Nodes 6 to 14:\n\nThese nodes represent the final demand outcomes (strong or weak) for each decision path. Here, the actual state of nature—strong demand or weak demand—is determined by chance."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#probabilities-for-market-research-study",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#probabilities-for-market-research-study",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Probabilities for Market Research Study",
    "text": "Probabilities for Market Research Study\n\n\n\nPDC developed the following branch probabilities.\n\nIf the market research study is undertaken,\n\\[\nP(\\text{Favorable report}) = P(F) = 0.77\n\\]\n\\[\nP(\\text{Unfavorable report}) = P(U) = 0.23\n\\]\nIf the market research report is favorable,\n\\[\nP(\\text{Strong demand given a favorable report}) = P(s_1 | F) = 0.94\n\\]\n\\[\nP(\\text{Weak demand given a favorable report}) = P(s_2 | F) = 0.06\n\\]\nIf the market research report is unfavorable,\n\\[\nP(\\text{Strong demand given an unfavorable report}) = P(s_1 | U) = 0.35\n\\]\n\\[\nP(\\text{Weak demand given an unfavorable report}) = P(s_2 | U) = 0.65\n\\]\nIf the market research report is not undertaken, the prior probabilities are applicable:\n\\[\nP(\\text{Strong demand}) = P(s_1) = 0.80\n\\]\n\\[\nP(\\text{Weak demand}) = P(s_2) = 0.20\n\\]"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Strategy",
    "text": "Decision Strategy\n\nThe approach used to determine the optimal decision strategy is based on a backward pass through the decision tree using the following steps:\n\nAt chance nodes, compute the expected value by multiplying the payoff at the end of each branch by the corresponding branch probability.\nAt decision nodes, select the decision branch that leads to the best expected value. This expected value becomes the expected value at the decision node."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#decision-strategy-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Decision Strategy",
    "text": "Decision Strategy\n\n\n\n\n\nStarting the backward pass calculations by computing the expected values at chance nodes 6 to 14 provides the following results:\n\n\\[\n\\begin{align*}\n\\text{EV(Node 6)} &= 0.94(8) + 0.06(7) = 7.94 \\\\\n\\text{EV(Node 7)} &= 0.94(14) + 0.06(5) = 13.46 \\\\\n\\text{EV(Node 8)} &= 0.94(20) + 0.06(-9) = 18.26 \\\\\n\\text{EV(Node 9)} &= 0.35(8) + 0.65(7) = 7.35 \\\\\n\\text{EV(Node 10)} &= 0.35(14) + 0.65(5) = 8.15 \\\\\n\\text{EV(Node 11)} &= 0.35(20) + 0.65(-9) = 1.15 \\\\\n\\text{EV(Node 12)} &= 0.80(8) + 0.20(7) = 7.80 \\\\\n\\text{EV(Node 13)} &= 0.80(14) + 0.20(5) = 12.20 \\\\\n\\text{EV(Node 14)} &= 0.80(20) + 0.20(-9) = 14.20 \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#selecting-best-decisions",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#selecting-best-decisions",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting Best Decisions",
    "text": "Selecting Best Decisions\n\n\n\nNext, move to decision nodes 3, 4, and 5. For each of these nodes, select the decision alternative branch that leads to the best expected value.\n\nAt node 3, the choices are:\n\nSmall complex branch: EV(Node 6) = 7.94\nMedium complex branch: EV(Node 7) = 13.46\nLarge complex branch: EV(Node 8) = 18.26\n\n\n\nThe best decision is the large complex, with EV(Node 3) = 18.26.\n\nAt node 4, we select the best expected value from nodes 9, 10, and 11. The best decision is the medium complex, with EV(Node 4) = 8.15.\nFor node 5, we select the best expected value from nodes 12, 13, and 14. The best decision is the large complex, with EV(Node 5) = 14.20.\n\n\n\nPDC Decision Tree After Choosing Best Decisions at Nodes 3, 4, and 5"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#selecting-best-decisions-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#selecting-best-decisions-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Selecting Best Decisions",
    "text": "Selecting Best Decisions\n\n\n\n\nThe expected value at chance node 2 can now be computed as follows:\n\\[\n\\begin{align*}\n\\text{EV(Node 2)} &= 0.77 \\times \\text{EV(Node 3)} + 0.23 \\times \\text{EV(Node 4)} \\\\\n&= 0.77(18.26) + 0.23(8.15) = 15.93\n\\end{align*}\n\\]\nThis calculation reduces the decision tree to one involving only the two decision branches from node 1.\n\nPDC Decision Tree Reduced to Two Decision Branches"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#final-decision-strategy",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#final-decision-strategy",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Final Decision Strategy",
    "text": "Final Decision Strategy\n\n\n\n\nAt decision node 1, PDC can determine the optimal choice by comparing the expected values from nodes 2 and 5.\n\nThe highest expected value is 15.93, which supports the decision to conduct the market research study.\n\n\nThe Optimal Decision Strategy for PDC is to conduct the market research study and then carry out the following decision strategy:\n\nIf the market research is favorable: Construct the large condominium complex to maximize profits (\\(d_3\\)).\nIf the market research is unfavorable: Construct the medium condominium complex as a safer choice under lower demand expectations (\\(d_2\\)).\n\n\n\nPDC Decision Tree After Choosing Best Decisions at Nodes 3, 4, and 5"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-of-decision-tree-analysis",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-of-decision-tree-analysis",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary of Decision Tree Analysis",
    "text": "Summary of Decision Tree Analysis\n\nWork backward through the tree to calculate expected values at each chance node.\nSelect the optimal decision branch at each decision node based on these expected values.\nThe resulting sequence of optimal branches forms the final decision strategy for maximizing expected profit.\n\n\nBy systematically calculating expected values and selecting the best options at each node, PDC arrives at a data-driven decision strategy that adapts based on the information received from the market research study."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-sample-information-formula",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#expected-value-of-sample-information-formula",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Expected Value of Sample Information Formula",
    "text": "Expected Value of Sample Information Formula\n\\[\n\\text{EVSI} = |\\text{EVwSI} - \\text{EVwoSI}|\n\\]\nwhere:\n\nEVSI = expected value of sample information\nEVwSI = expected value with sample information about the states of nature\nEVwoSI = expected value without sample information about the states of nature\n\n\n\nNote the role of the absolute value. For minimization problems, the expected value with sample information is always less than or equal to the expected value without sample information."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-expected-value-of-sample-information-evsi",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#example-expected-value-of-sample-information-evsi",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Example: Expected Value of Sample Information (EVSI)",
    "text": "Example: Expected Value of Sample Information (EVSI)\nThe expected value associated with the market research study is $15.93.\nBefore, we saw that the best expected value if the market research study is not undertaken is $14.20. Thus, we can conclude that the difference is:\n\\[\n\\text{EVSI} = 15.93 - 14.20 = 1.73\n\\]\nthat is the expected value of sample information (EVSI).\nTo conclude, conducting the market research study adds $1.73 million to the PDC expected value."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#computing-branch-probabilities-using-bayes-theorem-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#computing-branch-probabilities-using-bayes-theorem-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Computing Branch Probabilities Using Bayes’ Theorem",
    "text": "Computing Branch Probabilities Using Bayes’ Theorem\n\nThe branch probabilities for the PDC decision tree chance nodes were specified in the problem description, with no computations initially required.\n\n\nPDC developed the following branch probabilities.\n\nIf the market research study is undertaken,\n\\[\nP(\\text{Favorable report}) = P(F) = 0.77\n\\]\n\\[\nP(\\text{Unfavorable report}) = P(U) = 0.23\n\\]\nIf the market research report is favorable,\n\\[\nP(\\text{Strong demand given a favorable report}) = P(s_1 | F) = 0.94\n\\]\n\\[\nP(\\text{Weak demand given a favorable report}) = P(s_2 | F) = 0.06\n\\]\nIf the market research report is unfavorable,\n\\[\nP(\\text{Strong demand given an unfavorable report}) = P(s_1 | U) = 0.35\n\\]\n\\[\nP(\\text{Weak demand given an unfavorable report}) = P(s_2 | U) = 0.65\n\\]\nIf the market research report is not undertaken, the prior probabilities are applicable:\n\\[\nP(\\text{Strong demand}) = P(s_1) = 0.80\n\\]\n\\[\nP(\\text{Weak demand}) = P(s_2) = 0.20\n\\]"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#computing-branch-probabilities-using-bayes-theorem-2",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#computing-branch-probabilities-using-bayes-theorem-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Computing Branch Probabilities Using Bayes’ Theorem",
    "text": "Computing Branch Probabilities Using Bayes’ Theorem\nNow, we will see how Bayes’ theorem can be used to compute branch probabilities for decision trees.\nBayes’ theorem is expressed as:\n\\[\nP(s_j | F) = \\frac{P(F | s_j) \\cdot P(s_j)}{P(F)}\n\\]\nwhere:\n\n\\(P(s_j | F)\\) is the posterior probability of state \\(s_j\\) given a favorable report \\(F\\).\n\\(P(F | s_j)\\) is the conditional probability of receiving a favorable report given state \\(s_j\\).\n\\(P(s_j)\\) is the prior probability of state \\(s_j\\).\n\\(P(F)\\) is the total probability of receiving a favorable report."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#bayes-theorem-in-decision-trees",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#bayes-theorem-in-decision-trees",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Bayes’ Theorem in Decision Trees",
    "text": "Bayes’ Theorem in Decision Trees\n\n\n\nDefinitions\nLet:\n\n\\(F\\): Favorable market research report\n\\(U\\): Unfavorable market research report\n\\(s_1\\): Strong demand (state of nature 1)\n\\(s_2\\): Weak demand (state of nature 2)\n\n\nKey Branch Probabilities\n\nAt Chance Node 2: Determine probabilities of a favorable or unfavorable report: \\(P(F)\\) and \\(P(U)\\).\nAt Chance Nodes 6, 7, and 8: Calculate posterior probabilities for demand given a favorable report:\n\n\\(P(s_1 | F)\\): Probability of strong demand given a favorable report.\n\\(P(s_2 | F)\\): Probability of weak demand given a favorable report.\n\n\n\n\n\n\n\nAt Chance Nodes 9, 10, and 11: Calculate posterior probabilities for demand given an unfavorable report:\n\n\\(P(s_1 | U)\\): Probability of strong demand given an unfavorable report.\n\\(P(s_2 | U)\\): Probability of weak demand given an unfavorable report.\n\nAt Chance Nodes 12, 13, and 14: Use prior probabilities \\(P(s_1)\\) and \\(P(s_2)\\) if the market research study is not conducted.\n\n\n\nThe PDC Decision Tree"
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#conditional-probability-calculations",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#conditional-probability-calculations",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Conditional Probability Calculations",
    "text": "Conditional Probability Calculations\n\nTo perform the probability computations, we need two main sets of probabilities:\n\nPrior Probabilities: PDC’s initial assessment of the likelihood of each state of nature:\n\n\\(P(s_1)\\): Probability of strong demand.\n\\(P(s_2)\\): Probability of weak demand.\n\n\n\n\nConditional Probabilities: Likelihood of specific market research outcomes (sample information) given each state of nature.\n\n\n\nFavorable Report:\n\n\\(P(F | s_1)\\): Probability of favorable report given strong demand.\n\\(P(F | s_2)\\): Probability of favorable report given weak demand.\n\nUnfavorable Report:\n\n\\(P(U | s_1)\\): Probability of unfavorable report given strong demand.\n\\(P(U | s_2)\\): Probability of unfavorable report given weak demand.\n\n\n\n\nThese conditional probabilities allow us to use Bayes’ theorem to update prior probabilities based on market research outcomes, leading to more informed decision-making."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#market-research-probabilities-table",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#market-research-probabilities-table",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Market Research Probabilities Table",
    "text": "Market Research Probabilities Table\n\nWe assume that the following assessments are available for these conditional probabilities. This is the key piece of information that we use to compute the branches probabilities.\n\n\n\n\n\n\n\n\n\nState of Nature / Market Research\nFavorable, \\(F\\)\nUnfavorable, \\(U\\)\n\n\n\n\nStrong demand, \\(s_1\\)\n\\(P(F|s_1) = 0.90\\)\n\\(P(U|s_1) = 0.10\\)\n\n\nWeak demand, \\(s_2\\)\n\\(P(F|s_2) = 0.25\\)\n\\(P(U|s_2) = 0.75\\)\n\n\n\n\nNote: These probability assessments provide a reasonable degree of confidence in the market research study:\n\nIf \\(s_1\\) is true, \\(P(F|s_1) = 0.90\\) and \\(P(U|s_1) = 0.10\\).\nIf \\(s_2\\) is true, \\(P(F|s_2) = 0.25\\) and \\(P(U|s_2) = 0.75\\)."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#tabular-computation-branch-probabilities-for-favorable-report",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#tabular-computation-branch-probabilities-for-favorable-report",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tabular Computation: Branch Probabilities for Favorable Report",
    "text": "Tabular Computation: Branch Probabilities for Favorable Report\n\n\n\nSteps for Tabular Probability Computation\n\nStep 1: In column 1, enter the states of nature. In column 2, enter the prior probabilities. In column 3, enter the conditional probabilities of a favorable report \\(F\\) given each state of nature.\nStep 2: In column 4, compute the joint probabilities by multiplying the prior probability values in column 2 by the corresponding conditional probabilities in column 3.\nStep 3: Sum the joint probabilities in column 4 to obtain the probability of a favorable report, \\(P(F)\\).\nStep 4: Divide each joint probability in column 4 by \\(P(F) = 0.77\\) to obtain the revised or posterior probabilities, \\(P(s_1|F)\\) and \\(P(s_2|F)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n(1)States of Nature \\(s_j\\)\n(2)Prior Probabilities \\(P(s_j)\\)\n(3)Conditional Probabilities \\(P(F | s_j)\\)\n(4)Joint Probabilities \\(P(F \\cap s_j)\\)\n(5)Posterior Probabilities \\(P(s_j | F)\\)\n\n\n\n\n\\(s_1\\)\n0.8\n0.90\n\\(0.80\\times0.90 = 0.72\\)\n\\(\\frac{0.72}{0.77}=0.94\\)\n\n\n\\(s_2\\)\n0.2\n0.25\n0.05\n0.06\n\n\nTotal\n1.0\n\n\\(P(F) = 0.77\\)\n1.00\n\n\n\n\n\nThe Table shows that the probability of obtaining a favorable report is \\(P(F) = 0.77\\).\nIn addition:\n\n\\(P(s_1|F) = 0.94\\)\n\\(P(s_2|F) = 0.06\\)\n\n\n\nNote that a favorable report prompts a posterior probability of 0.94 that demand will be strong (\\(s_1\\))."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#tabular-computation-branch-probabilities-for-unfavorable-report",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#tabular-computation-branch-probabilities-for-unfavorable-report",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Tabular Computation: Branch Probabilities for Unfavorable Report",
    "text": "Tabular Computation: Branch Probabilities for Unfavorable Report\n\nThe tabular probability computation procedure must be repeated for each possible sample information outcome.\n\n\nSteps for Tabular Probability Computation\n\nStep 1: In column 1, enter the states of nature. In column 2, enter the prior probabilities. In column 3, enter the conditional probabilities of an unfavorable report \\(U\\) given each state of nature.\nStep 2: In column 4, compute the joint probabilities by multiplying the prior probability values in column 2 by the corresponding conditional probabilities in column 3.\nStep 3: Sum the joint probabilities in column 4 to obtain the probability of an unfavorable report, \\(P(U)\\).\nStep 4: Divide each joint probability in column 4 by \\(P(U) = 0.23\\) to obtain the revised or posterior probabilities, \\(P(s_1|U)\\) and \\(P(s_2|U)\\).\n\n\n\n\n\n\n\n\n\n\n\n\n(1)States of Nature \\(s_j\\)\n(2)Prior Probabilities \\(P(s_j)\\)\n(3)Conditional Probabilities \\(P(U | s_j)\\)\n(4)Joint Probabilities \\(P(U \\cap s_j)\\)\n(5)Posterior Probabilities \\(P(s_j | U)\\)\n\n\n\n\n\\(s_1\\)\n0.8\n0.10\n\\(0.8\\times0.1=0.08\\)\n\\(\\frac{0.08}{0.23}=0.35\\)\n\n\n\\(s_2\\)\n0.2\n0.75\n0.15\n0.65\n\n\nTotal\n1.0\n\n\\(P(U) = 0.23\\)\n1.00\n\n\n\n\nThe probability of an unfavorable report is \\(P(U) = 0.23\\).\nWith an unfavorable report:\n\n\\(P(s_1|U) = 0.35\\)\n\\(P(s_2|U) = 0.65\\)\nNote that an unfavorable report prompts a posterior probability of 0.65 that demand will be weak \\((s_2)\\)."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#conclusion",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#conclusion",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Conclusion",
    "text": "Conclusion\n\nThe resulting posterior probabilities provide a clearer understanding of potential outcomes, enabling PDC to select the optimal path based on updated insights. To recap from previous slides:\n\nThe Optimal Decision Strategy for PDC is to conduct the market research study and then carry out the following decision strategy, with EV = 15.93:\n\nIf the market research is favorable: Construct the large condominium complex to maximize profits (\\(d_3\\)) with EV = 18.26.\nIf the market research is unfavorable: Construct the medium condominium complex as a safer choice under lower demand expectations (\\(d_2\\)) with EV = 8.15."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-1",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-1",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\nSome key takeaways from this session:\n\nDecision Analysis Structure: A structured approach using payoff tables and decision trees allows for organized, strategic decision-making, particularly in uncertain conditions.\nExpected Value Approach: By calculating expected values across different states of nature, we can identify optimal decisions based on probabilistic outcomes, maximizing potential profits.\nValue of Information:\n\nExpected Value of Perfect Information (EVPI): Quantifies the benefit of having certainty about future states, guiding decision-makers on how much to invest in obtaining information.\nExpected Value of Sample Information (EVSI): Measures the potential benefit of additional data (e.g., market research), providing insight on the value of partial or imperfect information.\n\nBayes’ Theorem in Decision Trees: Allows for updating probabilities based on new evidence (e.g., favorable or unfavorable reports) to make more informed, dynamic decisions.\nDecision Trees with Probabilities: Decision trees not only display possible decisions and outcomes but, with added probabilities, allow for more precise expected value calculations.\nOptimal Decision Strategy: Analyzing decision trees and recalculating with updated probabilities leads to a final strategy that maximizes expected outcomes based on the best available information."
  },
  {
    "objectID": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-2",
    "href": "lecture_slides/20_chapter_decision_analysis/20_chapter_decision_analysis.html#summary-2",
    "title": " MGMT 30500: Business Statistics ",
    "section": "Summary",
    "text": "Summary\n\n\n\n\n\n\n\n\n\nTerm\nDefinition\nPurpose\nExample\n\n\n\n\nPayoff\nQuantitative value of profit/loss for a decision-state combination\nUsed to evaluate and compare decision alternatives\nBuilding a large complex yields $20 million if demand is high.\n\n\nResults\nActual effects observed after decision and state of nature occur\nEvaluate real-world effectiveness of decision\nMedium complex yields a realized profit of $14 million.\n\n\nOutputs\nImmediate, measurable consequences from the decision\nProvide operational metrics\nNumber of units built, time to completion, occupancy rate.\n\n\nOutcomes\nBroader end results, often aligned with goals/objectives\nAssess decision’s success in achieving goals\nProfit, market reputation, customer satisfaction, future demand"
  }
]