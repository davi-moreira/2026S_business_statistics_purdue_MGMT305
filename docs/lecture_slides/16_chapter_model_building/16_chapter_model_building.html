<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Professor Davi Moreira ">

<title> MGMT 30500: Business Statistics  – MGMT 30500: Business Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-79df7ed5347781c1339259261daa236f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><span style="font-size: 100%;"> MGMT 30500: Business Statistics </span></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      <img src="../../images/mgmt_305_ai_logo.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main">
    <a href="https://github.com/davi-moreira/2025S_business_statistics_purdue_MGMT305" title="GitHub" class="quarto-navigation-tool px-1" aria-label="GitHub"><i class="bi bi-github"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../syllabus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Syllabus</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../material.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Material</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../schedule.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedule</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#general-linear-model" id="toc-general-linear-model" class="nav-link" data-scroll-target="#general-linear-model">General Linear Model</a>
  <ul class="collapse">
  <li><a href="#general-linear-model-1" id="toc-general-linear-model-1" class="nav-link" data-scroll-target="#general-linear-model-1">General Linear Model</a></li>
  <li><a href="#general-linear-model-2" id="toc-general-linear-model-2" class="nav-link" data-scroll-target="#general-linear-model-2">General Linear Model</a></li>
  </ul></li>
  <li><a href="#modelling-curvilinear-relationships" id="toc-modelling-curvilinear-relationships" class="nav-link" data-scroll-target="#modelling-curvilinear-relationships">Modelling Curvilinear Relationships</a>
  <ul class="collapse">
  <li><a href="#modelling-curvilinear-relationships-1" id="toc-modelling-curvilinear-relationships-1" class="nav-link" data-scroll-target="#modelling-curvilinear-relationships-1">Modelling Curvilinear Relationships</a></li>
  <li><a href="#modelling-curvilinear-relationships-2" id="toc-modelling-curvilinear-relationships-2" class="nav-link" data-scroll-target="#modelling-curvilinear-relationships-2">Modelling Curvilinear Relationships</a></li>
  <li><a href="#modelling-curvilinear-relationships-3" id="toc-modelling-curvilinear-relationships-3" class="nav-link" data-scroll-target="#modelling-curvilinear-relationships-3">Modelling Curvilinear Relationships</a></li>
  <li><a href="#interpretation-of-independent-variable-effect-in-a-second-order-model" id="toc-interpretation-of-independent-variable-effect-in-a-second-order-model" class="nav-link" data-scroll-target="#interpretation-of-independent-variable-effect-in-a-second-order-model">Interpretation of Independent Variable Effect in a Second-Order Model</a></li>
  <li><a href="#marginal-effect-of-x_1" id="toc-marginal-effect-of-x_1" class="nav-link" data-scroll-target="#marginal-effect-of-x_1">Marginal Effect of <span class="math inline">\(x_1\)</span></a></li>
  <li><a href="#practical-interpretation" id="toc-practical-interpretation" class="nav-link" data-scroll-target="#practical-interpretation">Practical Interpretation</a></li>
  </ul></li>
  <li><a href="#interaction" id="toc-interaction" class="nav-link" data-scroll-target="#interaction">Interaction</a>
  <ul class="collapse">
  <li><a href="#interaction-1" id="toc-interaction-1" class="nav-link" data-scroll-target="#interaction-1">Interaction</a></li>
  <li><a href="#example-interaction" id="toc-example-interaction" class="nav-link" data-scroll-target="#example-interaction">Example: Interaction</a></li>
  <li><a href="#example-difference-in-mean-sales" id="toc-example-difference-in-mean-sales" class="nav-link" data-scroll-target="#example-difference-in-mean-sales">Example: Difference in Mean Sales</a></li>
  <li><a href="#example-regression-model-with-interaction" id="toc-example-regression-model-with-interaction" class="nav-link" data-scroll-target="#example-regression-model-with-interaction">Example: Regression Model with Interaction</a></li>
  <li><a href="#example-estimated-regression-equation" id="toc-example-estimated-regression-equation" class="nav-link" data-scroll-target="#example-estimated-regression-equation">Example: Estimated Regression Equation</a></li>
  <li><a href="#example-significance-of-interaction" id="toc-example-significance-of-interaction" class="nav-link" data-scroll-target="#example-significance-of-interaction">Example: Significance of Interaction</a></li>
  <li><a href="#example-interpretation-of-coefficients" id="toc-example-interpretation-of-coefficients" class="nav-link" data-scroll-target="#example-interpretation-of-coefficients">Example: Interpretation of Coefficients</a></li>
  <li><a href="#example-marginal-effects" id="toc-example-marginal-effects" class="nav-link" data-scroll-target="#example-marginal-effects">Example: Marginal Effects</a></li>
  <li><a href="#example-interpretation-of-interaction-effect" id="toc-example-interpretation-of-interaction-effect" class="nav-link" data-scroll-target="#example-interpretation-of-interaction-effect">Example: Interpretation of Interaction Effect</a></li>
  <li><a href="#example-coefficient-interpretation" id="toc-example-coefficient-interpretation" class="nav-link" data-scroll-target="#example-coefficient-interpretation">Example: Coefficient Interpretation</a></li>
  </ul></li>
  <li><a href="#log-transformation" id="toc-log-transformation" class="nav-link" data-scroll-target="#log-transformation">Log Transformation</a>
  <ul class="collapse">
  <li><a href="#original-data" id="toc-original-data" class="nav-link" data-scroll-target="#original-data">Original Data</a></li>
  <li><a href="#log-transformation-1" id="toc-log-transformation-1" class="nav-link" data-scroll-target="#log-transformation-1">Log Transformation</a></li>
  <li><a href="#possibile-logarithmic-transformations" id="toc-possibile-logarithmic-transformations" class="nav-link" data-scroll-target="#possibile-logarithmic-transformations">Possibile Logarithmic Transformations</a></li>
  <li><a href="#what-changes-after-the-transformation" id="toc-what-changes-after-the-transformation" class="nav-link" data-scroll-target="#what-changes-after-the-transformation">What Changes After the Transformation</a></li>
  <li><a href="#log-transformation-summary" id="toc-log-transformation-summary" class="nav-link" data-scroll-target="#log-transformation-summary">Log Transformation Summary</a></li>
  <li><a href="#example-log-transformation" id="toc-example-log-transformation" class="nav-link" data-scroll-target="#example-log-transformation">Example: Log Transformation</a></li>
  </ul></li>
  <li><a href="#nonlinear-models-that-are-intrinsically-linear" id="toc-nonlinear-models-that-are-intrinsically-linear" class="nav-link" data-scroll-target="#nonlinear-models-that-are-intrinsically-linear">Nonlinear Models That Are Intrinsically Linear</a>
  <ul class="collapse">
  <li><a href="#nonlinear-models-that-are-intrinsically-linear-1" id="toc-nonlinear-models-that-are-intrinsically-linear-1" class="nav-link" data-scroll-target="#nonlinear-models-that-are-intrinsically-linear-1">Nonlinear Models That Are Intrinsically Linear</a></li>
  <li><a href="#example-of-exponential-model" id="toc-example-of-exponential-model" class="nav-link" data-scroll-target="#example-of-exponential-model">Example of Exponential Model</a></li>
  <li><a href="#logarithmic-transformation-of-the-model" id="toc-logarithmic-transformation-of-the-model" class="nav-link" data-scroll-target="#logarithmic-transformation-of-the-model">Logarithmic Transformation of the Model</a></li>
  <li><a href="#linearized-model" id="toc-linearized-model" class="nav-link" data-scroll-target="#linearized-model">Linearized Model</a></li>
  <li><a href="#linearized-model---example-prediction" id="toc-linearized-model---example-prediction" class="nav-link" data-scroll-target="#linearized-model---example-prediction">Linearized Model - Example Prediction</a></li>
  </ul></li>
  <li><a href="#other-transformations-to-consider" id="toc-other-transformations-to-consider" class="nav-link" data-scroll-target="#other-transformations-to-consider">Other Transformations to Consider</a>
  <ul class="collapse">
  <li><a href="#other-transformations-to-consider-1" id="toc-other-transformations-to-consider-1" class="nav-link" data-scroll-target="#other-transformations-to-consider-1">Other Transformations to Consider</a></li>
  <li><a href="#square-root-transformation" id="toc-square-root-transformation" class="nav-link" data-scroll-target="#square-root-transformation">Square-Root Transformation</a></li>
  <li><a href="#logarithmic-transformation" id="toc-logarithmic-transformation" class="nav-link" data-scroll-target="#logarithmic-transformation">Logarithmic Transformation</a></li>
  <li><a href="#reciprocal-transformation" id="toc-reciprocal-transformation" class="nav-link" data-scroll-target="#reciprocal-transformation">Reciprocal Transformation</a></li>
  <li><a href="#exponential-transformation" id="toc-exponential-transformation" class="nav-link" data-scroll-target="#exponential-transformation">Exponential Transformation</a></li>
  <li><a href="#power-transformations" id="toc-power-transformations" class="nav-link" data-scroll-target="#power-transformations">Power Transformations</a></li>
  </ul></li>
  <li><a href="#when-to-add-or-delete-variables" id="toc-when-to-add-or-delete-variables" class="nav-link" data-scroll-target="#when-to-add-or-delete-variables">When to Add or Delete Variables</a>
  <ul class="collapse">
  <li><a href="#overview-of-predictor-evaluation" id="toc-overview-of-predictor-evaluation" class="nav-link" data-scroll-target="#overview-of-predictor-evaluation">Overview of Predictor Evaluation</a></li>
  <li><a href="#four-scenarios-for-predictors" id="toc-four-scenarios-for-predictors" class="nav-link" data-scroll-target="#four-scenarios-for-predictors">Four Scenarios for Predictors</a></li>
  <li><a href="#scenario-1-statistically-significant-and-effective" id="toc-scenario-1-statistically-significant-and-effective" class="nav-link" data-scroll-target="#scenario-1-statistically-significant-and-effective">Scenario 1: Statistically Significant and Effective</a></li>
  <li><a href="#scenario-2-statistically-significant-but-not-effective" id="toc-scenario-2-statistically-significant-but-not-effective" class="nav-link" data-scroll-target="#scenario-2-statistically-significant-but-not-effective">Scenario 2: Statistically Significant but Not Effective</a></li>
  <li><a href="#scenario-3-not-statistically-significant-but-effective" id="toc-scenario-3-not-statistically-significant-but-effective" class="nav-link" data-scroll-target="#scenario-3-not-statistically-significant-but-effective">Scenario 3: Not Statistically Significant but Effective</a></li>
  <li><a href="#scenario-4-not-statistically-significant-and-not-effective" id="toc-scenario-4-not-statistically-significant-and-not-effective" class="nav-link" data-scroll-target="#scenario-4-not-statistically-significant-and-not-effective">Scenario 4: Not Statistically Significant and Not Effective</a></li>
  </ul></li>
  <li><a href="#strategies-for-adding-or-removing-variables" id="toc-strategies-for-adding-or-removing-variables" class="nav-link" data-scroll-target="#strategies-for-adding-or-removing-variables">Strategies for Adding or Removing Variables</a>
  <ul class="collapse">
  <li><a href="#strategies-for-adding-or-removing-variables-1" id="toc-strategies-for-adding-or-removing-variables-1" class="nav-link" data-scroll-target="#strategies-for-adding-or-removing-variables-1">Strategies for Adding or Removing Variables</a></li>
  <li><a href="#adding-or-removing-variables" id="toc-adding-or-removing-variables" class="nav-link" data-scroll-target="#adding-or-removing-variables">Adding or Removing Variables</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test" id="toc-adding-variables-in-regression-models-f-test" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-1" id="toc-adding-variables-in-regression-models-f-test-1" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-1">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-2" id="toc-adding-variables-in-regression-models-f-test-2" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-2">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-3" id="toc-adding-variables-in-regression-models-f-test-3" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-3">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-4" id="toc-adding-variables-in-regression-models-f-test-4" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-4">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-5" id="toc-adding-variables-in-regression-models-f-test-5" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-5">Adding Variables in Regression Models: F-test</a></li>
  <li><a href="#adding-variables-in-regression-models-f-test-6" id="toc-adding-variables-in-regression-models-f-test-6" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-f-test-6">Adding Variables in Regression Models: F-test</a></li>
  </ul></li>
  <li><a href="#stepwise-regression" id="toc-stepwise-regression" class="nav-link" data-scroll-target="#stepwise-regression">Stepwise Regression</a>
  <ul class="collapse">
  <li><a href="#stepwise-regression-overview" id="toc-stepwise-regression-overview" class="nav-link" data-scroll-target="#stepwise-regression-overview">Stepwise Regression: Overview</a></li>
  <li><a href="#stepwise-regression-how-it-works" id="toc-stepwise-regression-how-it-works" class="nav-link" data-scroll-target="#stepwise-regression-how-it-works">Stepwise Regression: How It Works</a></li>
  <li><a href="#considerations-and-limitations" id="toc-considerations-and-limitations" class="nav-link" data-scroll-target="#considerations-and-limitations">Considerations and Limitations</a></li>
  <li><a href="#stepwise-regression-example" id="toc-stepwise-regression-example" class="nav-link" data-scroll-target="#stepwise-regression-example">Stepwise Regression Example</a></li>
  <li><a href="#stepwise-regression-example-starting-point" id="toc-stepwise-regression-example-starting-point" class="nav-link" data-scroll-target="#stepwise-regression-example-starting-point">Stepwise Regression Example: Starting Point</a></li>
  <li><a href="#stepwise-regression-example-checking-for-removal" id="toc-stepwise-regression-example-checking-for-removal" class="nav-link" data-scroll-target="#stepwise-regression-example-checking-for-removal">Stepwise Regression Example: Checking for Removal</a></li>
  <li><a href="#stepwise-regression-example-considering-remaining-predictors" id="toc-stepwise-regression-example-considering-remaining-predictors" class="nav-link" data-scroll-target="#stepwise-regression-example-considering-remaining-predictors">Stepwise Regression Example: Considering Remaining Predictors</a></li>
  <li><a href="#stepwise-regression-example-final-model" id="toc-stepwise-regression-example-final-model" class="nav-link" data-scroll-target="#stepwise-regression-example-final-model">Stepwise Regression Example: Final Model</a></li>
  <li><a href="#summary-of-the-stepwise-procedure" id="toc-summary-of-the-stepwise-procedure" class="nav-link" data-scroll-target="#summary-of-the-stepwise-procedure">Summary of the Stepwise Procedure</a></li>
  </ul></li>
  <li><a href="#forward-selection" id="toc-forward-selection" class="nav-link" data-scroll-target="#forward-selection">Forward Selection</a>
  <ul class="collapse">
  <li><a href="#forward-selection-overview" id="toc-forward-selection-overview" class="nav-link" data-scroll-target="#forward-selection-overview">Forward Selection: Overview</a></li>
  <li><a href="#forward-selection-procedure" id="toc-forward-selection-procedure" class="nav-link" data-scroll-target="#forward-selection-procedure">Forward Selection: Procedure</a></li>
  <li><a href="#forward-selection-limitations" id="toc-forward-selection-limitations" class="nav-link" data-scroll-target="#forward-selection-limitations">Forward Selection Limitations</a></li>
  </ul></li>
  <li><a href="#backward-elimination" id="toc-backward-elimination" class="nav-link" data-scroll-target="#backward-elimination">Backward Elimination</a>
  <ul class="collapse">
  <li><a href="#backward-elimination-overview" id="toc-backward-elimination-overview" class="nav-link" data-scroll-target="#backward-elimination-overview">Backward Elimination: Overview</a></li>
  <li><a href="#backward-elimination-procedure" id="toc-backward-elimination-procedure" class="nav-link" data-scroll-target="#backward-elimination-procedure">Backward Elimination: Procedure</a></li>
  <li><a href="#backward-elimination-limitations" id="toc-backward-elimination-limitations" class="nav-link" data-scroll-target="#backward-elimination-limitations">Backward Elimination Limitations</a></li>
  </ul></li>
  <li><a href="#best-subsets-regression" id="toc-best-subsets-regression" class="nav-link" data-scroll-target="#best-subsets-regression">Best-Subsets Regression</a>
  <ul class="collapse">
  <li><a href="#best-subsets-regression-1" id="toc-best-subsets-regression-1" class="nav-link" data-scroll-target="#best-subsets-regression-1">Best-Subsets Regression</a></li>
  </ul></li>
  <li><a href="#adding-variables-in-regression-models-notes" id="toc-adding-variables-in-regression-models-notes" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-notes">Adding Variables in Regression Models: Notes</a>
  <ul class="collapse">
  <li><a href="#adding-variables-in-regression-models-notes-1" id="toc-adding-variables-in-regression-models-notes-1" class="nav-link" data-scroll-target="#adding-variables-in-regression-models-notes-1">Adding Variables in Regression Models: Notes</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul></li>
  <li><a href="#thank-you" id="toc-thank-you" class="nav-link" data-scroll-target="#thank-you">Thank you!</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="16_chapter_model_building.html"><i class="bi bi-file-slides"></i>RevealJS</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span style="font-size: 100%;"> MGMT 30500: Business Statistics </span></h1>
<p class="subtitle lead"><span style="font-size: 150%;"> Regression Analysis: Model Building</span></p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Professor<br>Davi Moreira<br> </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<div class="nonincremental">
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li>General Linear Model</li>
<li>Modeling Curvilinear Relationships</li>
<li>Interaction</li>
<li>Transformations</li>
<li>Nonlinear Models That Are Intrinsically Linear</li>
</ul>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li><p>Determining When to Add or Delete Variables<br>
</p></li>
<li><p>Variable Selection Procedures</p>
<ul>
<li>Stepwise Method</li>
<li>Forward Method</li>
<li>Backward Method</li>
<li>Best Subsets Method</li>
</ul></li>
</ul>
</div>
</div>
</div>
</section>
<section id="general-linear-model" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">General Linear Model</h1>
<section id="general-linear-model-1" class="level2">
<h2 class="anchored" data-anchor-id="general-linear-model-1">General Linear Model</h2>
<ul>
<li><p>Models in which the parameters <span class="math inline">\((\beta_0, \beta_1, \ldots, \beta_p)\)</span> all have exponents of one are called <strong>linear models</strong>.</p></li>
<li><p>A <strong>general linear model</strong> involving <span class="math inline">\(p\)</span> independent variables (<span class="math inline">\(z_i\)</span>’s) is:</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 z_1 + \beta_2 z_2 + \ldots + \beta_p z_p + \epsilon
\]</span></p>
<p>where each independent variable <span class="math inline">\(z_i\)</span> is a (linear or nonlinear) function of <span class="math inline">\(x_1, x_2, \ldots, x_k\)</span> (the variables for which data have been collected).</p>
<ul>
<li>Here, <span class="math inline">\(y\)</span> can be a function of the original response variable as well.</li>
</ul>
</div>
</section>
<section id="general-linear-model-2" class="level2">
<h2 class="anchored" data-anchor-id="general-linear-model-2">General Linear Model</h2>
<ul>
<li><p>The simplest case is when we have collected data for just one variable <span class="math inline">\(x_1\)</span> and want to estimate <span class="math inline">\(y\)</span> by using a straight-line relationship. In this case <span class="math inline">\(z_1 = x_1\)</span>.</p></li>
<li><p>This model is called a <strong>simple first-order model</strong> with one predictor variable.</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \epsilon
\]</span></p>
</div>
</section>
</section>
<section id="modelling-curvilinear-relationships" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Modelling Curvilinear Relationships</h1>
<section id="modelling-curvilinear-relationships-1" class="level2">
<h2 class="anchored" data-anchor-id="modelling-curvilinear-relationships-1">Modelling Curvilinear Relationships</h2>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="16_chapter_model_building_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="modelling-curvilinear-relationships-2" class="level2">
<h2 class="anchored" data-anchor-id="modelling-curvilinear-relationships-2">Modelling Curvilinear Relationships</h2>
<ul>
<li><p>Some non-linear models can be expressed as a general linear model.</p></li>
<li><p>To account for a curvilinear relationship, we might consider a <strong>second-order model with one predictor variable</strong> <span class="math inline">\((x_1)\)</span>:</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon
\]</span></p>
<ul>
<li>It is a linear model because we can set: <span class="math inline">\(z_1 = x_1\)</span> and <span class="math inline">\(z_2 = x_1^2\)</span>.</li>
</ul>
</div>
</section>
<section id="modelling-curvilinear-relationships-3" class="level2">
<h2 class="anchored" data-anchor-id="modelling-curvilinear-relationships-3">Modelling Curvilinear Relationships</h2>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="16_chapter_model_building_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \epsilon
\]</span></p>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div style="font-size: 70%;">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon
\]</span></p>
</div>
</div>
</div>
</section>
<section id="interpretation-of-independent-variable-effect-in-a-second-order-model" class="level2">
<h2 class="anchored" data-anchor-id="interpretation-of-independent-variable-effect-in-a-second-order-model">Interpretation of Independent Variable Effect in a Second-Order Model</h2>
<ul>
<li><p><span class="math inline">\(\beta_1\)</span>: Represents the linear effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span>. It gives the initial (or marginal) change in <span class="math inline">\(y\)</span> for a one-unit increase in <span class="math inline">\(x_1\)</span> when <span class="math inline">\(x_1^2\)</span> is held constant.</p></li>
<li><p><span class="math inline">\(\beta_2\)</span>: Represents the quadratic effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span>. It determines whether the curve opens upwards <span class="math inline">\((\beta_2 &gt; 0)\)</span> or downwards <span class="math inline">\((\beta_2 &lt; 0)\)</span>.</p></li>
</ul>
</section>
<section id="marginal-effect-of-x_1" class="level2">
<h2 class="anchored" data-anchor-id="marginal-effect-of-x_1">Marginal Effect of <span class="math inline">\(x_1\)</span></h2>
<ul>
<li>The overall effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> can be expressed as:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
\frac{dy}{dx_1} = \beta_1 + 2\beta_2 x_1
\]</span></p>
<ul>
<li><p>This shows that the effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> changes as <span class="math inline">\(x_1\)</span> increases or decreases due to the presence of the quadratic term <span class="math inline">\(x_1^2\)</span>.</p></li>
<li><p>Instead of a constant change (as in linear models), the presence of <span class="math inline">\(2\beta_2 x_1\)</span> shows a varying slope depending on the value of <span class="math inline">\(x_1\)</span>.</p></li>
</ul>
</div>
</section>
<section id="practical-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="practical-interpretation">Practical Interpretation</h2>
<ul>
<li><p>If <span class="math inline">\(\beta_2 &gt; 0\)</span>, <span class="math inline">\(y\)</span> increases at an increasing rate as <span class="math inline">\(x_1\)</span> increases, resulting in a U-shaped curve.</p></li>
<li><p>If <span class="math inline">\(\beta_2 &lt; 0\)</span>, <span class="math inline">\(y\)</span> increases at a decreasing rate and then decreases, resulting in an inverted U-shaped curve.</p></li>
<li><p>The effect of <span class="math inline">\(x_1\)</span> should always be considered in light of both <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>.</p></li>
</ul>
</section>
</section>
<section id="interaction" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Interaction</h1>
<section id="interaction-1" class="level2">
<h2 class="anchored" data-anchor-id="interaction-1">Interaction</h2>
<ul>
<li>If the original data set consists of observations for <span class="math inline">\(y\)</span> and two independent variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, we might develop a <strong>second-order model with two predictor variables</strong> <span class="math inline">\((x_1\)</span> and <span class="math inline">\(x_2)\)</span> with interaction:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon
\]</span></p>
<ul>
<li><p>The variable <span class="math inline">\(x_1 x_2\)</span> is added to account for the potential effects of the two variables acting together.</p></li>
<li><p><span class="math inline">\(\beta_3\)</span> measures the <strong>interaction effect</strong>.</p></li>
</ul>
</div>
</section>
<section id="example-interaction" class="level2">
<h2 class="anchored" data-anchor-id="example-interaction">Example: Interaction</h2>
<div class="nonincremental">
<p>Lets check the regression study conducted by Tyler Personal Care for one of its new shampoo products. Two factors believed to have the most influence on sales are:</p>
<ul>
<li><p>Unit selling price</p></li>
<li><p>Advertising expenditure</p></li>
</ul>
<p>To investigate the effects of these two variables on sales, prices of $2.00, $2.50, and $3.00 were paired with advertising expenditures of $50,000 and $100,000 in 24 test markets.</p>
</div>
</section>
<section id="example-difference-in-mean-sales" class="level2">
<h2 class="anchored" data-anchor-id="example-difference-in-mean-sales">Example: Difference in Mean Sales</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<p><strong>Mean Sales (1000s) for the Tyler Personal Care Example</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Advertising Expenditure</strong></th>
<th><strong>$2.00</strong></th>
<th><strong>$2.50</strong></th>
<th><strong>$3.00</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>$50,000</strong></td>
<td>461</td>
<td>364</td>
<td>332</td>
</tr>
<tr class="even">
<td><strong>$100,000</strong></td>
<td>808</td>
<td>646</td>
<td>375</td>
</tr>
</tbody>
</table>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div style="font-size: 70%;">
<ul>
<li><p>With a price of $2.00, the difference in mean sales between advertising expenditures of $50,000 and $100,000 is:</p>
<p><span class="math display">\[
808,000 - 461,000 = 347,000 \, units
\]</span></p></li>
<li><p>When the price is $2.50, the difference is:</p>
<p><span class="math display">\[
646,000 - 364,000 = 282,000 \, units
\]</span></p></li>
<li><p>When the price is $3.00, the difference is:</p>
<p><span class="math display">\[
375,000 - 332,000 = 43,000 \, units
\]</span></p></li>
</ul>
<div class="fragment">
<p>Clearly, the difference in mean sales between advertising expenditures depends on the price of the product. The effect of increased advertising expenditure diminishes at higher selling prices, providing evidence of interaction between the price and advertising expenditure variables.</p>
</div>
</div>
</div>
</div>
</section>
<section id="example-regression-model-with-interaction" class="level2">
<h2 class="anchored" data-anchor-id="example-regression-model-with-interaction">Example: Regression Model with Interaction</h2>
<p><br></p>
<p>To account for the effect of interaction, we use the following regression model:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon
\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(y\)</span> = unit sales (1000s)</li>
<li><span class="math inline">\(x_1\)</span> = price ($)</li>
<li><span class="math inline">\(x_2\)</span> = advertising expenditure ($1000s)</li>
</ul>
</section>
<section id="example-estimated-regression-equation" class="level2">
<h2 class="anchored" data-anchor-id="example-estimated-regression-equation">Example: Estimated Regression Equation</h2>
<p>Using the estimated regression equation:</p>
<p><span class="math display">\[
\text{Sales} = -275.8333 + 175 \, \text{Price} + 19.68 \, \text{AdvExp} - 6.08 \, \text{PriceAdv}
\]</span></p>
<p>Where:</p>
<ul>
<li><strong>Sales</strong> = unit sales (1000s)</li>
<li><strong>Price</strong> = price of the product ($)</li>
<li><strong>AdvExp</strong> = advertising expenditure ($1000s)</li>
<li><strong>PriceAdv</strong> = interaction term (Price times AdvExp)</li>
</ul>
</section>
<section id="example-significance-of-interaction" class="level2">
<h2 class="anchored" data-anchor-id="example-significance-of-interaction">Example: Significance of Interaction</h2>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/interaction_reg_output.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p>The <span class="math inline">\(p\)</span>-value corresponding to the <span class="math inline">\(t\)</span>-test for <code>PriceAdv</code> is 0.0000, which indicates significant interaction between the price of the product and the advertising expenditure.</p>
<p><br></p>
</section>
<section id="example-interpretation-of-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="example-interpretation-of-coefficients">Example: Interpretation of Coefficients</h2>
<p><br></p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span>: Intercept. Represents the expected value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are zero.</p></li>
<li><p><span class="math inline">\(\beta_1\)</span>: Effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> when <span class="math inline">\(x_2 = 0\)</span>.</p></li>
<li><p><span class="math inline">\(\beta_2\)</span>: Effect of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(y\)</span> when <span class="math inline">\(x_1 = 0\)</span>.</p></li>
<li><p><span class="math inline">\(\beta_3\)</span>: Interaction effect between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Indicates how the relationship between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(y\)</span> changes with different values of <span class="math inline">\(x_2\)</span>, and vice-versa.</p></li>
</ul>
</section>
<section id="example-marginal-effects" class="level2">
<h2 class="anchored" data-anchor-id="example-marginal-effects">Example: Marginal Effects</h2>
<ul>
<li><strong>Effect of</strong> <span class="math inline">\(x_1\)</span>:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
\frac{\partial y}{\partial x_1} = \beta_1 + \beta_3 x_2
\]</span></p>
<ul>
<li><strong>Effect of</strong> <span class="math inline">\(x_2\)</span>:</li>
</ul>
</div>
<div class="fragment">
<p><span class="math display">\[
\frac{\partial y}{\partial x_2} = \beta_2 + \beta_3 x_1
\]</span></p>
</div>
<ul>
<li>The effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> depends on <span class="math inline">\(x_2\)</span>, and the effect of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(y\)</span> depends on <span class="math inline">\(x_1\)</span>.</li>
</ul>
</section>
<section id="example-interpretation-of-interaction-effect" class="level2">
<h2 class="anchored" data-anchor-id="example-interpretation-of-interaction-effect">Example: Interpretation of Interaction Effect</h2>
<p><br></p>
<ul>
<li><p>If <span class="math inline">\(\beta_3 &gt; 0\)</span>, a positive (or negative) effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> increases as <span class="math inline">\(x_2\)</span> increases.</p></li>
<li><p>If <span class="math inline">\(\beta_3 &lt; 0\)</span>, a positive (or negative) effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> decreases as <span class="math inline">\(x_2\)</span> increases.</p></li>
</ul>
</section>
<section id="example-coefficient-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="example-coefficient-interpretation">Example: Coefficient Interpretation</h2>
<div style="font-size: 80%;">
<ul>
<li><p><strong>Price</strong>: <span class="math inline">\(175\)</span> - When AdvExp is zero, a one-unit increase in Price leads to an expected increase of 175 units in <span class="math inline">\(y\)</span>.</p></li>
<li><p><strong>AdvExp</strong>: <span class="math inline">\(19.68\)</span> - When Price is zero, a one-unit increase in AdvExp results in an expected increase of 19.68 units in <span class="math inline">\(y\)</span>.</p></li>
<li><p><strong>PriceAdv</strong>: <span class="math inline">\(-6.08\)</span>- Interaction effect: A one-unit increase in AdvExp decreases the effect of Price on <span class="math inline">\(y\)</span> by 6.08 units (and vice versa).</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation of Interaction Effect</strong></p>
<p><br></p>
<ul>
<li><p>The interaction term <span class="math inline">\(\beta_3\)</span> (PriceAdv) is negative.</p>
<ul>
<li>As AdvExp increases, the positive effect of Price on <span class="math inline">\(y\)</span> decreases.</li>
<li>Suggests diminishing returns on Price when AdvExp is already high (or vice versa).</li>
</ul></li>
<li><p>An increase in Advertising Expenditures may lead to higher sales, but this effect diminishes as more the Price increases.</p></li>
<li><p>The interaction effect is negative and significant, showing that the combined effect of Price and AdvExp on <span class="math inline">\(y\)</span> is not purely additive.</p></li>
<li><p><strong>Takeaway</strong>: Adjustments to Price or AdvExp should consider their interaction, as increasing both may not yield linear increases in <span class="math inline">\(y.\)</span></p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="log-transformation" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Log Transformation</h1>
<section id="original-data" class="level2">
<h2 class="anchored" data-anchor-id="original-data">Original Data</h2>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="16_chapter_model_building_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="480"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="log-transformation-1" class="level2">
<h2 class="anchored" data-anchor-id="log-transformation-1">Log Transformation</h2>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="16_chapter_model_building_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="possibile-logarithmic-transformations" class="level2">
<h2 class="anchored" data-anchor-id="possibile-logarithmic-transformations">Possibile Logarithmic Transformations</h2>
<p><br></p>
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 34%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>X</strong></th>
<th style="text-align: center;"><strong>logX</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><br><strong>Y</strong><br></td>
<td style="text-align: center;"><br><strong>linear</strong><br><span class="math inline">\(\hat{Y}_i = \alpha + \beta X_i\)</span><br></td>
<td style="text-align: center;"><br><strong>linear-log</strong><br><span class="math inline">\(\hat{Y}_i = \alpha + \beta \log X_i\)</span><br></td>
</tr>
<tr class="even">
<td style="text-align: center;"><br><strong>logY</strong><br></td>
<td style="text-align: center;"><br><strong>log-linear</strong><br><span class="math inline">\(\log \hat{Y}_i = \alpha + \beta X_i\)</span><br></td>
<td style="text-align: center;"><br><strong>log-log</strong><br><span class="math inline">\(\log \hat{Y}_i = \alpha + \beta \log X_i\)</span><br></td>
</tr>
</tbody>
</table>
<p><br></p>
<p><br></p>
<div style="font-size: 60%;">
<p>Source: <a href="https://kenbenoit.net/assets/courses/ME104/logmodels2.pdf">Linear Regression Models with Logarithmic Transformations</a></p>
</div>
</section>
<section id="what-changes-after-the-transformation" class="level2">
<h2 class="anchored" data-anchor-id="what-changes-after-the-transformation">What Changes After the Transformation</h2>
<p><br></p>
<ul>
<li><p>You should be cautious when interpreting and reporting the findings of the model.</p></li>
<li><p>The interpretation varies based on the variable that was transformed (dependent variable, independent variable, or both).</p></li>
<li><p>As a general rule, you should always keep in mind the logic:</p></li>
</ul>
<div class="fragment">
<blockquote class="blockquote">
<p><em>“What does a one-unit change in this transformed variable mean in terms of the original variable?”</em></p>
</blockquote>
<center>
<a href="https://theeffectbook.net/ch-StatisticalAdjustment.html#getting-fancier-with-regression">The Effect Book</a>
</center>
</div>
</section>
<section id="log-transformation-summary" class="level2">
<h2 class="anchored" data-anchor-id="log-transformation-summary">Log Transformation Summary</h2>
<p><br></p>
<div style="font-size: 80%;">
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Model Equation</strong></th>
<th><strong>Interpretation of</strong> <span class="math inline">\(\beta_1\)</span></th>
<th><strong>Interpretation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Level-level</strong></td>
<td><span class="math inline">\(y = \beta_0 + \beta_1 x + \epsilon\)</span></td>
<td><span class="math inline">\(\Delta y = \beta_1 \Delta x\)</span></td>
<td>A one-unit change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\)</span> unit change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Level-log</strong></td>
<td><span class="math inline">\(y = \beta_0 + \beta_1 \log(x) + \epsilon\)</span></td>
<td><span class="math inline">\(\Delta y = (\beta_1 / 100) \% \Delta x\)</span></td>
<td>A 1% change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1/100\)</span> unit change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Log-level</strong></td>
<td><span class="math inline">\(\log(y) = \beta_0 + \beta_1 x + \epsilon\)</span></td>
<td><span class="math inline">\(\%\Delta y = (100\beta_1) \Delta x\)</span></td>
<td>A one-unit change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top table">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Log-log</strong></td>
<td><span class="math inline">\(\log(y) = \beta_0 + \beta_1 \log(x) + \epsilon\)</span></td>
<td><span class="math inline">\(\%\Delta y = \beta_1 \% \Delta x\)</span></td>
<td>A 1% change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</section>
<section id="example-log-transformation" class="level2">
<h2 class="anchored" data-anchor-id="example-log-transformation">Example: Log Transformation</h2>
<div style="font-size: 70%;">
<p>Predict Miles-Per-Gallon (MPG) according to the automobile Weight (in pounds):</p>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="fragment">
<p><span class="math display">\[
\text{MPG} = 56.0957 - 0.0116 \times \text{Weight}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/level_level_example.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>The pattern does not look like the the horizontal band we should expect to find if the assumptions about the error term are valid.</p></li>
<li><p>Variability in the residuals appears to increase as the value of <span class="math inline">\(\hat{y}\)</span> increases.</p></li>
</ul>
</div>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="fragment">
<p><span class="math display">\[
\text{LnMPG} = 4.5242 - 0.0005 \times \text{Weight}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/log_level_example.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li><p>The wedge-shaped pattern disappeared.</p></li>
<li><p>The model with the logarithm of miles per gallon as the dependent variable provides an excellent fit to the oberved data.</p></li>
</ul>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="nonlinear-models-that-are-intrinsically-linear" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Nonlinear Models That Are Intrinsically Linear</h1>
<section id="nonlinear-models-that-are-intrinsically-linear-1" class="level2">
<h2 class="anchored" data-anchor-id="nonlinear-models-that-are-intrinsically-linear-1">Nonlinear Models That Are Intrinsically Linear</h2>
<p><br></p>
<p>Models in which the parameters <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span> have exponents other than one are called nonlinear models.</p>
<p>For the case of the <strong>exponential model</strong>, we can perform a transformation of variables that will enable us to perform regression analysis using the general linear model.</p>
<p>The exponential model involves the following regression equation:</p>
<p><span class="math display">\[
E(y) = \beta_0 \beta_1^x
\]</span></p>
<p>This model is appropriate when the dependent variable <span class="math inline">\(y\)</span> increases or decreases by a constant percentage, instead of by a fixed amount, as <span class="math inline">\(x\)</span> increases.</p>
</section>
<section id="example-of-exponential-model" class="level2">
<h2 class="anchored" data-anchor-id="example-of-exponential-model">Example of Exponential Model</h2>
<div class="nonincremental">
<p>Suppose sales for a product <span class="math inline">\(y\)</span> are related to advertising expenditure <span class="math inline">\(x\)</span> (in $1000s) according to the following regression equation:</p>
<p><span class="math display">\[
E(y) = 500(1.2)^x
\]</span> Thus,</p>
<ul>
<li>for <span class="math inline">\(x = 1\)</span>, <span class="math inline">\(E(y) = 500(1.2)^1 = 600\)</span></li>
<li>for <span class="math inline">\(x = 2\)</span>, <span class="math inline">\(E(y) = 500(1.2)^2 = 720\)</span></li>
<li>for <span class="math inline">\(x = 3\)</span>, <span class="math inline">\(E(y) = 500(1.2)^3 = 864\)</span></li>
</ul>
<p>Note that <span class="math inline">\(E(y)\)</span> is not increasing by a constant amount in this case, but by a constant percentage. The percentage increase is 20%.</p>
</div>
</section>
<section id="logarithmic-transformation-of-the-model" class="level2">
<h2 class="anchored" data-anchor-id="logarithmic-transformation-of-the-model">Logarithmic Transformation of the Model</h2>
<p><br></p>
<p>We can transform this nonlinear model to a linear model by taking the natural logarithm of both sides of the equation:</p>
<p><span class="math display">\[
\ln E(y) = \ln \beta_0 + x \ln \beta_1
\]</span></p>
</section>
<section id="linearized-model" class="level2">
<h2 class="anchored" data-anchor-id="linearized-model">Linearized Model</h2>
<p><br></p>
<p>Now, if we let <span class="math inline">\(y' = \ln E(y)\)</span>, <span class="math inline">\(\beta'_0 = \ln \beta_0\)</span>, and <span class="math inline">\(\beta'_1 = \ln \beta_1\)</span>, we can rewrite the equation as:</p>
<p><span class="math display">\[
y' = \beta'_0 + \beta'_1 x
\]</span></p>
<p>The formulas for simple linear regression can now be used to develop estimates of <span class="math inline">\(\beta'_0\)</span> and <span class="math inline">\(\beta'_1\)</span>. Denoting the estimates as <span class="math inline">\(b'_0\)</span> and <span class="math inline">\(b'_1\)</span>, leads to the following estimated regression equation:</p>
<p><span class="math display">\[
\hat{y'} = b'_0 + b'_1 x
\]</span></p>
<p>To obtain predictions of the original dependent variable <span class="math inline">\(y\)</span> given a value of <span class="math inline">\(x\)</span>, we would first substitute the value of <span class="math inline">\(x\)</span> into the equation above to compute <span class="math inline">\(\hat{y'}\)</span>, and then raise <span class="math inline">\(e\)</span> to the power of <span class="math inline">\(\hat{y'}\)</span> to obtain the prediction of <span class="math inline">\(y\)</span>, or the expected value of <span class="math inline">\(y\)</span>, in its original units.</p>
</section>
<section id="linearized-model---example-prediction" class="level2">
<h2 class="anchored" data-anchor-id="linearized-model---example-prediction">Linearized Model - Example Prediction</h2>
<div class="nonincremental">
<p>Given the estimates:</p>
<ul>
<li><p><span class="math inline">\(b'_0 = 3.5\)</span></p></li>
<li><p><span class="math inline">\(b'_1 = 0.2\)</span></p></li>
</ul>
<p>Let’s predict <span class="math inline">\(y\)</span> when the advertising expenditure <span class="math inline">\(x = 5\)</span> (in $1000s).</p>
<p>Using the linearized equation we calculate <span class="math inline">\(y'\)</span>:</p>
<p><span class="math display">\[
y' = b'_0 + b'_1 \cdot x = 3.5 + 0.2 \cdot 5 = 4.5
\]</span></p>
<p>Now, exponentiate <span class="math inline">\(y'\)</span> to get the predicted <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
y = e^{4.5} \approx 90.02
\]</span></p>
<p>Thus, the predicted sales <span class="math inline">\(y\)</span> when the advertising expenditure is 5 (in $1000s) is approximately 90 units (in $1000s).</p>
</div>
</section>
</section>
<section id="other-transformations-to-consider" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Other Transformations to Consider</h1>
<section id="other-transformations-to-consider-1" class="level2">
<h2 class="anchored" data-anchor-id="other-transformations-to-consider-1">Other Transformations to Consider</h2>
<p><br></p>
<ul>
<li><strong>Square-root</strong>: <span class="math inline">\(\sqrt{x}\)</span><br>
</li>
<li><strong>Logarithmic</strong>: <span class="math inline">\(\log_{10}(x), \log_{10}(y), \ln(x)\)</span>, etc.<br>
</li>
<li><strong>Reciprocal</strong>: <span class="math inline">\(1/y, 1/x\)</span><br>
</li>
<li><strong>Exponential</strong>: <span class="math inline">\(e^x, e^y\)</span><br>
</li>
<li><strong>Square</strong>: <span class="math inline">\(x^2, y^2\)</span><br>
</li>
<li><strong>Power</strong>: <span class="math inline">\(x^k, y^k\)</span></li>
</ul>
</section>
<section id="square-root-transformation" class="level2">
<h2 class="anchored" data-anchor-id="square-root-transformation">Square-Root Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(\sqrt{x}\)</span> term or <span class="math inline">\((x^{0.5})\)</span></p>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/transformation_sqrt.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="logarithmic-transformation" class="level2">
<h2 class="anchored" data-anchor-id="logarithmic-transformation">Logarithmic Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(\ln(x) \text{ or } \log(x)\)</span> term.</p>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/transformation_log.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="reciprocal-transformation" class="level2">
<h2 class="anchored" data-anchor-id="reciprocal-transformation">Reciprocal Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(1/x\)</span> term.</p>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/transformation_reciprocal.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="exponential-transformation" class="level2">
<h2 class="anchored" data-anchor-id="exponential-transformation">Exponential Transformation</h2>
<p><br></p>
<p>Change <span class="math inline">\(y\)</span> to <span class="math inline">\(\ln(y)\)</span> as the new response variable.</p>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/transformation_exponential.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
<section id="power-transformations" class="level2">
<h2 class="anchored" data-anchor-id="power-transformations">Power Transformations</h2>
<p><br></p>
<p>Add <span class="math inline">\(x^2\)</span> or <span class="math inline">\(x^k\)</span> term.</p>
<p><br></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="figs/transformation_power.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<p><br></p>
</section>
</section>
<section id="when-to-add-or-delete-variables" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">When to Add or Delete Variables</h1>
<section id="overview-of-predictor-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="overview-of-predictor-evaluation">Overview of Predictor Evaluation</h2>
<ul>
<li><p><strong>Statistical Significance</strong>: Indicates whether the relationship between a predictor and the dependent variable is unlikely to have occurred by chance.</p></li>
<li><p><strong>Effectiveness</strong>: Reflects the practical impact or importance of the predictor on the dependent variable.</p>
<ul>
<li>Assessed by observing changes in <strong>adjusted R-squared</strong> when the predictor is included.</li>
<li>Statistical significance is evaluated using the <strong>p-value</strong>.</li>
</ul></li>
</ul>
</section>
<section id="four-scenarios-for-predictors" class="level2">
<h2 class="anchored" data-anchor-id="four-scenarios-for-predictors">Four Scenarios for Predictors</h2>
<div style="font-size: 70%;">
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 36%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Statistically Significant</strong><br>(e.g.&nbsp;p-value &lt; 0.05)</th>
<th style="text-align: center;"><strong>Not Statistically Significant</strong><br>(e.g.&nbsp;p-value ≥ 0.05)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Effective</strong> (Adjusted R-squared increases significantly)</td>
<td style="text-align: center;">Scenario 1<br>Predictor is both statistically significant and effective.</td>
<td style="text-align: center;">Scenario 3<br>Effective but not statistically significant.</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Not Effective</strong> (Adjusted R-squared does not increase significantly)</td>
<td style="text-align: center;">Scenario 2<br>Statistically significant but not effective.</td>
<td style="text-align: center;">Scenario 4<br>Not statistically significant nor effective.</td>
</tr>
</tbody>
</table>
<ul>
<li><p><strong>Definition</strong>: A predictor is an <strong>ineffective predictor</strong> if its <span class="math inline">\(|T-Value| = \left| \frac{b - 0}{se(b)} \right| &lt; 1\)</span>. If that is the case, the coefficient estimate <span class="math inline">\(b\)</span> is within one standard deviation from 0, i.e., too close to 0, or its two-sided <span class="math inline">\(p-value &gt; 0.32\)</span> (Empirical rule).</p>
<ul>
<li><p><strong>Adding</strong> an effective predictor will decrease the estimated error variance <span class="math inline">\(S^2\)</span> and hence increase Adj <span class="math inline">\(R^2\)</span>. The opposite is true when adding an ineffective predictor.</p></li>
<li><p><strong>Removing</strong> an effective predictor will increase the estimated error variance <span class="math inline">\(S^2\)</span> and hence decrease Adj <span class="math inline">\(R^2\)</span>. The opposite is true when removing an ineffective predictor.</p></li>
</ul></li>
</ul>
</div>
</section>
<section id="scenario-1-statistically-significant-and-effective" class="level2">
<h2 class="anchored" data-anchor-id="scenario-1-statistically-significant-and-effective">Scenario 1: Statistically Significant and Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>p-value</strong> below chosen significance level (e.g., <span class="math inline">\(p &lt; 0.05\)</span>)</p></li>
<li><p><strong>Adjusted R-squared</strong> increases meaningfully when the predictor is included</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li><p>Predictor reliably contributes to the dependent variable’s variance.</p></li>
<li><p>Both statistically and practically meaningful.</p></li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li><p><strong>Healthcare</strong>: Adding “age” as a predictor in a model for blood pressure yields a <strong>p-value of</strong> <span class="math inline">\(p &lt; 0.001\)</span> and increases the adjusted R-squared from 0.30 to <strong>0.45</strong>.</p></li>
<li><p>Age is both a statistically significant and effective predictor of blood pressure.</p></li>
</ul>
</div>
</section>
<section id="scenario-2-statistically-significant-but-not-effective" class="level2">
<h2 class="anchored" data-anchor-id="scenario-2-statistically-significant-but-not-effective">Scenario 2: Statistically Significant but Not Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li><p><strong>p-value</strong> below the significance threshold</p></li>
<li><p><strong>Minimal change in adjusted R-squared</strong>: negligible improvement in the model’s explanatory power</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li>Statistically reliable but lacks practical impact.</li>
<li>Common in large samples where even small effects become significant.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li><strong>Economics</strong>: Adding “hair color” as a predictor of income yields <strong>p = 0.02</strong>, but increases adjusted R-squared from 0.25 to <strong>0.251</strong>.</li>
<li>Hair color is statistically significant but not practically effective.</li>
</ul>
</div>
</section>
<section id="scenario-3-not-statistically-significant-but-effective" class="level2">
<h2 class="anchored" data-anchor-id="scenario-3-not-statistically-significant-but-effective">Scenario 3: Not Statistically Significant but Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li><strong>p-value</strong> exceeds the significance level (e.g., <span class="math inline">\(p &gt; 0.05\)</span>)</li>
<li><strong>Substantial increase in adjusted R-squared</strong></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li>Meaningful effect, but lacks statistical support.</li>
<li>May need a larger sample size or further refinement.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li><p><strong>Education</strong>: Adding “hours of sleep” as a predictor of student performance increases adjusted R-squared from 0.40 to <strong>0.50</strong> but yields <strong>p = 0.08</strong>.</p></li>
<li><p>“Hours of sleep” has a practical impact but isn’t statistically significant.</p></li>
</ul>
</div>
</section>
<section id="scenario-4-not-statistically-significant-and-not-effective" class="level2">
<h2 class="anchored" data-anchor-id="scenario-4-not-statistically-significant-and-not-effective">Scenario 4: Not Statistically Significant and Not Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li><strong>p-value</strong> above the significance threshold</li>
<li><strong>No increase in adjusted R-squared</strong></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li>Predictor lacks both statistical and practical value.</li>
<li>Likely safe to exclude from the model.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li><strong>Marketing</strong>: Adding “shoe size” to predict customer satisfaction yields <strong>p = 0.60</strong> and decreases adjusted R-squared from 0.35 to <strong>0.34</strong>.</li>
</ul>
</div>
</section>
</section>
<section id="strategies-for-adding-or-removing-variables" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Strategies for Adding or Removing Variables</h1>
<section id="strategies-for-adding-or-removing-variables-1" class="level2">
<h2 class="anchored" data-anchor-id="strategies-for-adding-or-removing-variables-1">Strategies for Adding or Removing Variables</h2>
<div style="font-size: 70%;">
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>#</strong></th>
<th><strong>Strategy</strong></th>
<th><strong>Description</strong></th>
<th><strong>Add Variables</strong></th>
<th><strong>Remove Variables</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><strong>P-Value</strong></td>
<td>Based on statistical significance</td>
<td>If p-value &lt; 0.05</td>
<td>If p-value &gt; 0.05</td>
</tr>
<tr class="even">
<td>2</td>
<td><strong>Adjusted R-Squared</strong></td>
<td>Checks if model fit improves</td>
<td>If adjusted <span class="math inline">\(R^2\)</span> increases</td>
<td>If adjusted <span class="math inline">\(R^2\)</span> decreases</td>
</tr>
<tr class="odd">
<td>3</td>
<td><strong>F-Test</strong></td>
<td>Compares models with and without added variables</td>
<td>If F-test indicates significant improvement</td>
<td>If F-test shows no significant improvement</td>
</tr>
<tr class="even">
<td>4</td>
<td><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" target="_blank"><strong>AIC</strong></a> or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" target="_blank"><strong>BIC</strong></a></td>
<td>Balances model fit and complexity</td>
<td>If AIC/BIC decreases</td>
<td>If AIC/BIC increases</td>
</tr>
<tr class="odd">
<td>5</td>
<td><a href="https://openintro-ims.netlify.app/model-mlr#sec-model-selection" target="_blank"><strong>Stepwise Regression</strong></a></td>
<td>Automated selection procedure based on statistical contribution</td>
<td>Add variables with high statistical contribution</td>
<td>Remove variables with low contribution</td>
</tr>
<tr class="even">
<td>6</td>
<td><strong>Multicollinearity (<a href="https://online.stat.psu.edu/stat462/node/180/" target="_blank">VIF</a>)</strong></td>
<td>The Variance Inflation Factor detects multicollinearity between independent variables</td>
<td>Use the full model</td>
<td>If VIF &gt; 10</td>
</tr>
<tr class="odd">
<td>7</td>
<td><strong>Best Subset Selection</strong></td>
<td>Compares all possible combinations of predictors to identify the best model</td>
<td>Adds the combination of predictors with the best performance based on chosen criteria (e.g., adjusted <span class="math inline">\(R^2\)</span>)</td>
<td>N/A; evaluates models by selecting the best subset</td>
</tr>
<tr class="even">
<td>8</td>
<td><a href="https://openintro-ims.netlify.app/inf-model-mlr#sec-inf-mult-reg-cv" target="_blank"><strong>Cross-Validation</strong></a></td>
<td>Assesses model performance across different data subsets</td>
<td>If cross-validation performance improves</td>
<td>If cross-validation performance worsens</td>
</tr>
<tr class="odd">
<td>9</td>
<td><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf" target="_blank"><strong>Good vs Bad Controls</strong></a></td>
<td>For causal inference purposes</td>
<td>Add good controls that help block non-causal paths</td>
<td>Remove bad controls that open new spurious paths</td>
</tr>
<tr class="even">
<td>10</td>
<td><strong>Theoretical Justification</strong></td>
<td>Adds or removes variables based on theory, domain knowledge, or experience</td>
<td>Add based on theory or domain knowledge</td>
<td>Remove variables that are irrelevant, regardless of statistical significance</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="adding-or-removing-variables" class="level2">
<h2 class="anchored" data-anchor-id="adding-or-removing-variables">Adding or Removing Variables</h2>
<div class="nonincremental">
<p>We will focus on the following:</p>
<ol type="1">
<li><strong>Stepwise regression</strong></li>
<li><strong>Forward selection</strong></li>
<li><strong>Backward elimination</strong></li>
<li><strong>Best-subsets regression</strong>.</li>
</ol>
<p>The first three procedures are iterative; at each step, a single independent variable is added or deleted, and the new model is evaluated. The process continues until a stopping criterion indicates that the procedure cannot find a better model.</p>
<p>The best-subsets procedure is not a one-variable-at-a-time procedure; it evaluates regression models involving different subsets of the independent variables.</p>
</div>
</section>
<section id="adding-variables-in-regression-models-f-test" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test">Adding Variables in Regression Models: F-test</h2>
<p>We can use an F-test to determine whether it is advantageous to add one or more independent variables to a multiple regression model.</p>
<p>This is based on determining the reduction in the error sum of squares (SSE) resulting from adding variables.</p>
<p>The null and alternative hypotheses are defined as:</p>
<p><span class="math display">\[
H_0: \beta_{q+1} = \beta_{q+2} = \cdots = \beta_p = 0
\]</span></p>
<p><span class="math display">\[
H_a: \text{One or more of the parameters is not equal to zero}
\]</span></p>
<p>where <span class="math inline">\(q\)</span> is the number of independent variables in the first model.</p>
</section>
<section id="adding-variables-in-regression-models-f-test-1" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-1">Adding Variables in Regression Models: F-test</h2>
<p>Let’s illustrate this using the Butler Trucking example.</p>
<p>The regression equation with miles traveled <span class="math inline">\(x_1\)</span> as the only independent variable is:</p>
<p><span class="math display">\[
\hat{y} = 1.2739 + 0.0678x_1
\]</span></p>
<p>The error sum of squares for this model is:</p>
<p><span class="math display">\[
SSE(x_1) = 8.0287
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-2" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-2">Adding Variables in Regression Models: F-test</h2>
<p>When the number of deliveries <span class="math inline">\(x_2\)</span> is added, the regression equation becomes:</p>
<p><span class="math display">\[
\hat{y} = -0.8687 + 0.0611x_1 + 0.9234x_2
\]</span></p>
<p>The error sum of squares for this model is:</p>
<p><span class="math display">\[
SSE(x_1, x_2) = 2.2994
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-3" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-3">Adding Variables in Regression Models: F-test</h2>
<p>The reduction in SSE from adding <span class="math inline">\(x_2\)</span> to the model is:</p>
<p><span class="math display">\[
SSE(x_1) - SSE(x_1, x_2) = 8.0287 - 2.2994 = 5.7293
\]</span></p>
<p>We can conduct a F-test to determine if this reduction is significant:</p>
<p><span class="math display">\[
F = \frac{\frac{SSE(x_1) - SSE(x_1, x_2)}{1}}{\frac{SSE(x_1, x_2)}{n - p - 1}}
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-4" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-4">Adding Variables in Regression Models: F-test</h2>
<div class="nonincremental">
<div style="font-size: 80%;">
<p>Substituting the values:</p>
<p><span class="math display">\[
F = \frac{5.7293}{1} \Big/ \frac{2.2994}{7} = 17.44
\]</span> Where,</p>
<ul>
<li><span class="math inline">\(n = 10\)</span></li>
<li><span class="math inline">\(p = 2\)</span></li>
</ul>
<p><strong>Conclusion from F-Test</strong></p>
<p>Using Excel, we obtain a <span class="math inline">\(p\)</span>-value of <span class="math inline">\(0.0042\)</span> for the calculated F-statistic. Since the <span class="math inline">\(p\)</span>-value is less than the significance level <span class="math inline">\(\alpha = 0.05,\)</span> we reject the null hypothesis. Thus, adding <span class="math inline">\(x_2\)</span> results in a significant reduction in SSE.</p>
<p>The t-test and F-test are equivalent when only one independent variable is being added, and we can use either to assess significance.</p>
</div>
</div>
</section>
<section id="adding-variables-in-regression-models-f-test-5" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-5">Adding Variables in Regression Models: F-test</h2>
<p>In the stepwise regression, forward selection, and backward elimination procedures, the criterion for selecting an independent variable to add or delete from the model at each step is based on the F-statistic.</p>
<p>Suppose we are considering adding <span class="math inline">\(x_2\)</span> to a model involving <span class="math inline">\(x_1\)</span> or deleting <span class="math inline">\(x_2\)</span> from a model involving <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. To test whether the addition or deletion of <span class="math inline">\(x_2\)</span> is statistically significant, the null and alternative hypotheses can be stated as follows:</p>
<p><span class="math display">\[
H_0: \beta_2 = 0
\]</span></p>
<p><span class="math display">\[
H_a: \beta_2 \neq 0
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-6" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-f-test-6">Adding Variables in Regression Models: F-test</h2>
<p>We saw that:</p>
<p><span class="math display">\[
F = \frac{{SSE(x_1) - SSE(x_1, x_2)}}{1} \div \frac{{SSE(x_1, x_2)}}{n - p - 1}
\]</span></p>
<p>can be used as a criterion for determining whether the presence of <span class="math inline">\(x_2\)</span> in the model causes a significant reduction in the error sum of squares.</p>
<p>The p-value corresponding to this F-statistic is used to determine whether an independent variable should be added or deleted from the regression model. The usual rejection rule applies: Reject <span class="math inline">\(H_0\)</span> if p-value <span class="math inline">\(\leq \alpha\)</span>.</p>
</section>
</section>
<section id="stepwise-regression" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Stepwise Regression</h1>
<section id="stepwise-regression-overview" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-overview">Stepwise Regression: Overview</h2>
<ul>
<li><p>Stepwise regression is a <strong>semi-automated</strong> procedure for selecting independent variables in a multiple regression model.</p></li>
<li><p>At each step, the method evaluates whether any variable should be <strong>removed</strong> from or <strong>added</strong> to the model based on predefined significance levels.</p></li>
<li><p>Because it does not exhaustively examine all possible combinations of predictors, stepwise regression does not guarantee finding the best subset of predictors in terms of overall fit or predictive accuracy.</p></li>
</ul>
</section>
<section id="stepwise-regression-how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-how-it-works">Stepwise Regression: How It Works</h2>
<ol type="1">
<li><strong>Initial Removal Check</strong>
<ul>
<li>Begin with an initial model (which can start with no variables, a single variable, or a chosen subset).</li>
<li><strong>Compute F-statistics and p-values</strong> for each predictor already included.</li>
<li>If <strong>any</strong> predictor’s p-value exceeds the “p-value to leave” threshold (often denoted <span class="math inline">\(\alpha_{\text{remove}}\)</span>), the predictor with the <strong>largest</strong> p-value is removed.</li>
<li>After a variable is removed, a new step commences.</li>
</ul></li>
<li><strong>Next Possible Addition</strong>
<ul>
<li>If no variable meets the criterion for removal, then the procedure checks any variables <strong>not</strong> in the model.</li>
<li><strong>Compute F-statistics and p-values</strong> for each candidate predictor not in the model.</li>
<li>If the <strong>smallest</strong> p-value among these is below the “p-value to enter” threshold (often denoted <span class="math inline">\(\alpha_{\text{enter}}\)</span>), the corresponding predictor is added.</li>
<li>Steps alternate between removal and addition until no variable can be removed or added based on these criteria.</li>
</ul></li>
</ol>
</section>
<section id="considerations-and-limitations" class="level2">
<h2 class="anchored" data-anchor-id="considerations-and-limitations">Considerations and Limitations</h2>
<ul>
<li><p><strong>Non-exhaustive approach</strong>: Because stepwise regression evaluates one variable at a time (in or out), it does <strong>not</strong> consider all possible subsets of predictors. Therefore, it might overlook a model that would yield a higher <span class="math inline">\(R^2\)</span> or better predictive performance.</p></li>
<li><p><strong>Variability of inclusion</strong>: A predictor can enter at one step, be removed at a later step, and potentially re-enter if the residual relationships change after adding or removing other variables.</p></li>
<li><p><strong>Overemphasis on p-values</strong>: Stepwise regression heavily depends on p-values, which can be sensitive to sample size and collinearity. It can also lead to an overly complex model or, conversely, a model that excludes potentially relevant predictors.</p></li>
<li><p><strong>Data-driven model building</strong>: Automated selection methods (including stepwise) may produce results that do not generalize well outside the sample. Cross-validation or penalized methods (e.g., LASSO, ridge regression) are often recommended as more robust alternatives.</p></li>
</ul>
</section>
<section id="stepwise-regression-example" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-example">Stepwise Regression Example</h2>
<p>Suppose we have a dataset with:</p>
<ul>
<li><strong>Income</strong> (in thousands of dollars)</li>
<li><strong>Age</strong> (age of household head)</li>
<li><strong>Education</strong> (years of education)</li>
<li><strong>Spending</strong> (annual spending on goods, our dependent variable)</li>
</ul>
</section>
<section id="stepwise-regression-example-starting-point" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-example-starting-point">Stepwise Regression Example: Starting Point</h2>
<ol type="1">
<li><strong>Initial Model</strong>
<ul>
<li>Begin with one predictor (for instance, <strong>Income</strong>) or a subset deemed important by domain knowledge.</li>
<li>Fit the model:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \epsilon.
\]</span></li>
<li>Suppose <strong>Income</strong> is significant at <span class="math inline">\(\alpha=0.05\)</span>. Keep <strong>Income</strong> in the model.</li>
</ul></li>
<li><strong>Evaluating Other Predictors</strong>
<ul>
<li>Next, consider adding <strong>Age</strong> or <strong>Education</strong>.</li>
<li>Fit two separate models, each adding one candidate variable:
<ol type="1">
<li><span class="math inline">\(\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.\)</span></li>
<li><span class="math inline">\(\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_3 \cdot \text{Age} + \epsilon.\)</span></li>
</ol></li>
<li>Calculate p-values for <span class="math inline">\(\hat{\beta}_2\)</span> and <span class="math inline">\(\hat{\beta}_3\)</span>. If <strong>Education</strong> has the lower p-value (below the “p-value to enter,” say 0.05), add <strong>Education</strong> to the model.</li>
</ul></li>
</ol>
</section>
<section id="stepwise-regression-example-checking-for-removal" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-example-checking-for-removal">Stepwise Regression Example: Checking for Removal</h2>
<p>Once you have a model with <strong>Income</strong> and <strong>Education</strong>, stepwise regression checks if <strong>Income</strong> or <strong>Education</strong> should be removed:</p>
<ol type="1">
<li>Re-estimate:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.
\]</span></li>
<li>If either predictor’s p-value exceeds “p-value to leave” (say 0.10), remove that predictor. Otherwise, both stay.</li>
</ol>
</section>
<section id="stepwise-regression-example-considering-remaining-predictors" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-example-considering-remaining-predictors">Stepwise Regression Example: Considering Remaining Predictors</h2>
<p>If <strong>Age</strong> is still not in the model, you check whether it can enter:</p>
<ol type="1">
<li>Fit:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \beta_3 \cdot \text{Age} + \epsilon.
\]</span></li>
<li>If <strong>Age</strong>’s p-value is below the threshold, it is added; otherwise, it is excluded.<br>
</li>
<li>Continue this process until no more additions or removals are justified.</li>
</ol>
</section>
<section id="stepwise-regression-example-final-model" class="level2">
<h2 class="anchored" data-anchor-id="stepwise-regression-example-final-model">Stepwise Regression Example: Final Model</h2>
<p>Eventually, the procedure converges on a model, for example:</p>
<p><span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.
\]</span></p>
<p>This indicates <strong>Income</strong> and <strong>Education</strong> meet the significance criteria for inclusion, while <strong>Age</strong> does not.</p>
</section>
<section id="summary-of-the-stepwise-procedure" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-stepwise-procedure">Summary of the Stepwise Procedure</h2>
<ol type="1">
<li><strong>Start</strong>
<ul>
<li>Choose an initial model (empty, single variable, or chosen subset).</li>
</ul></li>
<li><strong>Remove</strong>
<ul>
<li>Check if any included variables can be removed based on “p-value to leave.” If so, remove the worst offender and repeat.</li>
</ul></li>
<li><strong>Add</strong>
<ul>
<li>If no variable is removed in a step, check whether any excluded variable meets the “p-value to enter.” If so, add the variable with the smallest p-value.</li>
</ul></li>
<li><strong>Stop</strong>
<ul>
<li>Terminate when no variable can be removed or added according to the thresholds.</li>
</ul></li>
</ol>
<!---
# Stepwise Regression {background-color="#cfb991"}

## Stepwise Regression

The stepwise regression procedure begins each step by determining whether any of the variables **already in the model** should be removed.

It does so by first computing an F-statistic and corresponding p-value for each independent variable in the model.

Refering to the level of significance $\alpha$ for determining whether an independent variable should be removed from the model as **p Value to Leave**, if the p-value for any independent variable is greater than **p Value to Leave**, the independent variable with the largest p-value is removed, and the stepwise regression procedure begins a new step.

## Stepwise Regression Process

If no independent variable can be removed from the model, the procedure attempts to enter another independent variable into the model.

It does so by first computing an F-statistic and corresponding p-value for each independent variable that is not in the model.

Refering to the level of significance $\alpha$ for determining whether an independent variable should be entered into the model as **p Value to Enter**.

The independent variable with the smallest p-value is entered into the model provided its p-value is less than **p Value to Enter**. The procedure continues in this manner until no independent variables can be deleted from or added to the model.

## Stepwise Regression Limitations

Because the one-at-a-time procedures do not consider every possible subset for a given number of independent variables, they will not necessarily select the model with the highest R-Square value.

In summary, at each step of the stepwise regression procedure, the first consideration is to see whether any independent variable can be removed from the current model. If none of the independent variables can be removed from the model, the procedure checks to see whether any of the independent variables that are not currently in the model can be entered.

## Stepwise Regression Considerations

Because of the nature of the stepwise regression procedure, an independent variable can enter the model at one step, be removed at a subsequent step, and then enter the model at a later step.

The procedure stops when no independent variables can be removed from or entered into the model.

## Stepwise Regression Example

Let's consider a dataset with the following variables:

-   **Income**: Household income (in \$1000s)
-   **Age**: Age of the head of the household
-   **Education**: Years of education
-   **Spending**: Annual spending on goods (dependent variable)

::: fragment
**Initial Model**

We start by considering an initial model with **Income** as the only predictor of **Spending**.

$$
Spending = \beta_0 + \beta_1 \cdot Income + \epsilon
$$

Using an F-statistic and p-value, we find **Income** is significant, so we keep it in the model.
:::

## Stepwise Regression Example

:::: {style="font-size: 60%;"}
::: nonincremental
The remaining variables, **Age** and **Education**, are candidates for inclusion.

**Calculating p-values for Inclusion**

-   **Add Each Variable Separately**: Create two new models:

    1.  **Adding Education**:

        $$
        Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
        $$

    2.  **Adding Age**:

        $$
        Spending = \beta_0 + \beta_1 \cdot Income + \beta_3 \cdot Age + \epsilon
        $$

-   **Estimate Coefficients**: For each model, estimate the new coefficients ($\hat{\beta}_2$ or $\hat{\beta}_3$).

-   **Compute Standard Errors**: Calculate the standard errors for these new coefficients.

-   **Calculate t-statistics**:

    $$
    t_{\text{Education}} = \frac{\hat{\beta}_2}{SE(\hat{\beta}_2)}
    $$

    $$
    t_{\text{Age}} = \frac{\hat{\beta}_3}{SE(\hat{\beta}_3)}
    $$

-   **Determine p-values**: Find the p-values corresponding to $t_{\text{Education}}$ and $t_{\text{Age}}$.

**Decision**

-   **Select Variable with Lowest p-value**: Choose the variable with the lowest p-value below the entry threshold (e.g., 0.05).

-   **Add Significant Variable**: Since **Education** is significant (assuming a p-value of 0.01), add it to the model.
:::
::::

## Stepwise Regression Example

:::: {style="font-size: 70%;"}
::: nonincremental
With **Income** and **Education** in the model:

$$
Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
$$

**Calculating p-values for Removal**

-   **Re-estimate Coefficients**: Re-estimate $\hat{\beta}_1$ and $\hat{\beta}_2$.

-   **Compute Standard Errors**: Calculate the standard errors for these coefficients.

-   **Calculate t-statistics**:

    $$
    t_{\text{Income}} = \frac{\hat{\beta}_1}{SE(\hat{\beta}_1)}
    $$

    $$
    t_{\text{Education}} = \frac{\hat{\beta}_2}{SE(\hat{\beta}_2)}
    $$

-   **Determine p-values**: Find the p-values corresponding to $t_{\text{Income}}$ and $t_{\text{Education}}$.

**Decision**

-   **Check for Non-significance**: If any variable's p-value exceeds the removal threshold (e.g., 0.10), consider removing it.

-   **Retain Significant Variables**: If both variables remain significant (p-values below 0.05), keep them in the model.
:::
::::

## Stepwise Regression Example

:::: {style="font-size: 70%;"}
::: nonincremental
**Assess Remaining Variables**

Now, only **Age** remains for consideration.

**Calculating p-value for Age**

-   **Add Age to the Model**:

    $$
    Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \beta_3 \cdot Age + \epsilon
    $$

-   **Estimate** $\hat{\beta}_3$ and Compute SE: Estimate the coefficient for **Age** and its standard error.

-   **Calculate t-statistic and p-value**:

    $$
    t_{\text{Age}} = \frac{\hat{\beta}_3}{SE(\hat{\beta}_3)}
    $$

-   **Determine the p-value**: Find the p-value from the t-distribution.

**Decision**

-   **Add or Exclude**: If the p-value for **Age** is below 0.05, add it to the model; otherwise, exclude it.

-   **Example Outcome**: Suppose the p-value for **Age** is 0.15; you would not add **Age** to the model.
:::
::::

## Stepwise Regression Example

<br>

After completing the procedure, our final model could look like this:

$$
Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
$$

Here, **Income** and **Education** are the only significant predictors of **Spending**.

## Summary of Stepwise Procedure

1.  **Start**: Begin with one variable and calculate p-values.
2.  **Add**: Add the variable with the lowest p-value, provided it's below the threshold.
3.  **Remove**: Remove variables if their p-values become too high.
4.  **Stop**: Stop when no more variables can be added or removed.
--->
</section>
</section>
<section id="forward-selection" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Forward Selection</h1>
<section id="forward-selection-overview" class="level2">
<h2 class="anchored" data-anchor-id="forward-selection-overview">Forward Selection: Overview</h2>
<ul>
<li><p><strong>Forward selection</strong> is a <strong>sequential variable selection</strong> procedure that begins with an <strong>empty model</strong> (i.e., no predictors) and incrementally adds variables based on significance criteria.</p></li>
<li><p>Unlike the stepwise procedure, forward selection <strong>never removes</strong> any variable once it has been included.</p></li>
</ul>
</section>
<section id="forward-selection-procedure" class="level2">
<h2 class="anchored" data-anchor-id="forward-selection-procedure">Forward Selection: Procedure</h2>
<div style="font-size: 70%;">
<ol type="1">
<li><strong>Start with No Variables</strong>
<ul>
<li>The initial model includes <strong>no</strong> predictors: <span class="math display">\[
y = \beta_0 + \epsilon.
\]</span></li>
</ul></li>
<li><strong>Evaluate All Predictors for Entry</strong>
<ul>
<li>For each potential predictor not yet in the model, calculate the F-statistic (or equivalently, t-statistic for the coefficient) and its corresponding p-value.</li>
<li><strong>p-Value to Enter</strong>: Each predictor is tested against a specified significance level (e.g., <span class="math inline">\(\alpha_{\text{enter}}\)</span>). If the smallest p-value among all candidate predictors falls below <span class="math inline">\(\alpha_{\text{enter}}\)</span>, add that corresponding predictor to the model.</li>
</ul></li>
<li><strong>Recalculate and Repeat</strong>
<ul>
<li>After adding a predictor, recalculate the model parameters and evaluate the remaining predictors for entry. Continue this process of adding <strong>one</strong> variable at a time.</li>
</ul></li>
<li><strong>Termination</strong>
<ul>
<li>The procedure stops when <strong>no</strong> remaining predictors meet the threshold for entry, meaning all p-values for excluded variables exceed <span class="math inline">\(\alpha_{\text{enter}}\)</span>.</li>
</ul></li>
</ol>
<div class="fragment">
<blockquote class="blockquote">
<p><strong>Key Difference from Stepwise</strong>: In forward selection, <strong>once a variable is included</strong>, it cannot be removed—even if adding subsequent variables renders it less significant.</p>
</blockquote>
</div>
</div>
</section>
<section id="forward-selection-limitations" class="level2">
<h2 class="anchored" data-anchor-id="forward-selection-limitations">Forward Selection Limitations</h2>
<div style="font-size: 80%;">
<ol type="1">
<li><p><strong>No Removal of Variables</strong>: Because there is no mechanism to remove predictors, variables that become <strong>unnecessary</strong> later might remain in the final model. This can lead to inflated model complexity and reduced interpretability.</p></li>
<li><p><strong>Potential Multicollinearity Issues</strong>: Forward selection does not explicitly account for <strong>multicollinearity</strong>. High correlations among predictors may lead to unstable coefficient estimates and p-values, producing misleading or less robust results.</p></li>
<li><p><strong>Greedy Algorithm</strong>: The procedure is <strong>myopically focused</strong> on adding one predictor at a time based on immediate improvements in model fit. It may miss a combination of predictors that could perform better when considered together.</p></li>
<li><p><strong>Risk of Overfitting</strong>: When many potential predictors exist, forward selection can overfit the sample data, reducing the model’s generalizability. The model might appear strong in-sample but perform poorly on new data.</p></li>
<li><p><strong>Neglect of Interactions and Nonlinearities</strong>: Because forward selection evaluates predictors in isolation, it does not automatically consider <strong>interaction</strong> terms or <strong>nonlinear transformations</strong>. Thus, it can overlook influential higher-order relationships.</p></li>
</ol>
</div>
<!---
# Forward Selection {background-color="#cfb991"}

## Forward Selection

The forward selection procedure starts with no independent variables. It adds variables one at a time using the same procedure as stepwise regression for determining whether an independent variable should be entered into the model.

-   However, the forward selection procedure does not permit a variable to be removed from the model once it has been entered.

-   The procedure stops when the p-value for each of the independent variables not in the model is greater than **p Value to Enter**.

## Forward Selection Limitations

1.  **No Removal of Variables**: Once a variable is entered into the model, it cannot be removed, even if later additions make it less significant. This could result in keeping variables that are not optimal for the final model.

2.  **Ignores Multicollinearity**: Forward selection does not account for multicollinearity between independent variables. High correlations among predictors may lead to unstable coefficients and misleading results.

3.  **Greedy Approach**: The procedure focuses on adding one variable at a time based on immediate statistical improvement, which might lead to suboptimal global models. It might overlook combinations of variables that would better explain the dependent variable.

4.  **Model Overfitting**: Forward selection increases the risk of overfitting, especially when the dataset has many variables. This results in a model that fits the training data too closely but performs poorly on new data.

5.  **Assumes Independence of Variables**: The procedure assumes that variables can be assessed one by one for entry, without considering how combinations of variables interact. This might ignore important interactions between variables that could improve model performance.

--->
</section>
</section>
<section id="backward-elimination" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Backward Elimination</h1>
<section id="backward-elimination-overview" class="level2">
<h2 class="anchored" data-anchor-id="backward-elimination-overview">Backward Elimination: Overview</h2>
<p><strong>Backward elimination</strong> is a <strong>sequential variable selection</strong> method that starts with the <strong>full model</strong>—i.e., one that includes <strong>all</strong> potential predictors—and iteratively removes the least significant predictor at each step. It stops when no remaining predictors have a p-value above the designated <strong>“p-value to leave”</strong> threshold (<span class="math inline">\(\alpha_{\text{remove}}\)</span>). Unlike stepwise methods, once a variable is removed, it is <strong>not</strong> allowed to reenter the model.</p>
</section>
<section id="backward-elimination-procedure" class="level2">
<h2 class="anchored" data-anchor-id="backward-elimination-procedure">Backward Elimination: Procedure</h2>
<div style="font-size: 70%;">
<ol type="1">
<li><strong>Begin with All Predictors</strong>
<ul>
<li>The initial model is: <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k + \epsilon.
\]</span></li>
</ul></li>
<li><strong>Compute p-values</strong>
<ul>
<li>Estimate the coefficients and compute p-values (or equivalent F-statistics) for each predictor.</li>
</ul></li>
<li><strong>Remove the Least Significant Variable</strong>
<ul>
<li>Identify the predictor with the <strong>largest</strong> p-value.</li>
<li>If that p-value exceeds the “p-value to leave” threshold, remove the corresponding variable from the model.</li>
</ul></li>
<li><strong>Re-estimate and Repeat</strong>
<ul>
<li>After removing a variable, re-fit the model and compute p-values again for the reduced set of predictors.<br>
</li>
<li>Continue removing variables one at a time until <strong>no</strong> remaining predictors have p-values larger than <span class="math inline">\(\alpha_{\text{remove}}\)</span>.</li>
</ul></li>
<li><strong>Stop Criterion</strong>
<ul>
<li>Once no variable meets the removal criterion, the procedure ends. The final set of variables constitutes the chosen model.</li>
</ul></li>
</ol>
<div class="fragment">
<blockquote class="blockquote">
<p><strong>Key Restriction</strong>: Any predictor removed at an earlier step <strong>cannot</strong> be reconsidered for reentry in later steps.</p>
</blockquote>
</div>
</div>
</section>
<section id="backward-elimination-limitations" class="level2">
<h2 class="anchored" data-anchor-id="backward-elimination-limitations">Backward Elimination Limitations</h2>
<ol type="1">
<li><p><strong>No Reentry of Variables</strong>: Once a predictor is removed, it stays out—even if, after further eliminations, it would have become significant again. This may lead to <strong>omitting</strong> variables that could have value under a different model specification.</p></li>
<li><p><strong>Multicollinearity Concerns</strong>: Backward elimination does not explicitly address <strong>multicollinearity</strong>. Highly correlated predictors may cause instability in coefficient estimates, rendering p-values less reliable.</p></li>
<li><p><strong>Risk of Overfitting</strong>: Because the procedure begins with <strong>all</strong> variables, it may produce an overly complex initial model. While backward elimination might remove some predictors, it can still result in a model that is closely tailored to the sample data but performs poorly in <strong>out-of-sample</strong> scenarios.</p></li>
<li><p><strong>Dependence on Initial Model</strong>: The entire process depends heavily on the <strong>initial choice</strong> of predictors. If irrelevant variables are included or if critical interaction terms are missing, the final model may be suboptimal.</p></li>
<li><p><strong>Potentially Different Final Models</strong>: Different paths of elimination might yield different final models, depending on the order in which variables are removed. This is particularly true if multiple predictors have similar statistical significance or if interactions are not explored.</p></li>
</ol>
<!---

# Backward Elimination {background-color="#cfb991"}

## Backward Elimination

The backward elimination procedure begins with a model that includes all the independent variables.

It then deletes one independent variable at a time using the same procedure as stepwise regression. However, the backward elimination procedure does not permit an independent variable to be reentered once it has been removed.

The procedure stops when none of the independent variables in the model has a p-value greater than **p Value to Leave**.

## Backward Elimination Limitations

1.  **No Reentry of Variables**: Once a variable is removed from the model, it cannot be reentered, even if later stages show that it might be significant. This could lead to models that miss important predictors.

2.  **Ignores Multicollinearity**: Backward elimination does not take into account multicollinearity between variables. High correlations between predictors can result in unreliable coefficient estimates.

3.  **Overfitting Risk**: By starting with all variables and only eliminating those that don't meet the p-value threshold, there is a higher risk of overfitting. The model may fit the training data too closely but generalize poorly to new data.

4.  **Dependent on Initial Model**: The procedure is highly dependent on the initial model, which includes all variables. Poor choices in the initial set of variables can lead to suboptimal models.

5.  **May Lead to Different Models**: Different elimination paths could lead to different final models, and not all of them may be optimal. Backward elimination might overlook variable interactions and combinations that forward selection would have considered.

--->
</section>
</section>
<section id="best-subsets-regression" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Best-Subsets Regression</h1>
<section id="best-subsets-regression-1" class="level2">
<h2 class="anchored" data-anchor-id="best-subsets-regression-1">Best-Subsets Regression</h2>
<p>Many statistical software packages have a procedure called best-subsets regression that enables the user to find, given a specified number of independent variables, the best regression equation.</p>
<p>Typical output from such packages will enable the user to identify:</p>
<ul>
<li><p>The two best one-variable estimated regression equations,</p></li>
<li><p>The two best two-variable regression equations,</p></li>
<li><p>The two best three-variable regression equations, and so on.</p></li>
</ul>
<div class="fragment">
<p>The criterion used in determining which estimated regression equations are best for any number of predictors is usually the value of the adjusted coefficient of determination.</p>
</div>
</section>
</section>
<section id="adding-variables-in-regression-models-notes" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Adding Variables in Regression Models: Notes</h1>
<section id="adding-variables-in-regression-models-notes-1" class="level2">
<h2 class="anchored" data-anchor-id="adding-variables-in-regression-models-notes-1">Adding Variables in Regression Models: Notes</h2>
<ol type="1">
<li><p><strong>Limitations of Procedures</strong>: None of the procedures that add or delete variables one at a time can be guaranteed to identify the best regression model.</p>
<ul>
<li>However, they are excellent approaches to finding good models—especially when multicollinearity is present.</li>
</ul></li>
<li><p><strong>Software Implementation</strong>: The stepwise, forward selection, backward elimination, and best-subsets approaches to building a regression model can be implemented in Excel.</p>
<ul>
<li><p>However, this would be very inefficient as each approach would potentially require several steps in which various models based on what was learned in the previous step would have to be estimated.</p></li>
<li><p>Most statistical software (including <code>R</code>) are capable of implementing each of these algorithms automatically.</p></li>
</ul></li>
</ol>
</section>
</section>
<section id="summary" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Summary</h1>
<section id="summary-1" class="level2">
<h2 class="anchored" data-anchor-id="summary-1">Summary</h2>
<div style="font-size: 70%;">
<div class="nonincremental">
<p>Some key takeaways from this session:</p>
<ul>
<li><p><strong>General Linear Model</strong>: Models parameters with exponents of 1. Example:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 z_1 + \beta_2 z_2 + \ldots + \beta_p z_p + \epsilon\]</span></p></li>
<li><p><strong>Curvilinear Relationships</strong>: Use quadratic terms to model curvature:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon\]</span></p></li>
<li><p><strong>Interaction Effects</strong>: Captures how two variables together influence <span class="math inline">\(y\)</span>.Here is a great <a href="https://www.cambridge.org/core/journals/political-analysis/article/understanding-interaction-models-improving-empirical-analyses/9BA57B3720A303C61EBEC6DDFA40744B" target="_blank">paper about the topic</a>.</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon\]</span></p></li>
<li><p><strong>Log Transformations</strong>: Useful for handling non-linearity and heteroscedasticity.</p></li>
<li><p><strong>Stepwise Regression</strong>: Iterative process of adding/removing variables based on statistical significance, but risks overfitting.</p></li>
<li><p><strong>Forward Selection</strong>: Adds variables one-by-one but doesn’t allow removal after inclusion.</p></li>
<li><p><strong>Backward Elimination</strong>: Starts with all variables and eliminates non-significant ones.</p></li>
<li><p><strong>Best-Subsets Regression</strong>: Evaluates all possible subsets of variables to find the best model.</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="thank-you" class="level1" data-background-color="#cfb991">
<h1 data-background-color="#cfb991">Thank you!</h1>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>