<!DOCTYPE html>
<html lang="en"><head>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Professor Davi Moreira ">
  <title>MGMT 30500: Business Statistics –  MGMT 30500: Business Statistics </title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../site_libs/revealjs/dist/theme/quarto-c812a774c17cd743a31b19f8745c44ab.css">
  <link href="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><span style="font-size: 100%;"> MGMT 30500: Business Statistics </span></h1>
  <p class="subtitle"><span style="font-size: 150%;"> Regression Analysis: Model Building</span></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Professor<br>Davi Moreira<br> 
</div>
</div>
</div>

</section>
<section id="overview" class="slide level2 center">
<h2>Overview</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li>General Linear Model</li>
<li>Modeling Curvilinear Relationships</li>
<li>Interaction</li>
<li>Transformations</li>
<li>Nonlinear Models That Are Intrinsically Linear</li>
</ul>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<ul>
<li><p>Determining When to Add or Delete Variables<br>
</p></li>
<li><p>Variable Selection Procedures</p>
<ul>
<li>Stepwise Method</li>
<li>Forward Method</li>
<li>Backward Method</li>
<li>Best Subsets Method</li>
</ul></li>
</ul>
</div></div>
</section>
<section>
<section id="general-linear-model" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>General Linear Model</h1>

</section>
<section id="general-linear-model-1" class="slide level2 center">
<h2>General Linear Model</h2>
<ul>
<li class="fragment"><p>Models in which the parameters <span class="math inline">\((\beta_0, \beta_1, \ldots, \beta_p)\)</span> all have exponents of one are called <strong>linear models</strong>.</p></li>
<li class="fragment"><p>A <strong>general linear model</strong> involving <span class="math inline">\(p\)</span> independent variables (<span class="math inline">\(z_i\)</span>’s) is:</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 z_1 + \beta_2 z_2 + \ldots + \beta_p z_p + \epsilon
\]</span></p>
<p>where each independent variable <span class="math inline">\(z_i\)</span> is a (linear or nonlinear) function of <span class="math inline">\(x_1, x_2, \ldots, x_k\)</span> (the variables for which data have been collected).</p>
<ul>
<li class="fragment">Here, <span class="math inline">\(y\)</span> can be a function of the original response variable as well.</li>
</ul>
</div>
</section>
<section id="general-linear-model-2" class="slide level2 center">
<h2>General Linear Model</h2>
<ul>
<li class="fragment"><p>The simplest case is when we have collected data for just one variable <span class="math inline">\(x_1\)</span> and want to estimate <span class="math inline">\(y\)</span> by using a straight-line relationship. In this case <span class="math inline">\(z_1 = x_1\)</span>.</p></li>
<li class="fragment"><p>This model is called a <strong>simple first-order model</strong> with one predictor variable.</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \epsilon
\]</span></p>
</div>
</section></section>
<section>
<section id="modelling-curvilinear-relationships" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Modelling Curvilinear Relationships</h1>

</section>
<section id="modelling-curvilinear-relationships-1" class="slide level2 center">
<h2>Modelling Curvilinear Relationships</h2>
<p><br></p>

<img data-src="16_chapter_model_building_files/figure-html/unnamed-chunk-2-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"><p><br></p>
</section>
<section id="modelling-curvilinear-relationships-2" class="slide level2 center">
<h2>Modelling Curvilinear Relationships</h2>
<ul>
<li class="fragment"><p>Some non-linear models can be expressed as a general linear model.</p></li>
<li class="fragment"><p>To account for a curvilinear relationship, we might consider a <strong>second-order model with one predictor variable</strong> <span class="math inline">\((x_1)\)</span>:</p></li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon
\]</span></p>
<ul>
<li class="fragment">It is a linear model because we can set: <span class="math inline">\(z_1 = x_1\)</span> and <span class="math inline">\(z_2 = x_1^2\)</span>.</li>
</ul>
</div>
</section>
<section id="modelling-curvilinear-relationships-3" class="slide level2 center">
<h2>Modelling Curvilinear Relationships</h2>

<img data-src="16_chapter_model_building_files/figure-html/unnamed-chunk-3-1.png" class="quarto-figure quarto-figure-center r-stretch" width="672"><div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \epsilon
\]</span></p>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div style="font-size: 70%;">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon
\]</span></p>
</div>
</div></div>
</section>
<section id="interpretation-of-independent-variable-effect-in-a-second-order-model" class="slide level2 center">
<h2>Interpretation of Independent Variable Effect in a Second-Order Model</h2>
<ul>
<li class="fragment"><p><span class="math inline">\(\beta_1\)</span>: Represents the linear effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span>. It gives the initial (or marginal) change in <span class="math inline">\(y\)</span> for a one-unit increase in <span class="math inline">\(x_1\)</span> when <span class="math inline">\(x_1^2\)</span> is held constant.</p></li>
<li class="fragment"><p><span class="math inline">\(\beta_2\)</span>: Represents the quadratic effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span>. It determines whether the curve opens upwards <span class="math inline">\((\beta_2 &gt; 0)\)</span> or downwards <span class="math inline">\((\beta_2 &lt; 0)\)</span>.</p></li>
</ul>
</section>
<section id="marginal-effect-of-x_1" class="slide level2 center">
<h2>Marginal Effect of <span class="math inline">\(x_1\)</span></h2>
<ul>
<li class="fragment">The overall effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> can be expressed as:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
\frac{dy}{dx_1} = \beta_1 + 2\beta_2 x_1
\]</span></p>
<ul>
<li class="fragment"><p>This shows that the effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> changes as <span class="math inline">\(x_1\)</span> increases or decreases due to the presence of the quadratic term <span class="math inline">\(x_1^2\)</span>.</p></li>
<li class="fragment"><p>Instead of a constant change (as in linear models), the presence of <span class="math inline">\(2\beta_2 x_1\)</span> shows a varying slope depending on the value of <span class="math inline">\(x_1\)</span>.</p></li>
</ul>
</div>
</section>
<section id="practical-interpretation" class="slide level2 center">
<h2>Practical Interpretation</h2>
<ul>
<li class="fragment"><p>If <span class="math inline">\(\beta_2 &gt; 0\)</span>, <span class="math inline">\(y\)</span> increases at an increasing rate as <span class="math inline">\(x_1\)</span> increases, resulting in a U-shaped curve.</p></li>
<li class="fragment"><p>If <span class="math inline">\(\beta_2 &lt; 0\)</span>, <span class="math inline">\(y\)</span> increases at a decreasing rate and then decreases, resulting in an inverted U-shaped curve.</p></li>
<li class="fragment"><p>The effect of <span class="math inline">\(x_1\)</span> should always be considered in light of both <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span>.</p></li>
</ul>
</section></section>
<section>
<section id="interaction" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Interaction</h1>

</section>
<section id="interaction-1" class="slide level2 center">
<h2>Interaction</h2>
<ul>
<li class="fragment">If the original data set consists of observations for <span class="math inline">\(y\)</span> and two independent variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, we might develop a <strong>second-order model with two predictor variables</strong> <span class="math inline">\((x_1\)</span> and <span class="math inline">\(x_2)\)</span> with interaction:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon
\]</span></p>
<ul>
<li class="fragment"><p>The variable <span class="math inline">\(x_1 x_2\)</span> is added to account for the potential effects of the two variables acting together.</p></li>
<li class="fragment"><p><span class="math inline">\(\beta_3\)</span> measures the <strong>interaction effect</strong>.</p></li>
</ul>
</div>
</section>
<section id="example-interaction" class="slide level2 center">
<h2>Example: Interaction</h2>
<p>Lets check the regression study conducted by Tyler Personal Care for one of its new shampoo products. Two factors believed to have the most influence on sales are:</p>
<ul>
<li><p>Unit selling price</p></li>
<li><p>Advertising expenditure</p></li>
</ul>
<p>To investigate the effects of these two variables on sales, prices of $2.00, $2.50, and $3.00 were paired with advertising expenditures of $50,000 and $100,000 in 24 test markets.</p>
</section>
<section id="example-difference-in-mean-sales" class="slide level2 center">
<h2>Example: Difference in Mean Sales</h2>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<p><strong>Mean Sales (1000s) for the Tyler Personal Care Example</strong></p>
<table class="caption-top">
<thead>
<tr class="header">
<th><strong>Advertising Expenditure</strong></th>
<th><strong>$2.00</strong></th>
<th><strong>$2.50</strong></th>
<th><strong>$3.00</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>$50,000</strong></td>
<td>461</td>
<td>364</td>
<td>332</td>
</tr>
<tr class="even">
<td><strong>$100,000</strong></td>
<td>808</td>
<td>646</td>
<td>375</td>
</tr>
</tbody>
</table>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div style="font-size: 70%;">
<ul>
<li class="fragment"><p>With a price of $2.00, the difference in mean sales between advertising expenditures of $50,000 and $100,000 is:</p>
<p><span class="math display">\[
808,000 - 461,000 = 347,000 \, units
\]</span></p></li>
<li class="fragment"><p>When the price is $2.50, the difference is:</p>
<p><span class="math display">\[
646,000 - 364,000 = 282,000 \, units
\]</span></p></li>
<li class="fragment"><p>When the price is $3.00, the difference is:</p>
<p><span class="math display">\[
375,000 - 332,000 = 43,000 \, units
\]</span></p></li>
</ul>
<div class="fragment">
<p>Clearly, the difference in mean sales between advertising expenditures depends on the price of the product. The effect of increased advertising expenditure diminishes at higher selling prices, providing evidence of interaction between the price and advertising expenditure variables.</p>
</div>
</div>
</div></div>
</section>
<section id="example-regression-model-with-interaction" class="slide level2 center">
<h2>Example: Regression Model with Interaction</h2>
<p><br></p>
<p>To account for the effect of interaction, we use the following regression model:</p>
<p><span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon
\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(y\)</span> = unit sales (1000s)</li>
<li class="fragment"><span class="math inline">\(x_1\)</span> = price ($)</li>
<li class="fragment"><span class="math inline">\(x_2\)</span> = advertising expenditure ($1000s)</li>
</ul>
</section>
<section id="example-estimated-regression-equation" class="slide level2 center">
<h2>Example: Estimated Regression Equation</h2>
<p>Using the estimated regression equation:</p>
<p><span class="math display">\[
\text{Sales} = -275.8333 + 175 \, \text{Price} + 19.68 \, \text{AdvExp} - 6.08 \, \text{PriceAdv}
\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><strong>Sales</strong> = unit sales (1000s)</li>
<li class="fragment"><strong>Price</strong> = price of the product ($)</li>
<li class="fragment"><strong>AdvExp</strong> = advertising expenditure ($1000s)</li>
<li class="fragment"><strong>PriceAdv</strong> = interaction term (Price times AdvExp)</li>
</ul>
</section>
<section id="example-significance-of-interaction" class="slide level2 center">
<h2>Example: Significance of Interaction</h2>
<p><br></p>

<img data-src="figs/interaction_reg_output.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p>The <span class="math inline">\(p\)</span>-value corresponding to the <span class="math inline">\(t\)</span>-test for <code>PriceAdv</code> is 0.0000, which indicates significant interaction between the price of the product and the advertising expenditure.</p>
<p><br></p>
</section>
<section id="example-interpretation-of-coefficients" class="slide level2 center">
<h2>Example: Interpretation of Coefficients</h2>
<p><br></p>
<ul>
<li class="fragment"><p><span class="math inline">\(\beta_0\)</span>: Intercept. Represents the expected value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are zero.</p></li>
<li class="fragment"><p><span class="math inline">\(\beta_1\)</span>: Effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> when <span class="math inline">\(x_2 = 0\)</span>.</p></li>
<li class="fragment"><p><span class="math inline">\(\beta_2\)</span>: Effect of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(y\)</span> when <span class="math inline">\(x_1 = 0\)</span>.</p></li>
<li class="fragment"><p><span class="math inline">\(\beta_3\)</span>: Interaction effect between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Indicates how the relationship between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(y\)</span> changes with different values of <span class="math inline">\(x_2\)</span>, and vice-versa.</p></li>
</ul>
</section>
<section id="example-marginal-effects" class="slide level2 center">
<h2>Example: Marginal Effects</h2>
<ul>
<li class="fragment"><strong>Effect of</strong> <span class="math inline">\(x_1\)</span>:</li>
</ul>
<div class="fragment">
<p><span class="math display">\[
\frac{\partial y}{\partial x_1} = \beta_1 + \beta_3 x_2
\]</span></p>
<ul>
<li class="fragment"><strong>Effect of</strong> <span class="math inline">\(x_2\)</span>:</li>
</ul>
</div>
<div class="fragment">
<p><span class="math display">\[
\frac{\partial y}{\partial x_2} = \beta_2 + \beta_3 x_1
\]</span></p>
</div>
<ul>
<li class="fragment">The effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> depends on <span class="math inline">\(x_2\)</span>, and the effect of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(y\)</span> depends on <span class="math inline">\(x_1\)</span>.</li>
</ul>
</section>
<section id="example-interpretation-of-interaction-effect" class="slide level2 center">
<h2>Example: Interpretation of Interaction Effect</h2>
<p><br></p>
<ul>
<li class="fragment"><p>If <span class="math inline">\(\beta_3 &gt; 0\)</span>, a positive (or negative) effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> increases as <span class="math inline">\(x_2\)</span> increases.</p></li>
<li class="fragment"><p>If <span class="math inline">\(\beta_3 &lt; 0\)</span>, a positive (or negative) effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(y\)</span> decreases as <span class="math inline">\(x_2\)</span> increases.</p></li>
</ul>
</section>
<section id="example-coefficient-interpretation" class="slide level2 center">
<h2>Example: Coefficient Interpretation</h2>
<div style="font-size: 80%;">
<ul>
<li class="fragment"><p><strong>Price</strong>: <span class="math inline">\(175\)</span> - When AdvExp is zero, a one-unit increase in Price leads to an expected increase of 175 units in <span class="math inline">\(y\)</span>.</p></li>
<li class="fragment"><p><strong>AdvExp</strong>: <span class="math inline">\(19.68\)</span> - When Price is zero, a one-unit increase in AdvExp results in an expected increase of 19.68 units in <span class="math inline">\(y\)</span>.</p></li>
<li class="fragment"><p><strong>PriceAdv</strong>: <span class="math inline">\(-6.08\)</span>- Interaction effect: A one-unit increase in AdvExp decreases the effect of Price on <span class="math inline">\(y\)</span> by 6.08 units (and vice versa).</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation of Interaction Effect</strong></p>
<p><br></p>
<ul>
<li class="fragment"><p>The interaction term <span class="math inline">\(\beta_3\)</span> (PriceAdv) is negative.</p>
<ul>
<li class="fragment">As AdvExp increases, the positive effect of Price on <span class="math inline">\(y\)</span> decreases.</li>
<li class="fragment">Suggests diminishing returns on Price when AdvExp is already high (or vice versa).</li>
</ul></li>
<li class="fragment"><p>An increase in Advertising Expenditures may lead to higher sales, but this effect diminishes as more the Price increases.</p></li>
<li class="fragment"><p>The interaction effect is negative and significant, showing that the combined effect of Price and AdvExp on <span class="math inline">\(y\)</span> is not purely additive.</p></li>
<li class="fragment"><p><strong>Takeaway</strong>: Adjustments to Price or AdvExp should consider their interaction, as increasing both may not yield linear increases in <span class="math inline">\(y.\)</span></p></li>
</ul>
</div>
</div>
</section></section>
<section>
<section id="log-transformation" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Log Transformation</h1>

</section>
<section id="original-data" class="slide level2 center">
<h2>Original Data</h2>
<p><br></p>

<img data-src="16_chapter_model_building_files/figure-html/unnamed-chunk-5-1.png" class="quarto-figure quarto-figure-center r-stretch" width="480"></section>
<section id="log-transformation-1" class="slide level2 center">
<h2>Log Transformation</h2>
<p><br></p>

<img data-src="16_chapter_model_building_files/figure-html/unnamed-chunk-6-1.png" class="quarto-figure quarto-figure-center r-stretch" width="672"></section>
<section id="possibile-logarithmic-transformations" class="slide level2 center">
<h2>Possibile Logarithmic Transformations</h2>
<p><br></p>
<table class="caption-top">
<colgroup>
<col style="width: 26%">
<col style="width: 34%">
<col style="width: 38%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>X</strong></th>
<th style="text-align: center;"><strong>logX</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><br><strong>Y</strong><br></td>
<td style="text-align: center;"><br><strong>linear</strong><br><span class="math inline">\(\hat{Y}_i = \alpha + \beta X_i\)</span><br></td>
<td style="text-align: center;"><br><strong>linear-log</strong><br><span class="math inline">\(\hat{Y}_i = \alpha + \beta \log X_i\)</span><br></td>
</tr>
<tr class="even">
<td style="text-align: center;"><br><strong>logY</strong><br></td>
<td style="text-align: center;"><br><strong>log-linear</strong><br><span class="math inline">\(\log \hat{Y}_i = \alpha + \beta X_i\)</span><br></td>
<td style="text-align: center;"><br><strong>log-log</strong><br><span class="math inline">\(\log \hat{Y}_i = \alpha + \beta \log X_i\)</span><br></td>
</tr>
</tbody>
</table>
<p><br></p>
<p><br></p>
<div style="font-size: 60%;">
<p>Source: <a href="https://kenbenoit.net/assets/courses/ME104/logmodels2.pdf">Linear Regression Models with Logarithmic Transformations</a></p>
</div>
</section>
<section id="what-changes-after-the-transformation" class="slide level2 center">
<h2>What Changes After the Transformation</h2>
<p><br></p>
<ul>
<li class="fragment"><p>You should be cautious when interpreting and reporting the findings of the model.</p></li>
<li class="fragment"><p>The interpretation varies based on the variable that was transformed (dependent variable, independent variable, or both).</p></li>
<li class="fragment"><p>As a general rule, you should always keep in mind the logic:</p></li>
</ul>
<div class="fragment">
<blockquote>
<p><em>“What does a one-unit change in this transformed variable mean in terms of the original variable?”</em></p>
</blockquote>
<center>
<a href="https://theeffectbook.net/ch-StatisticalAdjustment.html#getting-fancier-with-regression">The Effect Book</a>
</center>
</div>
</section>
<section id="log-transformation-summary" class="slide level2 center">
<h2>Log Transformation Summary</h2>
<p><br></p>
<div style="font-size: 80%;">
<table class="caption-top">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Model Equation</strong></th>
<th><strong>Interpretation of</strong> <span class="math inline">\(\beta_1\)</span></th>
<th><strong>Interpretation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Level-level</strong></td>
<td><span class="math inline">\(y = \beta_0 + \beta_1 x + \epsilon\)</span></td>
<td><span class="math inline">\(\Delta y = \beta_1 \Delta x\)</span></td>
<td>A one-unit change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\)</span> unit change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Level-log</strong></td>
<td><span class="math inline">\(y = \beta_0 + \beta_1 \log(x) + \epsilon\)</span></td>
<td><span class="math inline">\(\Delta y = (\beta_1 / 100) \% \Delta x\)</span></td>
<td>A 1% change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1/100\)</span> unit change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Log-level</strong></td>
<td><span class="math inline">\(\log(y) = \beta_0 + \beta_1 x + \epsilon\)</span></td>
<td><span class="math inline">\(\%\Delta y = (100\beta_1) \Delta x\)</span></td>
<td>A one-unit change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
<div class="fragment">
<p><br></p>
<table class="caption-top">
<colgroup>
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 22%">
<col style="width: 31%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Log-log</strong></td>
<td><span class="math inline">\(\log(y) = \beta_0 + \beta_1 \log(x) + \epsilon\)</span></td>
<td><span class="math inline">\(\%\Delta y = \beta_1 \% \Delta x\)</span></td>
<td>A 1% change in <span class="math inline">\(x\)</span> results in a <span class="math inline">\(\beta_1\%\)</span> change in <span class="math inline">\(y\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</section>
<section id="example-log-transformation" class="slide level2 center">
<h2>Example: Log Transformation</h2>
<div style="font-size: 70%;">
<p>Predict Miles-Per-Gallon (MPG) according to the automobile Weight (in pounds):</p>
<div class="columns">
<div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="fragment">
<p><span class="math display">\[
\text{MPG} = 56.0957 - 0.0116 \times \text{Weight}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/level_level_example.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li class="fragment"><p>The pattern does not look like the the horizontal band we should expect to find if the assumptions about the error term are valid.</p></li>
<li class="fragment"><p>Variability in the residuals appears to increase as the value of <span class="math inline">\(\hat{y}\)</span> increases.</p></li>
</ul>
</div>
</div><div class="column" style="text-align: center; justify-content: center; align-items: center;">
<div class="fragment">
<p><span class="math display">\[
\text{LnMPG} = 4.5242 - 0.0005 \times \text{Weight}
\]</span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figs/log_level_example.png" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
</div>
</div>
<ul>
<li class="fragment"><p>The wedge-shaped pattern disappeared.</p></li>
<li class="fragment"><p>The model with the logarithm of miles per gallon as the dependent variable provides an excellent fit to the oberved data.</p></li>
</ul>
</div>
</div></div>
</div>
</section></section>
<section>
<section id="nonlinear-models-that-are-intrinsically-linear" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Nonlinear Models That Are Intrinsically Linear</h1>

</section>
<section id="nonlinear-models-that-are-intrinsically-linear-1" class="slide level2 center">
<h2>Nonlinear Models That Are Intrinsically Linear</h2>
<p><br></p>
<p>Models in which the parameters <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_p\)</span> have exponents other than one are called nonlinear models.</p>
<p>For the case of the <strong>exponential model</strong>, we can perform a transformation of variables that will enable us to perform regression analysis using the general linear model.</p>
<p>The exponential model involves the following regression equation:</p>
<p><span class="math display">\[
E(y) = \beta_0 \beta_1^x
\]</span></p>
<p>This model is appropriate when the dependent variable <span class="math inline">\(y\)</span> increases or decreases by a constant percentage, instead of by a fixed amount, as <span class="math inline">\(x\)</span> increases.</p>
</section>
<section id="example-of-exponential-model" class="slide level2 center">
<h2>Example of Exponential Model</h2>
<p>Suppose sales for a product <span class="math inline">\(y\)</span> are related to advertising expenditure <span class="math inline">\(x\)</span> (in $1000s) according to the following regression equation:</p>
<p><span class="math display">\[
E(y) = 500(1.2)^x
\]</span> Thus,</p>
<ul>
<li>for <span class="math inline">\(x = 1\)</span>, <span class="math inline">\(E(y) = 500(1.2)^1 = 600\)</span></li>
<li>for <span class="math inline">\(x = 2\)</span>, <span class="math inline">\(E(y) = 500(1.2)^2 = 720\)</span></li>
<li>for <span class="math inline">\(x = 3\)</span>, <span class="math inline">\(E(y) = 500(1.2)^3 = 864\)</span></li>
</ul>
<p>Note that <span class="math inline">\(E(y)\)</span> is not increasing by a constant amount in this case, but by a constant percentage. The percentage increase is 20%.</p>
</section>
<section id="logarithmic-transformation-of-the-model" class="slide level2 center">
<h2>Logarithmic Transformation of the Model</h2>
<p><br></p>
<p>We can transform this nonlinear model to a linear model by taking the natural logarithm of both sides of the equation:</p>
<p><span class="math display">\[
\ln E(y) = \ln \beta_0 + x \ln \beta_1
\]</span></p>
</section>
<section id="linearized-model" class="slide level2 center">
<h2>Linearized Model</h2>
<p><br></p>
<p>Now, if we let <span class="math inline">\(y' = \ln E(y)\)</span>, <span class="math inline">\(\beta'_0 = \ln \beta_0\)</span>, and <span class="math inline">\(\beta'_1 = \ln \beta_1\)</span>, we can rewrite the equation as:</p>
<p><span class="math display">\[
y' = \beta'_0 + \beta'_1 x
\]</span></p>
<p>The formulas for simple linear regression can now be used to develop estimates of <span class="math inline">\(\beta'_0\)</span> and <span class="math inline">\(\beta'_1\)</span>. Denoting the estimates as <span class="math inline">\(b'_0\)</span> and <span class="math inline">\(b'_1\)</span>, leads to the following estimated regression equation:</p>
<p><span class="math display">\[
\hat{y'} = b'_0 + b'_1 x
\]</span></p>
<p>To obtain predictions of the original dependent variable <span class="math inline">\(y\)</span> given a value of <span class="math inline">\(x\)</span>, we would first substitute the value of <span class="math inline">\(x\)</span> into the equation above to compute <span class="math inline">\(\hat{y'}\)</span>, and then raise <span class="math inline">\(e\)</span> to the power of <span class="math inline">\(\hat{y'}\)</span> to obtain the prediction of <span class="math inline">\(y\)</span>, or the expected value of <span class="math inline">\(y\)</span>, in its original units.</p>
</section>
<section id="linearized-model---example-prediction" class="slide level2 center">
<h2>Linearized Model - Example Prediction</h2>
<p>Given the estimates:</p>
<ul>
<li><p><span class="math inline">\(b'_0 = 3.5\)</span></p></li>
<li><p><span class="math inline">\(b'_1 = 0.2\)</span></p></li>
</ul>
<p>Let’s predict <span class="math inline">\(y\)</span> when the advertising expenditure <span class="math inline">\(x = 5\)</span> (in $1000s).</p>
<p>Using the linearized equation we calculate <span class="math inline">\(y'\)</span>:</p>
<p><span class="math display">\[
y' = b'_0 + b'_1 \cdot x = 3.5 + 0.2 \cdot 5 = 4.5
\]</span></p>
<p>Now, exponentiate <span class="math inline">\(y'\)</span> to get the predicted <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[
y = e^{4.5} \approx 90.02
\]</span></p>
<p>Thus, the predicted sales <span class="math inline">\(y\)</span> when the advertising expenditure is 5 (in $1000s) is approximately 90 units (in $1000s).</p>
</section></section>
<section>
<section id="other-transformations-to-consider" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Other Transformations to Consider</h1>

</section>
<section id="other-transformations-to-consider-1" class="slide level2 center">
<h2>Other Transformations to Consider</h2>
<p><br></p>
<ul>
<li class="fragment"><strong>Square-root</strong>: <span class="math inline">\(\sqrt{x}\)</span><br>
</li>
<li class="fragment"><strong>Logarithmic</strong>: <span class="math inline">\(\log_{10}(x), \log_{10}(y), \ln(x)\)</span>, etc.<br>
</li>
<li class="fragment"><strong>Reciprocal</strong>: <span class="math inline">\(1/y, 1/x\)</span><br>
</li>
<li class="fragment"><strong>Exponential</strong>: <span class="math inline">\(e^x, e^y\)</span><br>
</li>
<li class="fragment"><strong>Square</strong>: <span class="math inline">\(x^2, y^2\)</span><br>
</li>
<li class="fragment"><strong>Power</strong>: <span class="math inline">\(x^k, y^k\)</span></li>
</ul>
</section>
<section id="square-root-transformation" class="slide level2 center">
<h2>Square-Root Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(\sqrt{x}\)</span> term or <span class="math inline">\((x^{0.5})\)</span></p>
<p><br></p>

<img data-src="figs/transformation_sqrt.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><br></p>
</section>
<section id="logarithmic-transformation" class="slide level2 center">
<h2>Logarithmic Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(\ln(x) \text{ or } \log(x)\)</span> term.</p>
<p><br></p>

<img data-src="figs/transformation_log.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><br></p>
</section>
<section id="reciprocal-transformation" class="slide level2 center">
<h2>Reciprocal Transformation</h2>
<p><br></p>
<p>Add or use <span class="math inline">\(1/x\)</span> term.</p>
<p><br></p>

<img data-src="figs/transformation_reciprocal.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><br></p>
</section>
<section id="exponential-transformation" class="slide level2 center">
<h2>Exponential Transformation</h2>
<p><br></p>
<p>Change <span class="math inline">\(y\)</span> to <span class="math inline">\(\ln(y)\)</span> as the new response variable.</p>
<p><br></p>

<img data-src="figs/transformation_exponential.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><br></p>
</section>
<section id="power-transformations" class="slide level2 center">
<h2>Power Transformations</h2>
<p><br></p>
<p>Add <span class="math inline">\(x^2\)</span> or <span class="math inline">\(x^k\)</span> term.</p>
<p><br></p>

<img data-src="figs/transformation_power.png" class="quarto-figure quarto-figure-center r-stretch" style="width:80.0%"><p><br></p>
</section></section>
<section>
<section id="when-to-add-or-delete-variables" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>When to Add or Delete Variables</h1>

</section>
<section id="overview-of-predictor-evaluation" class="slide level2 center">
<h2>Overview of Predictor Evaluation</h2>
<ul>
<li class="fragment"><p><strong>Statistical Significance</strong>: Indicates whether the relationship between a predictor and the dependent variable is unlikely to have occurred by chance.</p></li>
<li class="fragment"><p><strong>Effectiveness</strong>: Reflects the practical impact or importance of the predictor on the dependent variable.</p>
<ul>
<li class="fragment">Assessed by observing changes in <strong>adjusted R-squared</strong> when the predictor is included.</li>
<li class="fragment">Statistical significance is evaluated using the <strong>p-value</strong>.</li>
</ul></li>
</ul>
</section>
<section id="four-scenarios-for-predictors" class="slide level2 center">
<h2>Four Scenarios for Predictors</h2>
<div style="font-size: 70%;">
<table class="caption-top">
<colgroup>
<col style="width: 23%">
<col style="width: 36%">
<col style="width: 40%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;"><strong>Statistically Significant</strong><br>(e.g.&nbsp;p-value &lt; 0.05)</th>
<th style="text-align: center;"><strong>Not Statistically Significant</strong><br>(e.g.&nbsp;p-value ≥ 0.05)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>Effective</strong> (Adjusted R-squared increases significantly)</td>
<td style="text-align: center;">Scenario 1<br>Predictor is both statistically significant and effective.</td>
<td style="text-align: center;">Scenario 3<br>Effective but not statistically significant.</td>
</tr>
<tr class="even">
<td style="text-align: center;"><strong>Not Effective</strong> (Adjusted R-squared does not increase significantly)</td>
<td style="text-align: center;">Scenario 2<br>Statistically significant but not effective.</td>
<td style="text-align: center;">Scenario 4<br>Not statistically significant nor effective.</td>
</tr>
</tbody>
</table>
<ul>
<li class="fragment"><p><strong>Definition</strong>: A predictor is an <strong>ineffective predictor</strong> if its <span class="math inline">\(|T-Value| = \left| \frac{b - 0}{se(b)} \right| &lt; 1\)</span>. If that is the case, the coefficient estimate <span class="math inline">\(b\)</span> is within one standard deviation from 0, i.e., too close to 0, or its two-sided <span class="math inline">\(p-value &gt; 0.32\)</span> (Empirical rule).</p>
<ul>
<li class="fragment"><p><strong>Adding</strong> an effective predictor will decrease the estimated error variance <span class="math inline">\(S^2\)</span> and hence increase Adj <span class="math inline">\(R^2\)</span>. The opposite is true when adding an ineffective predictor.</p></li>
<li class="fragment"><p><strong>Removing</strong> an effective predictor will increase the estimated error variance <span class="math inline">\(S^2\)</span> and hence decrease Adj <span class="math inline">\(R^2\)</span>. The opposite is true when removing an ineffective predictor.</p></li>
</ul></li>
</ul>
</div>
</section>
<section id="scenario-1-statistically-significant-and-effective" class="slide level2 center">
<h2>Scenario 1: Statistically Significant and Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li class="fragment"><p><strong>p-value</strong> below chosen significance level (e.g., <span class="math inline">\(p &lt; 0.05\)</span>)</p></li>
<li class="fragment"><p><strong>Adjusted R-squared</strong> increases meaningfully when the predictor is included</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li class="fragment"><p>Predictor reliably contributes to the dependent variable’s variance.</p></li>
<li class="fragment"><p>Both statistically and practically meaningful.</p></li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li class="fragment"><p><strong>Healthcare</strong>: Adding “age” as a predictor in a model for blood pressure yields a <strong>p-value of</strong> <span class="math inline">\(p &lt; 0.001\)</span> and increases the adjusted R-squared from 0.30 to <strong>0.45</strong>.</p></li>
<li class="fragment"><p>Age is both a statistically significant and effective predictor of blood pressure.</p></li>
</ul>
</div>
</section>
<section id="scenario-2-statistically-significant-but-not-effective" class="slide level2 center">
<h2>Scenario 2: Statistically Significant but Not Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li class="fragment"><p><strong>p-value</strong> below the significance threshold</p></li>
<li class="fragment"><p><strong>Minimal change in adjusted R-squared</strong>: negligible improvement in the model’s explanatory power</p></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li class="fragment">Statistically reliable but lacks practical impact.</li>
<li class="fragment">Common in large samples where even small effects become significant.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li class="fragment"><strong>Economics</strong>: Adding “hair color” as a predictor of income yields <strong>p = 0.02</strong>, but increases adjusted R-squared from 0.25 to <strong>0.251</strong>.</li>
<li class="fragment">Hair color is statistically significant but not practically effective.</li>
</ul>
</div>
</section>
<section id="scenario-3-not-statistically-significant-but-effective" class="slide level2 center">
<h2>Scenario 3: Not Statistically Significant but Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li class="fragment"><strong>p-value</strong> exceeds the significance level (e.g., <span class="math inline">\(p &gt; 0.05\)</span>)</li>
<li class="fragment"><strong>Substantial increase in adjusted R-squared</strong></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li class="fragment">Meaningful effect, but lacks statistical support.</li>
<li class="fragment">May need a larger sample size or further refinement.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li class="fragment"><p><strong>Education</strong>: Adding “hours of sleep” as a predictor of student performance increases adjusted R-squared from 0.40 to <strong>0.50</strong> but yields <strong>p = 0.08</strong>.</p></li>
<li class="fragment"><p>“Hours of sleep” has a practical impact but isn’t statistically significant.</p></li>
</ul>
</div>
</section>
<section id="scenario-4-not-statistically-significant-and-not-effective" class="slide level2 center">
<h2>Scenario 4: Not Statistically Significant and Not Effective</h2>
<p><strong>Characteristics</strong></p>
<ul>
<li class="fragment"><strong>p-value</strong> above the significance threshold</li>
<li class="fragment"><strong>No increase in adjusted R-squared</strong></li>
</ul>
<div class="fragment">
<p><strong>Interpretation</strong></p>
<ul>
<li class="fragment">Predictor lacks both statistical and practical value.</li>
<li class="fragment">Likely safe to exclude from the model.</li>
</ul>
</div>
<div class="fragment">
<p><strong>Example</strong></p>
<ul>
<li class="fragment"><strong>Marketing</strong>: Adding “shoe size” to predict customer satisfaction yields <strong>p = 0.60</strong> and decreases adjusted R-squared from 0.35 to <strong>0.34</strong>.</li>
</ul>
</div>
</section></section>
<section>
<section id="strategies-for-adding-or-removing-variables" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Strategies for Adding or Removing Variables</h1>

</section>
<section id="strategies-for-adding-or-removing-variables-1" class="slide level2 center">
<h2>Strategies for Adding or Removing Variables</h2>
<div style="font-size: 70%;">
<table class="caption-top">
<thead>
<tr class="header">
<th><strong>#</strong></th>
<th><strong>Strategy</strong></th>
<th><strong>Description</strong></th>
<th><strong>Add Variables</strong></th>
<th><strong>Remove Variables</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><strong>P-Value</strong></td>
<td>Based on statistical significance</td>
<td>If p-value &lt; 0.05</td>
<td>If p-value &gt; 0.05</td>
</tr>
<tr class="even">
<td>2</td>
<td><strong>Adjusted R-Squared</strong></td>
<td>Checks if model fit improves</td>
<td>If adjusted <span class="math inline">\(R^2\)</span> increases</td>
<td>If adjusted <span class="math inline">\(R^2\)</span> decreases</td>
</tr>
<tr class="odd">
<td>3</td>
<td><strong>F-Test</strong></td>
<td>Compares models with and without added variables</td>
<td>If F-test indicates significant improvement</td>
<td>If F-test shows no significant improvement</td>
</tr>
<tr class="even">
<td>4</td>
<td><a href="https://en.wikipedia.org/wiki/Akaike_information_criterion" target="_blank"><strong>AIC</strong></a> or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion" target="_blank"><strong>BIC</strong></a></td>
<td>Balances model fit and complexity</td>
<td>If AIC/BIC decreases</td>
<td>If AIC/BIC increases</td>
</tr>
<tr class="odd">
<td>5</td>
<td><a href="https://openintro-ims.netlify.app/model-mlr#sec-model-selection" target="_blank"><strong>Stepwise Regression</strong></a></td>
<td>Automated selection procedure based on statistical contribution</td>
<td>Add variables with high statistical contribution</td>
<td>Remove variables with low contribution</td>
</tr>
<tr class="even">
<td>6</td>
<td><strong>Multicollinearity (<a href="https://online.stat.psu.edu/stat462/node/180/" target="_blank">VIF</a>)</strong></td>
<td>The Variance Inflation Factor detects multicollinearity between independent variables</td>
<td>Use the full model</td>
<td>If VIF &gt; 10</td>
</tr>
<tr class="odd">
<td>7</td>
<td><strong>Best Subset Selection</strong></td>
<td>Compares all possible combinations of predictors to identify the best model</td>
<td>Adds the combination of predictors with the best performance based on chosen criteria (e.g., adjusted <span class="math inline">\(R^2\)</span>)</td>
<td>N/A; evaluates models by selecting the best subset</td>
</tr>
<tr class="even">
<td>8</td>
<td><a href="https://openintro-ims.netlify.app/inf-model-mlr#sec-inf-mult-reg-cv" target="_blank"><strong>Cross-Validation</strong></a></td>
<td>Assesses model performance across different data subsets</td>
<td>If cross-validation performance improves</td>
<td>If cross-validation performance worsens</td>
</tr>
<tr class="odd">
<td>9</td>
<td><a href="https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf" target="_blank"><strong>Good vs Bad Controls</strong></a></td>
<td>For causal inference purposes</td>
<td>Add good controls that help block non-causal paths</td>
<td>Remove bad controls that open new spurious paths</td>
</tr>
<tr class="even">
<td>10</td>
<td><strong>Theoretical Justification</strong></td>
<td>Adds or removes variables based on theory, domain knowledge, or experience</td>
<td>Add based on theory or domain knowledge</td>
<td>Remove variables that are irrelevant, regardless of statistical significance</td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="adding-or-removing-variables" class="slide level2 center">
<h2>Adding or Removing Variables</h2>
<p>We will focus on the following:</p>
<ol type="1">
<li><strong>Stepwise regression</strong></li>
<li><strong>Forward selection</strong></li>
<li><strong>Backward elimination</strong></li>
<li><strong>Best-subsets regression</strong>.</li>
</ol>
<p>The first three procedures are iterative; at each step, a single independent variable is added or deleted, and the new model is evaluated. The process continues until a stopping criterion indicates that the procedure cannot find a better model.</p>
<p>The best-subsets procedure is not a one-variable-at-a-time procedure; it evaluates regression models involving different subsets of the independent variables.</p>
</section>
<section id="adding-variables-in-regression-models-f-test" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>We can use an F-test to determine whether it is advantageous to add one or more independent variables to a multiple regression model.</p>
<p>This is based on determining the reduction in the error sum of squares (SSE) resulting from adding variables.</p>
<p>The null and alternative hypotheses are defined as:</p>
<p><span class="math display">\[
H_0: \beta_{q+1} = \beta_{q+2} = \cdots = \beta_p = 0
\]</span></p>
<p><span class="math display">\[
H_a: \text{One or more of the parameters is not equal to zero}
\]</span></p>
<p>where <span class="math inline">\(q\)</span> is the number of independent variables in the first model.</p>
</section>
<section id="adding-variables-in-regression-models-f-test-1" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>Let’s illustrate this using the Butler Trucking example.</p>
<p>The regression equation with miles traveled <span class="math inline">\(x_1\)</span> as the only independent variable is:</p>
<p><span class="math display">\[
\hat{y} = 1.2739 + 0.0678x_1
\]</span></p>
<p>The error sum of squares for this model is:</p>
<p><span class="math display">\[
SSE(x_1) = 8.0287
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-2" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>When the number of deliveries <span class="math inline">\(x_2\)</span> is added, the regression equation becomes:</p>
<p><span class="math display">\[
\hat{y} = -0.8687 + 0.0611x_1 + 0.9234x_2
\]</span></p>
<p>The error sum of squares for this model is:</p>
<p><span class="math display">\[
SSE(x_1, x_2) = 2.2994
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-3" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>The reduction in SSE from adding <span class="math inline">\(x_2\)</span> to the model is:</p>
<p><span class="math display">\[
SSE(x_1) - SSE(x_1, x_2) = 8.0287 - 2.2994 = 5.7293
\]</span></p>
<p>We can conduct a F-test to determine if this reduction is significant:</p>
<p><span class="math display">\[
F = \frac{\frac{SSE(x_1) - SSE(x_1, x_2)}{1}}{\frac{SSE(x_1, x_2)}{n - p - 1}}
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-4" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<div style="font-size: 80%;">
<p>Substituting the values:</p>
<p><span class="math display">\[
F = \frac{5.7293}{1} \Big/ \frac{2.2994}{7} = 17.44
\]</span> Where,</p>
<ul>
<li><span class="math inline">\(n = 10\)</span></li>
<li><span class="math inline">\(p = 2\)</span></li>
</ul>
<p><strong>Conclusion from F-Test</strong></p>
<p>Using Excel, we obtain a <span class="math inline">\(p\)</span>-value of <span class="math inline">\(0.0042\)</span> for the calculated F-statistic. Since the <span class="math inline">\(p\)</span>-value is less than the significance level <span class="math inline">\(\alpha = 0.05,\)</span> we reject the null hypothesis. Thus, adding <span class="math inline">\(x_2\)</span> results in a significant reduction in SSE.</p>
<p>The t-test and F-test are equivalent when only one independent variable is being added, and we can use either to assess significance.</p>
</div>
</section>
<section id="adding-variables-in-regression-models-f-test-5" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>In the stepwise regression, forward selection, and backward elimination procedures, the criterion for selecting an independent variable to add or delete from the model at each step is based on the F-statistic.</p>
<p>Suppose we are considering adding <span class="math inline">\(x_2\)</span> to a model involving <span class="math inline">\(x_1\)</span> or deleting <span class="math inline">\(x_2\)</span> from a model involving <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. To test whether the addition or deletion of <span class="math inline">\(x_2\)</span> is statistically significant, the null and alternative hypotheses can be stated as follows:</p>
<p><span class="math display">\[
H_0: \beta_2 = 0
\]</span></p>
<p><span class="math display">\[
H_a: \beta_2 \neq 0
\]</span></p>
</section>
<section id="adding-variables-in-regression-models-f-test-6" class="slide level2 center">
<h2>Adding Variables in Regression Models: F-test</h2>
<p>We saw that:</p>
<p><span class="math display">\[
F = \frac{{SSE(x_1) - SSE(x_1, x_2)}}{1} \div \frac{{SSE(x_1, x_2)}}{n - p - 1}
\]</span></p>
<p>can be used as a criterion for determining whether the presence of <span class="math inline">\(x_2\)</span> in the model causes a significant reduction in the error sum of squares.</p>
<p>The p-value corresponding to this F-statistic is used to determine whether an independent variable should be added or deleted from the regression model. The usual rejection rule applies: Reject <span class="math inline">\(H_0\)</span> if p-value <span class="math inline">\(\leq \alpha\)</span>.</p>
</section></section>
<section>
<section id="stepwise-regression" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Stepwise Regression</h1>

</section>
<section id="stepwise-regression-overview" class="slide level2 center">
<h2>Stepwise Regression: Overview</h2>
<ul>
<li class="fragment"><p>Stepwise regression is a <strong>semi-automated</strong> procedure for selecting independent variables in a multiple regression model.</p></li>
<li class="fragment"><p>At each step, the method evaluates whether any variable should be <strong>removed</strong> from or <strong>added</strong> to the model based on predefined significance levels.</p></li>
<li class="fragment"><p>Because it does not exhaustively examine all possible combinations of predictors, stepwise regression does not guarantee finding the best subset of predictors in terms of overall fit or predictive accuracy.</p></li>
</ul>
</section>
<section id="stepwise-regression-how-it-works" class="slide level2 center">
<h2>Stepwise Regression: How It Works</h2>
<ol type="1">
<li class="fragment"><strong>Initial Removal Check</strong>
<ul>
<li class="fragment">Begin with an initial model (which can start with no variables, a single variable, or a chosen subset).</li>
<li class="fragment"><strong>Compute F-statistics and p-values</strong> for each predictor already included.</li>
<li class="fragment">If <strong>any</strong> predictor’s p-value exceeds the “p-value to leave” threshold (often denoted <span class="math inline">\(\alpha_{\text{remove}}\)</span>), the predictor with the <strong>largest</strong> p-value is removed.</li>
<li class="fragment">After a variable is removed, a new step commences.</li>
</ul></li>
<li class="fragment"><strong>Next Possible Addition</strong>
<ul>
<li class="fragment">If no variable meets the criterion for removal, then the procedure checks any variables <strong>not</strong> in the model.</li>
<li class="fragment"><strong>Compute F-statistics and p-values</strong> for each candidate predictor not in the model.</li>
<li class="fragment">If the <strong>smallest</strong> p-value among these is below the “p-value to enter” threshold (often denoted <span class="math inline">\(\alpha_{\text{enter}}\)</span>), the corresponding predictor is added.</li>
<li class="fragment">Steps alternate between removal and addition until no variable can be removed or added based on these criteria.</li>
</ul></li>
</ol>
</section>
<section id="considerations-and-limitations" class="slide level2 center">
<h2>Considerations and Limitations</h2>
<ul>
<li class="fragment"><p><strong>Non-exhaustive approach</strong>: Because stepwise regression evaluates one variable at a time (in or out), it does <strong>not</strong> consider all possible subsets of predictors. Therefore, it might overlook a model that would yield a higher <span class="math inline">\(R^2\)</span> or better predictive performance.</p></li>
<li class="fragment"><p><strong>Variability of inclusion</strong>: A predictor can enter at one step, be removed at a later step, and potentially re-enter if the residual relationships change after adding or removing other variables.</p></li>
<li class="fragment"><p><strong>Overemphasis on p-values</strong>: Stepwise regression heavily depends on p-values, which can be sensitive to sample size and collinearity. It can also lead to an overly complex model or, conversely, a model that excludes potentially relevant predictors.</p></li>
<li class="fragment"><p><strong>Data-driven model building</strong>: Automated selection methods (including stepwise) may produce results that do not generalize well outside the sample. Cross-validation or penalized methods (e.g., LASSO, ridge regression) are often recommended as more robust alternatives.</p></li>
</ul>
</section>
<section id="stepwise-regression-example" class="slide level2 center">
<h2>Stepwise Regression Example</h2>
<p>Suppose we have a dataset with:</p>
<ul>
<li class="fragment"><strong>Income</strong> (in thousands of dollars)</li>
<li class="fragment"><strong>Age</strong> (age of household head)</li>
<li class="fragment"><strong>Education</strong> (years of education)</li>
<li class="fragment"><strong>Spending</strong> (annual spending on goods, our dependent variable)</li>
</ul>
</section>
<section id="stepwise-regression-example-starting-point" class="slide level2 center">
<h2>Stepwise Regression Example: Starting Point</h2>
<ol type="1">
<li class="fragment"><strong>Initial Model</strong>
<ul>
<li class="fragment">Begin with one predictor (for instance, <strong>Income</strong>) or a subset deemed important by domain knowledge.</li>
<li class="fragment">Fit the model:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \epsilon.
\]</span></li>
<li class="fragment">Suppose <strong>Income</strong> is significant at <span class="math inline">\(\alpha=0.05\)</span>. Keep <strong>Income</strong> in the model.</li>
</ul></li>
<li class="fragment"><strong>Evaluating Other Predictors</strong>
<ul>
<li class="fragment">Next, consider adding <strong>Age</strong> or <strong>Education</strong>.</li>
<li class="fragment">Fit two separate models, each adding one candidate variable:
<ol type="1">
<li class="fragment"><span class="math inline">\(\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.\)</span></li>
<li class="fragment"><span class="math inline">\(\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_3 \cdot \text{Age} + \epsilon.\)</span></li>
</ol></li>
<li class="fragment">Calculate p-values for <span class="math inline">\(\hat{\beta}_2\)</span> and <span class="math inline">\(\hat{\beta}_3\)</span>. If <strong>Education</strong> has the lower p-value (below the “p-value to enter,” say 0.05), add <strong>Education</strong> to the model.</li>
</ul></li>
</ol>
</section>
<section id="stepwise-regression-example-checking-for-removal" class="slide level2 center">
<h2>Stepwise Regression Example: Checking for Removal</h2>
<p>Once you have a model with <strong>Income</strong> and <strong>Education</strong>, stepwise regression checks if <strong>Income</strong> or <strong>Education</strong> should be removed:</p>
<ol type="1">
<li class="fragment">Re-estimate:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.
\]</span></li>
<li class="fragment">If either predictor’s p-value exceeds “p-value to leave” (say 0.10), remove that predictor. Otherwise, both stay.</li>
</ol>
</section>
<section id="stepwise-regression-example-considering-remaining-predictors" class="slide level2 center">
<h2>Stepwise Regression Example: Considering Remaining Predictors</h2>
<p>If <strong>Age</strong> is still not in the model, you check whether it can enter:</p>
<ol type="1">
<li class="fragment">Fit:<br>
<span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \beta_3 \cdot \text{Age} + \epsilon.
\]</span></li>
<li class="fragment">If <strong>Age</strong>’s p-value is below the threshold, it is added; otherwise, it is excluded.<br>
</li>
<li class="fragment">Continue this process until no more additions or removals are justified.</li>
</ol>
</section>
<section id="stepwise-regression-example-final-model" class="slide level2 center">
<h2>Stepwise Regression Example: Final Model</h2>
<p>Eventually, the procedure converges on a model, for example:</p>
<p><span class="math display">\[
\text{Spending} = \beta_0 + \beta_1 \cdot \text{Income} + \beta_2 \cdot \text{Education} + \epsilon.
\]</span></p>
<p>This indicates <strong>Income</strong> and <strong>Education</strong> meet the significance criteria for inclusion, while <strong>Age</strong> does not.</p>
</section>
<section id="summary-of-the-stepwise-procedure" class="slide level2 center">
<h2>Summary of the Stepwise Procedure</h2>
<ol type="1">
<li class="fragment"><strong>Start</strong>
<ul>
<li class="fragment">Choose an initial model (empty, single variable, or chosen subset).</li>
</ul></li>
<li class="fragment"><strong>Remove</strong>
<ul>
<li class="fragment">Check if any included variables can be removed based on “p-value to leave.” If so, remove the worst offender and repeat.</li>
</ul></li>
<li class="fragment"><strong>Add</strong>
<ul>
<li class="fragment">If no variable is removed in a step, check whether any excluded variable meets the “p-value to enter.” If so, add the variable with the smallest p-value.</li>
</ul></li>
<li class="fragment"><strong>Stop</strong>
<ul>
<li class="fragment">Terminate when no variable can be removed or added according to the thresholds.</li>
</ul></li>
</ol>
<!---
# Stepwise Regression {background-color="#cfb991"}

## Stepwise Regression

The stepwise regression procedure begins each step by determining whether any of the variables **already in the model** should be removed.

It does so by first computing an F-statistic and corresponding p-value for each independent variable in the model.

Refering to the level of significance $\alpha$ for determining whether an independent variable should be removed from the model as **p Value to Leave**, if the p-value for any independent variable is greater than **p Value to Leave**, the independent variable with the largest p-value is removed, and the stepwise regression procedure begins a new step.

## Stepwise Regression Process

If no independent variable can be removed from the model, the procedure attempts to enter another independent variable into the model.

It does so by first computing an F-statistic and corresponding p-value for each independent variable that is not in the model.

Refering to the level of significance $\alpha$ for determining whether an independent variable should be entered into the model as **p Value to Enter**.

The independent variable with the smallest p-value is entered into the model provided its p-value is less than **p Value to Enter**. The procedure continues in this manner until no independent variables can be deleted from or added to the model.

## Stepwise Regression Limitations

Because the one-at-a-time procedures do not consider every possible subset for a given number of independent variables, they will not necessarily select the model with the highest R-Square value.

In summary, at each step of the stepwise regression procedure, the first consideration is to see whether any independent variable can be removed from the current model. If none of the independent variables can be removed from the model, the procedure checks to see whether any of the independent variables that are not currently in the model can be entered.

## Stepwise Regression Considerations

Because of the nature of the stepwise regression procedure, an independent variable can enter the model at one step, be removed at a subsequent step, and then enter the model at a later step.

The procedure stops when no independent variables can be removed from or entered into the model.

## Stepwise Regression Example

Let's consider a dataset with the following variables:

-   **Income**: Household income (in \$1000s)
-   **Age**: Age of the head of the household
-   **Education**: Years of education
-   **Spending**: Annual spending on goods (dependent variable)

::: fragment
**Initial Model**

We start by considering an initial model with **Income** as the only predictor of **Spending**.

$$
Spending = \beta_0 + \beta_1 \cdot Income + \epsilon
$$

Using an F-statistic and p-value, we find **Income** is significant, so we keep it in the model.
:::

## Stepwise Regression Example

:::: {style="font-size: 60%;"}
::: nonincremental
The remaining variables, **Age** and **Education**, are candidates for inclusion.

**Calculating p-values for Inclusion**

-   **Add Each Variable Separately**: Create two new models:

    1.  **Adding Education**:

        $$
        Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
        $$

    2.  **Adding Age**:

        $$
        Spending = \beta_0 + \beta_1 \cdot Income + \beta_3 \cdot Age + \epsilon
        $$

-   **Estimate Coefficients**: For each model, estimate the new coefficients ($\hat{\beta}_2$ or $\hat{\beta}_3$).

-   **Compute Standard Errors**: Calculate the standard errors for these new coefficients.

-   **Calculate t-statistics**:

    $$
    t_{\text{Education}} = \frac{\hat{\beta}_2}{SE(\hat{\beta}_2)}
    $$

    $$
    t_{\text{Age}} = \frac{\hat{\beta}_3}{SE(\hat{\beta}_3)}
    $$

-   **Determine p-values**: Find the p-values corresponding to $t_{\text{Education}}$ and $t_{\text{Age}}$.

**Decision**

-   **Select Variable with Lowest p-value**: Choose the variable with the lowest p-value below the entry threshold (e.g., 0.05).

-   **Add Significant Variable**: Since **Education** is significant (assuming a p-value of 0.01), add it to the model.
:::
::::

## Stepwise Regression Example

:::: {style="font-size: 70%;"}
::: nonincremental
With **Income** and **Education** in the model:

$$
Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
$$

**Calculating p-values for Removal**

-   **Re-estimate Coefficients**: Re-estimate $\hat{\beta}_1$ and $\hat{\beta}_2$.

-   **Compute Standard Errors**: Calculate the standard errors for these coefficients.

-   **Calculate t-statistics**:

    $$
    t_{\text{Income}} = \frac{\hat{\beta}_1}{SE(\hat{\beta}_1)}
    $$

    $$
    t_{\text{Education}} = \frac{\hat{\beta}_2}{SE(\hat{\beta}_2)}
    $$

-   **Determine p-values**: Find the p-values corresponding to $t_{\text{Income}}$ and $t_{\text{Education}}$.

**Decision**

-   **Check for Non-significance**: If any variable's p-value exceeds the removal threshold (e.g., 0.10), consider removing it.

-   **Retain Significant Variables**: If both variables remain significant (p-values below 0.05), keep them in the model.
:::
::::

## Stepwise Regression Example

:::: {style="font-size: 70%;"}
::: nonincremental
**Assess Remaining Variables**

Now, only **Age** remains for consideration.

**Calculating p-value for Age**

-   **Add Age to the Model**:

    $$
    Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \beta_3 \cdot Age + \epsilon
    $$

-   **Estimate** $\hat{\beta}_3$ and Compute SE: Estimate the coefficient for **Age** and its standard error.

-   **Calculate t-statistic and p-value**:

    $$
    t_{\text{Age}} = \frac{\hat{\beta}_3}{SE(\hat{\beta}_3)}
    $$

-   **Determine the p-value**: Find the p-value from the t-distribution.

**Decision**

-   **Add or Exclude**: If the p-value for **Age** is below 0.05, add it to the model; otherwise, exclude it.

-   **Example Outcome**: Suppose the p-value for **Age** is 0.15; you would not add **Age** to the model.
:::
::::

## Stepwise Regression Example

<br>

After completing the procedure, our final model could look like this:

$$
Spending = \beta_0 + \beta_1 \cdot Income + \beta_2 \cdot Education + \epsilon
$$

Here, **Income** and **Education** are the only significant predictors of **Spending**.

## Summary of Stepwise Procedure

1.  **Start**: Begin with one variable and calculate p-values.
2.  **Add**: Add the variable with the lowest p-value, provided it's below the threshold.
3.  **Remove**: Remove variables if their p-values become too high.
4.  **Stop**: Stop when no more variables can be added or removed.
--->
</section></section>
<section>
<section id="forward-selection" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Forward Selection</h1>

</section>
<section id="forward-selection-overview" class="slide level2 center">
<h2>Forward Selection: Overview</h2>
<ul>
<li class="fragment"><p><strong>Forward selection</strong> is a <strong>sequential variable selection</strong> procedure that begins with an <strong>empty model</strong> (i.e., no predictors) and incrementally adds variables based on significance criteria.</p></li>
<li class="fragment"><p>Unlike the stepwise procedure, forward selection <strong>never removes</strong> any variable once it has been included.</p></li>
</ul>
</section>
<section id="forward-selection-procedure" class="slide level2 center">
<h2>Forward Selection: Procedure</h2>
<div style="font-size: 70%;">
<ol type="1">
<li class="fragment"><strong>Start with No Variables</strong>
<ul>
<li class="fragment">The initial model includes <strong>no</strong> predictors: <span class="math display">\[
y = \beta_0 + \epsilon.
\]</span></li>
</ul></li>
<li class="fragment"><strong>Evaluate All Predictors for Entry</strong>
<ul>
<li class="fragment">For each potential predictor not yet in the model, calculate the F-statistic (or equivalently, t-statistic for the coefficient) and its corresponding p-value.</li>
<li class="fragment"><strong>p-Value to Enter</strong>: Each predictor is tested against a specified significance level (e.g., <span class="math inline">\(\alpha_{\text{enter}}\)</span>). If the smallest p-value among all candidate predictors falls below <span class="math inline">\(\alpha_{\text{enter}}\)</span>, add that corresponding predictor to the model.</li>
</ul></li>
<li class="fragment"><strong>Recalculate and Repeat</strong>
<ul>
<li class="fragment">After adding a predictor, recalculate the model parameters and evaluate the remaining predictors for entry. Continue this process of adding <strong>one</strong> variable at a time.</li>
</ul></li>
<li class="fragment"><strong>Termination</strong>
<ul>
<li class="fragment">The procedure stops when <strong>no</strong> remaining predictors meet the threshold for entry, meaning all p-values for excluded variables exceed <span class="math inline">\(\alpha_{\text{enter}}\)</span>.</li>
</ul></li>
</ol>
<div class="fragment">
<blockquote>
<p><strong>Key Difference from Stepwise</strong>: In forward selection, <strong>once a variable is included</strong>, it cannot be removed—even if adding subsequent variables renders it less significant.</p>
</blockquote>
</div>
</div>
</section>
<section id="forward-selection-limitations" class="slide level2 center">
<h2>Forward Selection Limitations</h2>
<div style="font-size: 80%;">
<ol type="1">
<li class="fragment"><p><strong>No Removal of Variables</strong>: Because there is no mechanism to remove predictors, variables that become <strong>unnecessary</strong> later might remain in the final model. This can lead to inflated model complexity and reduced interpretability.</p></li>
<li class="fragment"><p><strong>Potential Multicollinearity Issues</strong>: Forward selection does not explicitly account for <strong>multicollinearity</strong>. High correlations among predictors may lead to unstable coefficient estimates and p-values, producing misleading or less robust results.</p></li>
<li class="fragment"><p><strong>Greedy Algorithm</strong>: The procedure is <strong>myopically focused</strong> on adding one predictor at a time based on immediate improvements in model fit. It may miss a combination of predictors that could perform better when considered together.</p></li>
<li class="fragment"><p><strong>Risk of Overfitting</strong>: When many potential predictors exist, forward selection can overfit the sample data, reducing the model’s generalizability. The model might appear strong in-sample but perform poorly on new data.</p></li>
<li class="fragment"><p><strong>Neglect of Interactions and Nonlinearities</strong>: Because forward selection evaluates predictors in isolation, it does not automatically consider <strong>interaction</strong> terms or <strong>nonlinear transformations</strong>. Thus, it can overlook influential higher-order relationships.</p></li>
</ol>
</div>
<!---
# Forward Selection {background-color="#cfb991"}

## Forward Selection

The forward selection procedure starts with no independent variables. It adds variables one at a time using the same procedure as stepwise regression for determining whether an independent variable should be entered into the model.

-   However, the forward selection procedure does not permit a variable to be removed from the model once it has been entered.

-   The procedure stops when the p-value for each of the independent variables not in the model is greater than **p Value to Enter**.

## Forward Selection Limitations

1.  **No Removal of Variables**: Once a variable is entered into the model, it cannot be removed, even if later additions make it less significant. This could result in keeping variables that are not optimal for the final model.

2.  **Ignores Multicollinearity**: Forward selection does not account for multicollinearity between independent variables. High correlations among predictors may lead to unstable coefficients and misleading results.

3.  **Greedy Approach**: The procedure focuses on adding one variable at a time based on immediate statistical improvement, which might lead to suboptimal global models. It might overlook combinations of variables that would better explain the dependent variable.

4.  **Model Overfitting**: Forward selection increases the risk of overfitting, especially when the dataset has many variables. This results in a model that fits the training data too closely but performs poorly on new data.

5.  **Assumes Independence of Variables**: The procedure assumes that variables can be assessed one by one for entry, without considering how combinations of variables interact. This might ignore important interactions between variables that could improve model performance.

--->
</section></section>
<section>
<section id="backward-elimination" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Backward Elimination</h1>

</section>
<section id="backward-elimination-overview" class="slide level2 center">
<h2>Backward Elimination: Overview</h2>
<p><strong>Backward elimination</strong> is a <strong>sequential variable selection</strong> method that starts with the <strong>full model</strong>—i.e., one that includes <strong>all</strong> potential predictors—and iteratively removes the least significant predictor at each step. It stops when no remaining predictors have a p-value above the designated <strong>“p-value to leave”</strong> threshold (<span class="math inline">\(\alpha_{\text{remove}}\)</span>). Unlike stepwise methods, once a variable is removed, it is <strong>not</strong> allowed to reenter the model.</p>
</section>
<section id="backward-elimination-procedure" class="slide level2 center">
<h2>Backward Elimination: Procedure</h2>
<div style="font-size: 70%;">
<ol type="1">
<li class="fragment"><strong>Begin with All Predictors</strong>
<ul>
<li class="fragment">The initial model is: <span class="math display">\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k + \epsilon.
\]</span></li>
</ul></li>
<li class="fragment"><strong>Compute p-values</strong>
<ul>
<li class="fragment">Estimate the coefficients and compute p-values (or equivalent F-statistics) for each predictor.</li>
</ul></li>
<li class="fragment"><strong>Remove the Least Significant Variable</strong>
<ul>
<li class="fragment">Identify the predictor with the <strong>largest</strong> p-value.</li>
<li class="fragment">If that p-value exceeds the “p-value to leave” threshold, remove the corresponding variable from the model.</li>
</ul></li>
<li class="fragment"><strong>Re-estimate and Repeat</strong>
<ul>
<li class="fragment">After removing a variable, re-fit the model and compute p-values again for the reduced set of predictors.<br>
</li>
<li class="fragment">Continue removing variables one at a time until <strong>no</strong> remaining predictors have p-values larger than <span class="math inline">\(\alpha_{\text{remove}}\)</span>.</li>
</ul></li>
<li class="fragment"><strong>Stop Criterion</strong>
<ul>
<li class="fragment">Once no variable meets the removal criterion, the procedure ends. The final set of variables constitutes the chosen model.</li>
</ul></li>
</ol>
<div class="fragment">
<blockquote>
<p><strong>Key Restriction</strong>: Any predictor removed at an earlier step <strong>cannot</strong> be reconsidered for reentry in later steps.</p>
</blockquote>
</div>
</div>
</section>
<section id="backward-elimination-limitations" class="slide level2 center">
<h2>Backward Elimination Limitations</h2>
<ol type="1">
<li class="fragment"><p><strong>No Reentry of Variables</strong>: Once a predictor is removed, it stays out—even if, after further eliminations, it would have become significant again. This may lead to <strong>omitting</strong> variables that could have value under a different model specification.</p></li>
<li class="fragment"><p><strong>Multicollinearity Concerns</strong>: Backward elimination does not explicitly address <strong>multicollinearity</strong>. Highly correlated predictors may cause instability in coefficient estimates, rendering p-values less reliable.</p></li>
<li class="fragment"><p><strong>Risk of Overfitting</strong>: Because the procedure begins with <strong>all</strong> variables, it may produce an overly complex initial model. While backward elimination might remove some predictors, it can still result in a model that is closely tailored to the sample data but performs poorly in <strong>out-of-sample</strong> scenarios.</p></li>
<li class="fragment"><p><strong>Dependence on Initial Model</strong>: The entire process depends heavily on the <strong>initial choice</strong> of predictors. If irrelevant variables are included or if critical interaction terms are missing, the final model may be suboptimal.</p></li>
<li class="fragment"><p><strong>Potentially Different Final Models</strong>: Different paths of elimination might yield different final models, depending on the order in which variables are removed. This is particularly true if multiple predictors have similar statistical significance or if interactions are not explored.</p></li>
</ol>
<!---

# Backward Elimination {background-color="#cfb991"}

## Backward Elimination

The backward elimination procedure begins with a model that includes all the independent variables.

It then deletes one independent variable at a time using the same procedure as stepwise regression. However, the backward elimination procedure does not permit an independent variable to be reentered once it has been removed.

The procedure stops when none of the independent variables in the model has a p-value greater than **p Value to Leave**.

## Backward Elimination Limitations

1.  **No Reentry of Variables**: Once a variable is removed from the model, it cannot be reentered, even if later stages show that it might be significant. This could lead to models that miss important predictors.

2.  **Ignores Multicollinearity**: Backward elimination does not take into account multicollinearity between variables. High correlations between predictors can result in unreliable coefficient estimates.

3.  **Overfitting Risk**: By starting with all variables and only eliminating those that don't meet the p-value threshold, there is a higher risk of overfitting. The model may fit the training data too closely but generalize poorly to new data.

4.  **Dependent on Initial Model**: The procedure is highly dependent on the initial model, which includes all variables. Poor choices in the initial set of variables can lead to suboptimal models.

5.  **May Lead to Different Models**: Different elimination paths could lead to different final models, and not all of them may be optimal. Backward elimination might overlook variable interactions and combinations that forward selection would have considered.

--->
</section></section>
<section>
<section id="best-subsets-regression" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Best-Subsets Regression</h1>

</section>
<section id="best-subsets-regression-1" class="slide level2 center">
<h2>Best-Subsets Regression</h2>
<p>Many statistical software packages have a procedure called best-subsets regression that enables the user to find, given a specified number of independent variables, the best regression equation.</p>
<p>Typical output from such packages will enable the user to identify:</p>
<ul>
<li class="fragment"><p>The two best one-variable estimated regression equations,</p></li>
<li class="fragment"><p>The two best two-variable regression equations,</p></li>
<li class="fragment"><p>The two best three-variable regression equations, and so on.</p></li>
</ul>
<div class="fragment">
<p>The criterion used in determining which estimated regression equations are best for any number of predictors is usually the value of the adjusted coefficient of determination.</p>
</div>
</section></section>
<section>
<section id="adding-variables-in-regression-models-notes" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Adding Variables in Regression Models: Notes</h1>

</section>
<section id="adding-variables-in-regression-models-notes-1" class="slide level2 center">
<h2>Adding Variables in Regression Models: Notes</h2>
<ol type="1">
<li class="fragment"><p><strong>Limitations of Procedures</strong>: None of the procedures that add or delete variables one at a time can be guaranteed to identify the best regression model.</p>
<ul>
<li class="fragment">However, they are excellent approaches to finding good models—especially when multicollinearity is present.</li>
</ul></li>
<li class="fragment"><p><strong>Software Implementation</strong>: The stepwise, forward selection, backward elimination, and best-subsets approaches to building a regression model can be implemented in Excel.</p>
<ul>
<li class="fragment"><p>However, this would be very inefficient as each approach would potentially require several steps in which various models based on what was learned in the previous step would have to be estimated.</p></li>
<li class="fragment"><p>Most statistical software (including <code>R</code>) are capable of implementing each of these algorithms automatically.</p></li>
</ul></li>
</ol>
</section></section>
<section>
<section id="summary" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Summary</h1>

</section>
<section id="summary-1" class="slide level2 center">
<h2>Summary</h2>
<div style="font-size: 70%;">
<p>Some key takeaways from this session:</p>
<ul>
<li><p><strong>General Linear Model</strong>: Models parameters with exponents of 1. Example:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 z_1 + \beta_2 z_2 + \ldots + \beta_p z_p + \epsilon\]</span></p></li>
<li><p><strong>Curvilinear Relationships</strong>: Use quadratic terms to model curvature:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_1^2 + \epsilon\]</span></p></li>
<li><p><strong>Interaction Effects</strong>: Captures how two variables together influence <span class="math inline">\(y\)</span>.Here is a great <a href="https://www.cambridge.org/core/journals/political-analysis/article/understanding-interaction-models-improving-empirical-analyses/9BA57B3720A303C61EBEC6DDFA40744B" target="_blank">paper about the topic</a>.</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon\]</span></p></li>
<li><p><strong>Log Transformations</strong>: Useful for handling non-linearity and heteroscedasticity.</p></li>
<li><p><strong>Stepwise Regression</strong>: Iterative process of adding/removing variables based on statistical significance, but risks overfitting.</p></li>
<li><p><strong>Forward Selection</strong>: Adds variables one-by-one but doesn’t allow removal after inclusion.</p></li>
<li><p><strong>Backward Elimination</strong>: Starts with all variables and eliminates non-significant ones.</p></li>
<li><p><strong>Best-Subsets Regression</strong>: Evaluates all possible subsets of variables to find the best model.</p></li>
</ul>
</div>
</section></section>
<section id="thank-you" class="title-slide slide level1 center" data-background-color="#cfb991">
<h1>Thank you!</h1>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Business Statistics</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>